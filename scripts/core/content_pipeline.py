import os
import re
import yaml
import logging
import subprocess
import shutil
import frontmatter
import json
import time
import uuid
import tempfile
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.console import Console
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any, Union, Set
from datetime import datetime
import google.generativeai as genai
from google.generativeai.client import configure
from google.generativeai.generative_models import GenerativeModel
from google.generativeai.types import GenerationConfig, BlockedPromptException
from google.api_core.exceptions import ResourceExhausted
import argparse
import requests
from dotenv import load_dotenv

# å¯¼å…¥æœ¬åœ°æ¨¡å—
try:
    from .wechat_publisher import WechatPublisher
except ImportError:
    from scripts.core.wechat_publisher import WechatPublisher

# å†…å®¹å˜ç°ç³»ç»Ÿï¼ˆå¯é€‰å¯¼å…¥ï¼‰
RewardSystemManager = None
try:
    from ..utils.reward_system_manager import RewardSystemManager
except ImportError:
    try:
        from scripts.utils.reward_system_manager import RewardSystemManager
    except ImportError:
        pass  # å†…å®¹å˜ç°ç³»ç»Ÿæ¨¡å—ä¸å¯ç”¨

class PublishingStatusManager:
    """å‘å¸ƒçŠ¶æ€ç®¡ç†å™¨"""
    
    def __init__(self, drafts_dir: Path):
        self.drafts_dir = Path(drafts_dir)
        self.status_dir = self.drafts_dir / ".publishing"
        self.status_dir.mkdir(exist_ok=True)
        
    def get_status_file_path(self, article_name: str) -> Path:
        """è·å–æ–‡ç« çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        article_name = article_name.replace('.md', '')
        return self.status_dir / f"{article_name}.yml"
    
    def get_published_platforms(self, article_name: str) -> List[str]:
        """è·å–æ–‡ç« å·²å‘å¸ƒçš„å¹³å°åˆ—è¡¨"""
        status_file = self.get_status_file_path(article_name)
        
        if not status_file.exists():
            return []
            
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                status_data = yaml.safe_load(f) or {}
            return status_data.get('published_platforms', [])
        except Exception:
            return []
    
    def update_published_platforms(self, article_name: str, platforms: List[str]):
        """æ›´æ–°æ–‡ç« çš„å‘å¸ƒå¹³å°åˆ—è¡¨"""
        status_file = self.get_status_file_path(article_name)
        
        # è¯»å–ç°æœ‰çŠ¶æ€
        status_data = {}
        if status_file.exists():
            try:
                with open(status_file, 'r', encoding='utf-8') as f:
                    status_data = yaml.safe_load(f) or {}
            except Exception:
                status_data = {}
        
        # æ›´æ–°å‘å¸ƒå¹³å°åˆ—è¡¨ï¼ˆåˆå¹¶ï¼Œé¿å…é‡å¤ï¼‰
        existing_platforms = set(status_data.get('published_platforms', []))
        new_platforms = set(platforms)
        all_platforms = list(existing_platforms.union(new_platforms))
        
        # æ›´æ–°çŠ¶æ€æ•°æ®
        status_data.update({
            'article_name': article_name,
            'published_platforms': all_platforms,
            'last_updated': datetime.now().isoformat(),
            'total_publications': len(all_platforms)
        })
        
        # ä¿å­˜çŠ¶æ€æ–‡ä»¶
        try:
            with open(status_file, 'w', encoding='utf-8') as f:
                yaml.safe_dump(status_data, f, default_flow_style=False, 
                             allow_unicode=True, sort_keys=False)
        except Exception as e:
            logging.error(f"ä¿å­˜å‘å¸ƒçŠ¶æ€å¤±è´¥: {e}")
    
    def get_available_platforms(self, article_name: str, all_platforms: List[str]) -> List[str]:
        """è·å–æ–‡ç« å¯å‘å¸ƒçš„å¹³å°åˆ—è¡¨ï¼ˆæ’é™¤å·²å‘å¸ƒçš„ï¼‰"""
        published_platforms = set(self.get_published_platforms(article_name))
        available_platforms = [p for p in all_platforms if p not in published_platforms]
        return available_platforms
    
    def initialize_legacy_post_status(self, posts_dir: Path):
        """åˆå§‹åŒ–å­˜é‡å·²å‘å¸ƒæ–‡æ¡£çš„çŠ¶æ€"""
        if not posts_dir.exists():
            return
            
        legacy_count = 0
        for post_file in posts_dir.glob("*.md"):
            article_name = post_file.stem
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰çŠ¶æ€æ–‡ä»¶
            if self.get_status_file_path(article_name).exists():
                continue
                
            # ä¸ºå­˜é‡æ–‡æ¡£åˆ›å»ºçŠ¶æ€è®°å½•ï¼ˆé»˜è®¤å·²åœ¨github_pageså‘å¸ƒï¼‰
            self.update_published_platforms(article_name, ['github_pages'])
            legacy_count += 1
            
        if legacy_count > 0:
            logging.info(f"å·²ä¸º {legacy_count} ä¸ªå­˜é‡æ–‡æ¡£åˆå§‹åŒ–å‘å¸ƒçŠ¶æ€")
        
        return legacy_count

class ContentPipeline:
    _instance = None  # ç±»å±æ€§ç”¨äºå•ä¾‹æ¨¡å¼
    _initialized = False  # è®°å½•æ˜¯å¦å·²åˆå§‹åŒ–
    
    def __init__(self, config_path: str = "config/pipeline_config.yml", verbose: bool = False):
        """åˆå§‹åŒ–å†…å®¹å¤„ç†ç®¡é“
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        self.verbose = verbose
        self.logger = logging.getLogger("ContentPipeline")
        self.project_root = Path(__file__).parent.parent
        
        # åˆå§‹åŒ–APIçŠ¶æ€
        self.api_available = True
        
        # è®°å½•æ˜¯å¦æ˜¯é¦–æ¬¡åˆå§‹åŒ–
        self.is_first_init = not ContentPipeline._initialized
        
        # åŠ è½½é…ç½®
        try:
            # åŠ è½½ä¸»é…ç½®æ–‡ä»¶
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            self.logger.debug(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            
            # åŠ è½½å®Œæ•´é…ç½®ï¼ˆåŒ…æ‹¬å¯¼å…¥çš„é…ç½®æ–‡ä»¶ï¼‰
            self.config = self._load_config()
            
            # åˆå§‹åŒ–å‘å¸ƒçŠ¶æ€ç®¡ç†å™¨
            drafts_dir = Path(self.config["paths"]["drafts"])
            self.status_manager = PublishingStatusManager(drafts_dir)
            
            # åˆå§‹åŒ–å­˜é‡æ–‡æ¡£çŠ¶æ€
            posts_dir = Path(self.config["paths"]["posts"])
            self.status_manager.initialize_legacy_post_status(posts_dir)
            
            # åˆå§‹åŒ–å†…å®¹å˜ç°ç³»ç»Ÿç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
            self.reward_manager = None
            if RewardSystemManager:
                try:
                    self.reward_manager = RewardSystemManager()
                    self.logger.debug("å†…å®¹å˜ç°ç³»ç»Ÿç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    self.logger.warning(f"å†…å®¹å˜ç°ç³»ç»Ÿç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            else:
                self.logger.debug("å†…å®¹å˜ç°ç³»ç»Ÿæ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡åˆå§‹åŒ–")
            

        except Exception as e:
            self.logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}", exc_info=True)
            raise
        
        self._setup_logging()
        
        # åŠ è½½æ¨¡æ¿å’Œå¹³å°é…ç½®
        # æ£€æŸ¥æ˜¯å¦æœ‰post_templatesé”®ï¼Œå¦‚æœæ²¡æœ‰ä½†æœ‰front_matteré”®ï¼Œåˆ™ä½¿ç”¨front_matter
        if 'post_templates' in self.config:
            self.templates = self.config['post_templates']
        elif 'front_matter' in self.config:
            self.templates = {'front_matter': self.config['front_matter']}
            if 'categories' in self.config:
                self.templates['categories'] = self.config['categories']
            if 'footer' in self.config:
                self.templates['footer'] = self.config['footer']
            self.logger.debug("ä»é…ç½®ä¸­åŠ è½½æ¨¡æ¿æˆåŠŸ")
        else:
            self.templates = {}
            self.logger.warning("æœªåŠ è½½æ¨¡æ¿æˆ–æ¨¡æ¿ä¸ºç©º")
        
        self.platforms_config = self.config.get('platforms', {})
        
        # è®¾ç½®API
        self._setup_apis()
        self._setup_site_url()

        # åˆå§‹åŒ–å‘å¸ƒå™¨
        self.wechat_publisher = None
        try:
            if self.platforms_config.get("wechat", {}).get("enabled", False):
                # Pass the initialized Gemini model to the publisher
                self.wechat_publisher = WechatPublisher(gemini_model=self.model)
                self.log("âœ… å¾®ä¿¡å‘å¸ƒå™¨åˆå§‹åŒ–æˆåŠŸ", level="debug")
        except Exception as e:
            self.log(f"âš ï¸ å¾®ä¿¡å‘å¸ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}", level="warning")
            self.log("å¾®ä¿¡å‘å¸ƒåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†ä¸å½±å“å…¶ä»–åŠŸèƒ½", level="info")
        
        # æ ‡è®°åˆå§‹åŒ–å®Œæˆ
        ContentPipeline._initialized = True
        if self.is_first_init:
            self.log("ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ", level="info")
        
    def log(self, message: str, level: str = "info", force: bool = False):
        """ç»Ÿä¸€çš„æ—¥å¿—å¤„ç†
        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            level: æ—¥å¿—çº§åˆ« (debug/info/warning/error)
            force: æ˜¯å¦å¼ºåˆ¶æ˜¾ç¤ºï¼ˆå¿½ç•¥verboseè®¾ç½®ï¼‰
        """
        # ç»Ÿä¸€ä½¿ç”¨loggingç³»ç»Ÿï¼Œè®©å¤„ç†å™¨å†³å®šçº§åˆ«è¿‡æ»¤
        logger_method = getattr(self.logger, level, self.logger.info)
        
        # å¦‚æœforce=Trueæˆ–è€…æ˜¯é«˜çº§åˆ«æ—¥å¿—ï¼Œåˆ™ç›´æ¥è®°å½•
        if force or level in ["error", "warning"]:
            logger_method(message)
        elif level == "debug":
            # DEBUGçº§åˆ«åªåœ¨verboseæ¨¡å¼ä¸‹è®°å½•
            if self.verbose:
                logger_method(message)
        else:
            # INFOçº§åˆ«æ­£å¸¸è®°å½•
            logger_method(message)
    
    def _load_config(self) -> dict:
        """åŠ è½½æ‰€æœ‰é…ç½®"""
        config_dir = Path("config")
        config = {}
        
        try:
            # åŠ è½½ä¸»é…ç½®
            with open(config_dir / "pipeline_config.yml", 'r', encoding='utf-8') as f:
                config.update(yaml.safe_load(f))
            
            # åŠ è½½å¯¼å…¥çš„é…ç½®
            for import_file in config.get("imports", []):
                try:
                    with open(config_dir / import_file, 'r', encoding='utf-8') as f:
                        imported_config = yaml.safe_load(f)
                        if imported_config:
                            # é€’å½’æ›´æ–°é…ç½®ï¼Œä¿æŒåµŒå¥—ç»“æ„
                            self._deep_update(config, imported_config)
                            self.logger.debug(f"æˆåŠŸå¯¼å…¥é…ç½®: {import_file}")
                        else:
                            self.logger.warning(f"å¯¼å…¥çš„é…ç½®ä¸ºç©º: {import_file}")
                except FileNotFoundError:
                    self.logger.warning(f"å¯¼å…¥çš„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {import_file}")
                except yaml.YAMLError as e:
                    self.logger.warning(f"å¯¼å…¥çš„é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {import_file}, {str(e)}")
                    
            return config
            
        except FileNotFoundError as e:
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {e.filename}")
            raise
        except yaml.YAMLError as e:
            logging.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
            raise
    
    def _deep_update(self, d: dict, u: dict) -> dict:
        """é€’å½’æ›´æ–°å­—å…¸ï¼Œä¿æŒåµŒå¥—ç»“æ„"""
        for k, v in u.items():
            if isinstance(v, dict):
                d[k] = self._deep_update(d.get(k, {}), v)
            else:
                d[k] = v
        return d
    
    def _setup_logging(self):
        """é…ç½®æ—¥å¿—"""
        log_path = Path(self.config["paths"]["logs"])
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ¸…é™¤æ ¹è®°å½•å™¨çš„å¤„ç†å™¨ä»¥é¿å…é‡å¤è®°å½•
        root_logger = logging.getLogger()
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # æ–‡ä»¶å¤„ç†å™¨ - ä½¿ç”¨è½®è½¬å¤„ç†å™¨é˜²æ­¢æ—¥å¿—æ–‡ä»¶è¿‡å¤§
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            log_path, 
            maxBytes=1024*1024,  # 1MB
            backupCount=3,       # ä¿ç•™3ä¸ªå¤‡ä»½æ–‡ä»¶
            encoding='utf-8'
        )
        # åªè®°å½•INFOçº§åˆ«åŠä»¥ä¸Šçš„æ¶ˆæ¯åˆ°æ–‡ä»¶
        file_handler.setLevel(logging.INFO)
        file_formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
        file_handler.setFormatter(file_formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨ - æ ¹æ®è¯¦ç»†æ¨¡å¼å†³å®šçº§åˆ«
        console_handler = logging.StreamHandler()
        if self.verbose:
            console_handler.setLevel(logging.DEBUG)
        else:
            console_handler.setLevel(logging.WARNING)  # åªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯
        console_formatter = logging.Formatter("%(levelname)s - %(message)s")
        console_handler.setFormatter(console_formatter)
        
        # ä¸å†è®¾ç½®æ ¹è®°å½•å™¨çš„å¤„ç†å™¨ï¼Œåªä½¿ç”¨ContentPipelineç‰¹å®šè®°å½•å™¨
        
        # è®¾ç½®ContentPipelineç‰¹å®šçš„loggerï¼Œä½†ä¸æ·»åŠ é‡å¤å¤„ç†å™¨
        self.logger.setLevel(logging.DEBUG)
        # é˜²æ­¢æ¶ˆæ¯ä¼ æ’­åˆ°æ ¹è®°å½•å™¨ï¼Œé¿å…é‡å¤è®°å½•
        self.logger.propagate = False
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        # åªç»™ContentPipeline loggeræ·»åŠ å¤„ç†å™¨
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # è®°å½•åˆå§‹åŒ–çŠ¶æ€ï¼ˆä»…åœ¨è¯¦ç»†æ¨¡å¼ä¸‹ï¼‰
        if self.verbose:
            self.log("ğŸ“„ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ", level="debug")
    
    def _setup_apis(self):
        """è®¾ç½®APIå®¢æˆ·ç«¯"""
        load_dotenv(override=True)  # ç¡®ä¿é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        try:
            configure(api_key=api_key)
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åç§°
            model_name = self.config["content_processing"]["gemini"]["model"]
            if self.is_first_init:
                self.log(f"ä½¿ç”¨é…ç½®çš„æ¨¡å‹: {model_name}", level="info")
            else:
                self.log(f"ä½¿ç”¨é…ç½®çš„æ¨¡å‹: {model_name}", level="debug")
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.model = GenerativeModel(model_name)
            
            # æµ‹è¯•è¿æ¥
            try:
                response = self.model.generate_content(
                    "Test connection",
                    generation_config=GenerationConfig(
                        temperature=0.1,
                        max_output_tokens=10
                    )
                )
                if response:
                    if self.is_first_init:
                        self.log("âœ… Gemini API è¿æ¥æˆåŠŸ", level="info")
                    else:
                        self.log("âœ… Gemini API è¿æ¥æˆåŠŸ", level="debug")
                    
                    # éªŒè¯æ¨¡æ¿åŠ è½½
                    self._validate_templates()
            except ResourceExhausted as e:
                self.log(f"âŒ API é…é¢å·²è€—å°½ï¼Œè¯·ç¨åå†è¯•: {str(e)}", level="error", force=True)
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç¨‹åºç»§ç»­è¿è¡Œï¼Œä½†æ ‡è®°APIä¸å¯ç”¨
                self.api_available = False
            except Exception as e:
                self.log(f"âŒ Gemini API è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}", level="error", force=True)
                self.api_available = False
        except Exception as e:
            self.log(f"âŒ è®¾ç½®APIå¤±è´¥: {str(e)}", level="error", force=True)
            raise
            
    def _validate_templates(self):
        """éªŒè¯æ¨¡æ¿æ˜¯å¦æ­£ç¡®åŠ è½½"""
        if not hasattr(self, 'templates') or not self.templates:
            self.log("æœªåŠ è½½æ¨¡æ¿æˆ–æ¨¡æ¿ä¸ºç©º", level="warning")
            return
            
        self.log(f"å·²åŠ è½½æ¨¡æ¿: {list(self.templates.keys())}", level="debug")
        self.log(f"æ¨¡æ¿å†…å®¹: {self.templates}", level="debug")
        
        # éªŒè¯å‰ç«¯æ¨¡æ¿
        if 'front_matter' in self.templates:
            if 'default' in self.templates['front_matter']:
                default_template = self.templates['front_matter']['default']
                self.log(f"é»˜è®¤å‰ç«¯æ¨¡æ¿åŒ…å« {len(default_template)} ä¸ªè®¾ç½®", level="debug")
                # æ£€æŸ¥å…³é”®è®¾ç½®
                if 'toc' in default_template and default_template['toc']:
                    self.log("âœ… ç›®å½•è®¾ç½®å·²åŠ è½½", level="debug")
                else:
                    self.log("âš ï¸ ç›®å½•è®¾ç½®æœªåŠ è½½æˆ–æœªå¯ç”¨", level="warning")
            else:
                self.log("âš ï¸ æœªæ‰¾åˆ°é»˜è®¤å‰ç«¯æ¨¡æ¿", level="warning")
                self.log(f"å¯ç”¨çš„å‰ç«¯æ¨¡æ¿: {list(self.templates['front_matter'].keys())}", level="debug")
        else:
            self.log("âš ï¸ æœªæ‰¾åˆ°å‰ç«¯æ¨¡æ¿é…ç½®", level="warning")
            
        # éªŒè¯é¡µè„šæ¨¡æ¿
        if 'footer' in self.templates:
            footer_platforms = list(self.templates['footer'].keys())
            self.log(f"é¡µè„šæ¨¡æ¿å¹³å°: {footer_platforms}", level="debug")
            
            # æ£€æŸ¥GitHub Pagesé¡µè„š
            if 'github_pages' in self.templates['footer']:
                footer_content = self.templates['footer']['github_pages']
                if footer_content and len(footer_content) > 10:
                    self.log("âœ… GitHub Pagesé¡µè„šæ¨¡æ¿å·²åŠ è½½", level="debug")
                else:
                    self.log("âš ï¸ GitHub Pagesé¡µè„šæ¨¡æ¿ä¸ºç©ºæˆ–å†…å®¹è¿‡çŸ­", level="warning")
            else:
                self.log("âš ï¸ æœªæ‰¾åˆ°GitHub Pagesé¡µè„šæ¨¡æ¿", level="warning")
        else:
            self.log("âš ï¸ æœªæ‰¾åˆ°é¡µè„šæ¨¡æ¿é…ç½®", level="warning")
    
    def list_drafts(self) -> List[Path]:
        """åˆ—å‡ºæ‰€æœ‰è‰ç¨¿æ–‡ä»¶"""
        drafts_dir = Path(self.config["paths"]["drafts"])
        all_drafts = list(drafts_dir.glob("*.md"))
        
        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„è‰ç¨¿æ–‡ä»¶
        valid_drafts = []
        for draft in all_drafts:
            if self._is_valid_draft(draft):
                valid_drafts.append(draft)
            else:
                self.log(f"âš ï¸ è·³è¿‡æ— æ•ˆè‰ç¨¿: {draft.name}", level="warning")
        
        return valid_drafts
    
    def select_draft(self) -> Optional[Path]:
        """è®©ç”¨æˆ·é€‰æ‹©è¦å¤„ç†çš„è‰ç¨¿"""
        drafts = self.list_drafts()
        if not drafts:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°è‰ç¨¿æ–‡ä»¶")
            print("\nğŸ’¡ æç¤ºï¼š")
            print("   1. æ‚¨å¯ä»¥åœ¨ _drafts/ ç›®å½•åˆ›å»ºæ–°çš„ .md æ–‡ä»¶")
            print("   2. æˆ–è€…é€‰æ‹©ä¸»èœå•çš„ '3. ç”Ÿæˆæµ‹è¯•æ–‡ç« ' é€‰é¡¹")
            print("   3. æˆ–è€…ä½¿ç”¨ '2. é‡æ–°å‘å¸ƒå·²å‘å¸ƒæ–‡ç« ' å°†å·²å‘å¸ƒæ–‡ç« è½¬ä¸ºè‰ç¨¿")
            
            while True:
                choice = input("\næ˜¯å¦ç°åœ¨ç”Ÿæˆæµ‹è¯•æ–‡ç« ï¼Ÿ(y/N): ").strip().lower()
                if choice in ['y', 'yes']:
                    return self.generate_test_content()
                elif choice in ['n', 'no', '']:
                    return None
                else:
                    print("è¯·è¾“å…¥ y æˆ– N")
            
        print("\nå¯ç”¨çš„è‰ç¨¿æ–‡ä»¶ï¼š")
        for i, draft in enumerate(drafts, 1):
            print(f"{i}. {draft.name}")
        print("0. é€€å‡º")
            
        while True:
            try:
                choice = int(input("\nè¯·é€‰æ‹©è¦å¤„ç†çš„è‰ç¨¿ (è¾“å…¥åºå·ï¼Œ0é€€å‡º): "))
                if choice == 0:
                    return None
                if 1 <= choice <= len(drafts):
                    return drafts[choice-1]
                print("æ— æ•ˆçš„é€‰æ‹©")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def list_published_posts(self) -> List[Path]:
        """åˆ—å‡ºå·²å‘å¸ƒçš„æ–‡ç« """
        posts_dir = Path(self.config["paths"]["posts"])
        if not posts_dir.exists():
            return []
        
        posts = []
        for file in posts_dir.glob("*.md"):
            if file.is_file():
                posts.append(file)
        
        return sorted(posts, key=lambda x: x.stat().st_mtime, reverse=True)
    
    def select_published_post(self) -> Optional[Path]:
        """è®©ç”¨æˆ·é€‰æ‹©è¦é‡æ–°å‘å¸ƒçš„å·²å‘å¸ƒæ–‡ç« """
        posts = self.list_published_posts()
        if not posts:
            print("æ²¡æœ‰æ‰¾åˆ°å·²å‘å¸ƒçš„æ–‡ç« ")
            return None
            
        print("\nå¯ç”¨çš„å·²å‘å¸ƒæ–‡ç« ï¼š")
        for i, post in enumerate(posts, 1):
            # è·å–æ–‡ç« çš„å‘å¸ƒçŠ¶æ€
            article_name = post.stem
            published_platforms = self.status_manager.get_published_platforms(article_name)
            
            if published_platforms:
                platforms_str = ", ".join(published_platforms)
                print(f"{i}. {post.name} [å·²å‘å¸ƒ: {platforms_str}]")
            else:
                print(f"{i}. {post.name} [æœªå‘å¸ƒåˆ°ä»»ä½•å¹³å°]")
        print("0. é€€å‡º")
            
        while True:
            try:
                choice = int(input("\nè¯·é€‰æ‹©è¦é‡æ–°å‘å¸ƒçš„æ–‡ç«  (è¾“å…¥åºå·ï¼Œ0é€€å‡º): "))
                if choice == 0:
                    return None
                if 1 <= choice <= len(posts):
                    return posts[choice-1]
                print("æ— æ•ˆçš„é€‰æ‹©")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def copy_post_to_draft(self, post_path: Path) -> Optional[Path]:
        """å°†å·²å‘å¸ƒæ–‡ç« ä½œä¸ºæºæ–‡ä»¶å¤åˆ¶åˆ°è‰ç¨¿ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
        try:
            drafts_dir = Path(self.config["paths"]["drafts"])
            drafts_dir.mkdir(exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰åŒåè‰ç¨¿ï¼ˆæºæ–‡ä»¶ï¼‰
            original_draft_path = drafts_dir / post_path.name
            
            if original_draft_path.exists():
                # å¦‚æœè‰ç¨¿å·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨è‰ç¨¿ä½œä¸ºæºæ–‡ä»¶
                self.log(f"ä½¿ç”¨ç°æœ‰è‰ç¨¿ä½œä¸ºæºæ–‡ä»¶: {original_draft_path}", level="info", force=True)
                return original_draft_path
            else:
                # å¦‚æœè‰ç¨¿ä¸å­˜åœ¨ï¼Œä»å·²å‘å¸ƒæ–‡ç« åˆ›å»ºæºæ–‡ä»¶
                # éœ€è¦æ¸…ç†å‘å¸ƒæ—¶æ·»åŠ çš„å†…å®¹ï¼Œæ¢å¤ä¸ºæºæ–‡ä»¶æ ¼å¼
                source_content = self._convert_published_to_source(post_path)
                
                with open(original_draft_path, 'w', encoding='utf-8') as f:
                    f.write(source_content)
                
                self.log(f"å·²ä»å‘å¸ƒæ–‡ç« åˆ›å»ºæºæ–‡ä»¶: {original_draft_path}", level="info", force=True)
                return original_draft_path
            
        except Exception as e:
            self.log(f"å¤„ç†æ–‡ç« æºæ–‡ä»¶å¤±è´¥: {str(e)}", level="error", force=True)
            return None
    
    def _convert_published_to_source(self, post_path: Path) -> str:
        """å°†å·²å‘å¸ƒæ–‡ç« è½¬æ¢å›æºæ–‡ä»¶æ ¼å¼"""
        try:
            with open(post_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æfront matter
            post = frontmatter.loads(content)
            
            # ç§»é™¤å‘å¸ƒæ—¶è‡ªåŠ¨æ·»åŠ çš„å­—æ®µ
            auto_generated_fields = [
                'layout', 'author_profile', 'breadcrumbs', 'comments', 
                'related', 'share', 'toc', 'toc_icon', 'toc_label', 
                'toc_sticky', 'last_modified_at'
            ]
            
            for field in auto_generated_fields:
                if field in post.metadata:
                    del post.metadata[field]
            
            # ç§»é™¤é¡µè„šå†…å®¹ï¼ˆä»æœ€åä¸€ä¸ª "---" å¼€å§‹çš„éƒ¨åˆ†ï¼‰
            content_lines = post.content.split('\n')
            footer_start = -1
            
            # ä»åå¾€å‰æŸ¥æ‰¾é¡µè„šåˆ†éš”ç¬¦
            for i in range(len(content_lines) - 1, -1, -1):
                if content_lines[i].strip() == '---' and i < len(content_lines) - 5:
                    # æ£€æŸ¥åé¢å‡ è¡Œæ˜¯å¦åŒ…å«é¡µè„šç‰¹å¾ï¼ˆå¦‚"å­¦ä¹ åˆ†äº«å£°æ˜"æˆ–"è¯·æˆ‘å–å’–å•¡"ï¼‰
                    footer_section = '\n'.join(content_lines[i:])
                    if any(keyword in footer_section for keyword in 
                          ['å­¦ä¹ åˆ†äº«å£°æ˜', 'è¯·æˆ‘å–å’–å•¡', 'Buy Me A Coffee', 'å‘è¡¨è¯„è®º']):
                        footer_start = i
                        break
            
            if footer_start > 0:
                post.content = '\n'.join(content_lines[:footer_start]).rstrip()
            
            # é‡æ–°ç»„è£…ä¸ºsourceæ ¼å¼
            return frontmatter.dumps(post)
            
        except Exception as e:
            self.log(f"è½¬æ¢å‘å¸ƒæ–‡ç« ä¸ºæºæ–‡ä»¶å¤±è´¥: {str(e)}", level="warning")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå†…å®¹
            with open(post_path, 'r', encoding='utf-8') as f:
                return f.read()
    
    def select_platforms(self, draft_path: Optional[Path] = None) -> List[str]:
        """è®©ç”¨æˆ·é€‰æ‹©å‘å¸ƒå¹³å°ï¼Œæ”¯æŒåŸºäºå‘å¸ƒçŠ¶æ€çš„è¿‡æ»¤"""
        all_platforms = [name for name, config in self.config["platforms"].items() 
                        if config.get("enabled", False)]
        
        if draft_path:
            # è·å–æ–‡ç« åç§°
            article_name = draft_path.stem
            
            # è·å–å·²å‘å¸ƒå¹³å°å’Œå¯ç”¨å¹³å°
            published_platforms = self.status_manager.get_published_platforms(article_name)
            available_platforms = self.status_manager.get_available_platforms(article_name, all_platforms)
            
            if published_platforms:
                print(f"\næ–‡ç«  '{article_name}' å·²å‘å¸ƒå¹³å°: {', '.join(published_platforms)}")
            
            if not available_platforms:
                print("è¯¥æ–‡ç« å·²åœ¨æ‰€æœ‰å¯ç”¨çš„å¹³å°å‘å¸ƒ")
                return []
                
            print("\nå¯é€‰çš„å‘å¸ƒå¹³å°ï¼š")
            for i, platform in enumerate(available_platforms, 1):
                print(f"{i}. {platform}")
            print("0. é€€å‡º")
                
            platform_list = available_platforms
        else:
            # æ–°æ–‡ç« ï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨å¹³å°
            print("\nå¯ç”¨çš„å‘å¸ƒå¹³å°ï¼š")
            for i, platform in enumerate(all_platforms, 1):
                print(f"{i}. {platform}")
            print("0. é€€å‡º")
                
            platform_list = all_platforms
            
        if not platform_list:
            return []
            
        selections = input("\nè¯·é€‰æ‹©å‘å¸ƒå¹³å° (å¤šä¸ªå¹³å°ç”¨é€—å·åˆ†éš”ï¼Œ0é€€å‡º): ").split(",")
        selected_platforms = []
        
        for sel in selections:
            sel_stripped = sel.strip()
            if not sel_stripped:  # è·³è¿‡ç©ºå­—ç¬¦ä¸²
                continue
            try:
                idx = int(sel_stripped)
                if idx == 0:
                    return []  # ç”¨æˆ·é€‰æ‹©é€€å‡º
                elif 1 <= idx <= len(platform_list):
                    selected_platforms.append(platform_list[idx - 1])
                else:
                    print(f"æ— æ•ˆé€‰æ‹©: {sel_stripped}")
            except ValueError:
                print(f"æ— æ•ˆè¾“å…¥: {sel_stripped}")
                
        return selected_platforms
    
    def ask_monetization_preference(self) -> bool:
        """è¯¢é—®ç”¨æˆ·æ˜¯å¦å¯ç”¨å†…å®¹å˜ç°åŠŸèƒ½"""
        if not self.reward_manager:
            return False
        
        print("\nğŸ’° å†…å®¹å˜ç°é€‰é¡¹ï¼š")
        print("  1. å¯ç”¨ - è‡ªåŠ¨ç”Ÿæˆèµ„æ–™åŒ…å¹¶ä¸Šä¼ åˆ°GitHub Release")
        print("  2. è·³è¿‡ - ä»…è¿›è¡Œå¸¸è§„å‘å¸ƒ")
        
        try:
            choice = input("\nè¯·é€‰æ‹© (1/2ï¼Œé»˜è®¤ä¸º2): ").strip()
            
            if choice == "1":
                print("âœ… å·²å¯ç”¨å†…å®¹å˜ç°åŠŸèƒ½")
                return True
            else:
                print("â­ï¸  è·³è¿‡å†…å®¹å˜ç°åŠŸèƒ½")
                return False
        except (EOFError, KeyboardInterrupt):
            print("\nâ­ï¸  è·³è¿‡å†…å®¹å˜ç°åŠŸèƒ½")
            return False
    
    def process_draft(self, draft_path: Path, platforms: List[str], enable_monetization: bool = False) -> dict:
        """å¤„ç†è‰ç¨¿æ–‡ä»¶"""
        try:
            self.log(f"============================== å¼€å§‹å¤„ç†è‰ç¨¿ ==============================", force=True)
            self.log(f"è‰ç¨¿æ–‡ä»¶: {draft_path}", force=True)
            
            all_success = True  # è·Ÿè¸ªæ‰€æœ‰æ“ä½œæ˜¯å¦æˆåŠŸ
            console = Console()
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console,
            ) as progress:
                # 1. è¯»å–å†…å®¹
                task = progress.add_task("ğŸ“– è¯»å–æ–‡ç« å†…å®¹...", total=None)
                with open(draft_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                progress.update(task, completed=True)
                
                # æ£€æŸ¥å†…å®¹å®Œæ•´æ€§
                if len(content) < 100:
                    self.log("âŒ æ–‡ç« å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´", level="error", force=True)
                    return {
                        'success': False,
                        'successful_platforms': [],
                        'total_platforms': len(platforms),
                        'published_platforms': [],
                        'article_name': draft_path.stem,
                        'error': 'æ–‡ç« å†…å®¹è¿‡çŸ­'
                    }
                
                # é¢„å¤„ç† front matter ä¸­çš„å¼•å·é—®é¢˜
                try:
                    # å°è¯•è§£æ front matter
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âš ï¸ Front matter è§£æé”™è¯¯: {str(e)}", level="warning")
                    # å°è¯•ä¿®å¤å¸¸è§çš„å¼•å·é—®é¢˜
                    content = self._fix_frontmatter_quotes(content)
                    try:
                        post = frontmatter.loads(content)
                    except Exception as e:
                        self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                        return {
                            'success': False,
                            'successful_platforms': [],
                            'total_platforms': len(platforms),
                            'published_platforms': [],
                            'article_name': draft_path.stem,
                            'error': f'front matterè§£æå¤±è´¥: {str(e)}'
                        }
                
                # 2. å›¾ç‰‡å¤„ç†æ­¥éª¤ï¼ˆå·²ç§»é™¤Cloudflare ImagesåŠŸèƒ½ï¼‰
                progress.update(progress.add_task("ğŸ–¼ï¸ å›¾ç‰‡å¤„ç†ï¼ˆè·³è¿‡ï¼‰", total=1), completed=True)
                
                # 3. æ¶¦è‰²å†…å®¹
                task = progress.add_task("âœ¨ æ¶¦è‰²æ–‡ç« å†…å®¹...", total=None)
                polished_content = self._polish_content(content)
                if not polished_content:
                    self.log("âŒ å†…å®¹æ¶¦è‰²å¤±è´¥ï¼Œä½¿ç”¨åŸå†…å®¹", level="warning", force=True)
                    polished_content = content
                progress.update(task, completed=True)
                
                # 4. ç”Ÿæˆå„å¹³å°å†…å®¹
                platform_contents = {}
                platform_success = {}  # è·Ÿè¸ªæ¯ä¸ªå¹³å°çš„å¤„ç†ç»“æœ
                
                for platform in platforms:
                    task = progress.add_task(f"ğŸ“ å¤„ç† {platform} å¹³å°...", total=None)
                    try:
                        platform_content = self._generate_platform_content(
                            polished_content,
                            platform,
                            draft_path
                        )
                        
                        # éªŒè¯å†…å®¹å®Œæ•´æ€§
                        if len(platform_content) < len(polished_content) * 0.9:
                            self.log(f"âŒ {platform}å¹³å°å†…å®¹å¯èƒ½ä¸å®Œæ•´", level="error", force=True)
                            platform_success[platform] = False
                        else:
                            platform_contents[platform] = platform_content
                            platform_success[platform] = True
                    except ValueError as e:
                        # å¤„ç†å¿…éœ€å­—æ®µéªŒè¯å¤±è´¥
                        self.log(f"âŒ {platform}å¹³å°å¤„ç†å¤±è´¥: {str(e)}", level="error", force=True)
                        platform_success[platform] = False
                        all_success = False
                    except Exception as e:
                        # å¤„ç†å…¶ä»–é”™è¯¯
                        self.log(f"âŒ {platform}å¹³å°å¤„ç†å‡ºé”™: {str(e)}", level="error", force=True)
                        platform_success[platform] = False
                        all_success = False
                    
                    progress.update(task, completed=True)
                
                # 5. å‘å¸ƒå†…å®¹
                for platform, content in platform_contents.items():
                    if not platform_success.get(platform, False):
                        continue
                        
                    task = progress.add_task(f"ğŸš€ å‘å¸ƒåˆ° {platform}...", total=None)
                    if platform == "github_pages":
                        publish_success = self._publish_to_github_pages(draft_path, content)
                        platform_success[platform] = publish_success
                    elif platform == "wechat":
                        publish_success = self._publish_to_wechat(content)
                        platform_success[platform] = publish_success
                    elif platform == "wordpress":
                        publish_success = self._publish_to_wordpress(content)
                        platform_success[platform] = publish_success
                    progress.update(task, completed=True)
                
                # æ£€æŸ¥æ‰€æœ‰å¹³å°æ˜¯å¦éƒ½æˆåŠŸ
                all_success = all_success and all(platform_success.values())
                
                # 6. æ›´æ–°å‘å¸ƒçŠ¶æ€
                successful_platforms = [platform for platform, success in platform_success.items() if success]
                if successful_platforms:
                    task = progress.add_task("ğŸ“Š æ›´æ–°å‘å¸ƒçŠ¶æ€...", total=None)
                    article_name = draft_path.stem
                    self.status_manager.update_published_platforms(article_name, successful_platforms)
                    self.log(f"å·²æ›´æ–°å‘å¸ƒçŠ¶æ€: {successful_platforms}", level="info", force=True)
                    progress.update(task, completed=True)
                
                # 7. å½’æ¡£è‰ç¨¿ï¼ˆä»…å½“é¦–æ¬¡å‘å¸ƒä¸”å…¨éƒ¨æˆåŠŸæ—¶ï¼‰
                published_platforms = self.status_manager.get_published_platforms(draft_path.stem)
                all_enabled_platforms = [name for name, config in self.config["platforms"].items() 
                                        if config.get("enabled", False)]
                
                # å¦‚æœå·²åœ¨æ‰€æœ‰å¯ç”¨å¹³å°å‘å¸ƒï¼Œåˆ™å½’æ¡£è‰ç¨¿
                archived_file_path = None
                if set(published_platforms) >= set(all_enabled_platforms):
                    task = progress.add_task("ğŸ“¦ å½’æ¡£è‰ç¨¿...", total=None)
                    archived_file_path = self._archive_draft(draft_path)
                    progress.update(task, completed=True)
                elif not all_success:
                    self.log("âš ï¸ å¤„ç†æœªå®Œå…¨æˆåŠŸï¼Œè·³è¿‡å½’æ¡£æ­¥éª¤", level="warning", force=True)
                else:
                    # è®¡ç®—æœªå‘å¸ƒçš„å¹³å°
                    unpublished_platforms = set(all_enabled_platforms) - set(published_platforms)
                    self.log(f"ğŸ’¾ å·²å‘å¸ƒåˆ°: {', '.join(published_platforms) if published_platforms else 'æ— '}", level="info", force=True)
                    self.log(f"ğŸ“‹ æœªå‘å¸ƒå¹³å°: {', '.join(unpublished_platforms)} (å¯ç¨åå‘å¸ƒ)", level="info", force=True)
                
            # å†…å®¹å˜ç°å¤„ç†
            monetization_result = None
            if enable_monetization and self.reward_manager and all_success:
                try:
                    task = progress.add_task("ğŸ’° åˆ›å»ºå†…å®¹å˜ç°åŒ…...", total=None)
                    
                    # ä½¿ç”¨å·²å‘å¸ƒçš„æ–‡ç« è·¯å¾„ï¼ˆå¦‚æœå·²å‘å¸ƒåˆ°GitHub Pagesï¼‰
                    if 'github' in published_platforms:
                        # ä½¿ç”¨_postsç›®å½•ä¸­çš„æ–‡ç« 
                        posts_dir = Path(self.config["paths"]["posts"])
                        # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä¸ç®¡æ˜¯å¦å·²å½’æ¡£
                        original_filename = archived_file_path.name if archived_file_path else draft_path.name
                        published_article_path = posts_dir / original_filename
                        
                        if published_article_path.exists():
                            monetization_success, monetization_data = self.reward_manager.create_article_package(
                                str(published_article_path), 
                                upload_to_github=True
                            )
                            
                            if monetization_success:
                                monetization_result = {
                                    'success': True,
                                    'package_path': monetization_data.get('package_path'),
                                    'github_release': monetization_data.get('github_release', {})
                                }
                                self.log(f"âœ… å†…å®¹å˜ç°åŒ…åˆ›å»ºæˆåŠŸ", level="info", force=True)
                                if monetization_data.get('github_release', {}).get('success'):
                                    download_url = monetization_data['github_release']['download_url']
                                    self.log(f"ğŸ“¦ ä¸‹è½½é“¾æ¥: {download_url}", level="info", force=True)
                            else:
                                monetization_result = {
                                    'success': False,
                                    'error': monetization_data.get('error', 'æœªçŸ¥é”™è¯¯')
                                }
                                self.log(f"âš ï¸ å†…å®¹å˜ç°åŒ…åˆ›å»ºå¤±è´¥: {monetization_data.get('error')}", level="warning", force=True)
                        else:
                            self.log(f"âš ï¸ å·²å‘å¸ƒæ–‡ç« æœªæ‰¾åˆ°: {published_article_path}", level="warning", force=True)
                    else:
                        # ä½¿ç”¨è‰ç¨¿æ–‡ä»¶æˆ–å½’æ¡£æ–‡ä»¶
                        source_file_path = archived_file_path if archived_file_path and archived_file_path.exists() else draft_path
                        
                        if not source_file_path.exists():
                            self.log(f"âš ï¸ æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file_path}", level="warning", force=True)
                            monetization_result = {
                                'success': False,
                                'error': f'æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file_path}'
                            }
                        else:
                            monetization_success, monetization_data = self.reward_manager.create_article_package(
                                str(source_file_path), 
                                upload_to_github=True
                            )
                            
                            if monetization_success:
                                monetization_result = {
                                    'success': True,
                                    'package_path': monetization_data.get('package_path'),
                                    'github_release': monetization_data.get('github_release', {})
                                }
                                self.log(f"âœ… å†…å®¹å˜ç°åŒ…åˆ›å»ºæˆåŠŸ", level="info", force=True)
                                if monetization_data.get('github_release', {}).get('success'):
                                    download_url = monetization_data['github_release']['download_url']
                                    self.log(f"ğŸ“¦ ä¸‹è½½é“¾æ¥: {download_url}", level="info", force=True)
                            else:
                                monetization_result = {
                                    'success': False,
                                    'error': monetization_data.get('error', 'æœªçŸ¥é”™è¯¯')
                                }
                                self.log(f"âš ï¸ å†…å®¹å˜ç°åŒ…åˆ›å»ºå¤±è´¥: {monetization_data.get('error')}", level="warning", force=True)
                    
                    progress.update(task, completed=True)
                    
                except Exception as e:
                    monetization_result = {
                        'success': False,
                        'error': str(e)
                    }
                    self.log(f"âŒ å†…å®¹å˜ç°å¤„ç†å¼‚å¸¸: {str(e)}", level="error", force=True)
                
            # è¿”å›è¯¦ç»†çš„å‘å¸ƒç»“æœ
            result = {
                'success': all_success,
                'successful_platforms': successful_platforms if 'successful_platforms' in locals() else [],
                'total_platforms': len(platforms),
                'published_platforms': published_platforms if 'published_platforms' in locals() else [],
                'article_name': draft_path.stem,
                'monetization': monetization_result
            }
            return result
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è‰ç¨¿æ—¶å‡ºé”™: {str(e)}")
            return {
                'success': False,
                'successful_platforms': [],
                'total_platforms': len(platforms),
                'published_platforms': [],
                'article_name': draft_path.stem,
                'error': str(e)
            }
    
    def _preprocess_content(self, text: str) -> str:
        """é¢„å¤„ç†å†…å®¹ï¼Œå¤„ç†ç‰¹æ®Šæ ¼å¼"""
        lines = text.split('\n')
        for i, line in enumerate(lines):
            if line.strip().startswith('excerpt:'):
                # å°†å•è¡Œ excerpt è½¬æ¢ä¸ºå¤šè¡Œæ ¼å¼
                content = line.split(':', 1)[1].strip().strip('"')
                lines[i] = 'excerpt: |'
                lines.insert(i + 1, '  ' + content)
        return '\n'.join(lines)
    
    def _fix_frontmatter_quotes(self, content: str) -> str:
        """ä¿®å¤ front matter ä¸­çš„å¼•å·é—®é¢˜"""
        # åˆ†ç¦» front matter å’Œæ­£æ–‡
        parts = content.split('---', 2)
        if len(parts) < 3:
            self.log("âŒ æ— æ³•è¯†åˆ« front matterï¼Œæ ¼å¼å¯èƒ½ä¸æ­£ç¡®", level="error")
            return content
        
        front_matter = parts[1]
        body = parts[2]
        
        # å¤„ç† front matter ä¸­çš„å¼•å·é—®é¢˜
        lines = front_matter.split('\n')
        for i, line in enumerate(lines):
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip()
                
                # å¤„ç† excerpt å­—æ®µ
                if key == 'excerpt' and value.startswith('"') and '"' in value[1:]:
                    # å°† excerpt è½¬æ¢ä¸ºå¤šè¡Œæ ¼å¼
                    lines[i] = 'excerpt: |'
                    # å»æ‰å¼•å·ï¼Œæ·»åŠ ç¼©è¿›
                    clean_value = value.strip('"')
                    lines.insert(i + 1, '  ' + clean_value)
                
                # å¤„ç†å…¶ä»–åŒ…å«å¼•å·çš„å­—æ®µ
                elif '"' in value and not (value.startswith('"') and value.endswith('"')):
                    # ä½¿ç”¨ | è¯­æ³•å¤„ç†å¤šè¡Œå†…å®¹
                    lines[i] = f'{key}: |'
                    lines.insert(i + 1, '  ' + value.strip('"'))
        
        # é‡æ–°ç»„åˆå†…å®¹
        fixed_front_matter = '\n'.join(lines)
        return f"---\n{fixed_front_matter}\n---{body}"
    
    def _polish_content(self, content: str) -> Optional[str]:
        """ä½¿ç”¨AIæ¶¦è‰²æ–‡ç« å†…å®¹"""
        if not self.api_available:
            self.log("APIä¸å¯ç”¨ï¼Œè·³è¿‡æ¶¦è‰²", level="warning")
            return content
        
        try:
            # è§£æfront matter
            try:
                post = frontmatter.loads(content)
            except Exception as e:
                self.log(f"è§£æfront matterå¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤
                content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"ä¿®å¤åä»æ— æ³•è§£æfront matter: {str(e)}", level="error")
                    return content
            
            # æå–æ­£æ–‡å†…å®¹
            content_text = post.content
            
            # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œä¸è¿›è¡Œæ¶¦è‰²
            if len(content_text) < 100:
                self.log("å†…å®¹å¤ªçŸ­ï¼Œä¸è¿›è¡Œæ¶¦è‰²", level="warning")
                return content
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""
            è¯·å¯¹ä»¥ä¸‹æ–‡ç« å†…å®¹è¿›è¡Œæ¶¦è‰²ï¼Œä½¿å…¶æ›´åŠ æµç•…ã€æ˜“è¯»ï¼ŒåŒæ—¶ä¿æŒåŸæ–‡çš„æ ¸å¿ƒæ€æƒ³å’Œä¿¡æ¯ã€‚
            ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è¯„è®ºæˆ–å‰è¨€ï¼Œç›´æ¥è¿”å›æ¶¦è‰²åçš„å†…å®¹ã€‚
            ä¸è¦ä¿®æ”¹æ–‡ç« çš„ç»“æ„æˆ–æ·»åŠ æ–°çš„ç« èŠ‚ã€‚
            
            {content_text}
            """
            
            # è°ƒç”¨API
            response = self.model.generate_content(prompt)
            
            if response and response.text:
                # æ›´æ–°å†…å®¹
                post.content = response.text.strip()
                return frontmatter.dumps(post)
            else:
                self.log("APIè¿”å›ä¸ºç©º", level="warning")
                return content
            
        except ResourceExhausted as e:
            self.log(f"APIé…é¢å·²ç”¨å°½: {str(e)}", level="error", force=True)
            self.api_available = False
            return content
        except Exception as e:
            self.log(f"æ¶¦è‰²å†…å®¹æ—¶å‡ºé”™: {str(e)}", level="error")
            return content
    
    def _validate_required_fields(self, post: frontmatter.Post) -> Tuple[bool, List[str]]:
        """éªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
        
        Args:
            post: frontmatter.Postå¯¹è±¡
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦é€šè¿‡éªŒè¯, ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨)
        """
        required_fields = ['title', 'date', 'header']
        missing_fields = []
        
        for field in required_fields:
            if field not in post or not post[field]:
                missing_fields.append(field)
        
        return len(missing_fields) == 0, missing_fields

    def _generate_excerpt(self, content: str) -> str:
        """ç”Ÿæˆæ–‡ç« æ‘˜è¦
        
        Args:
            content: æ–‡ç« å†…å®¹
            
        Returns:
            str: ç”Ÿæˆçš„æ‘˜è¦
        """
        try:
            if not self.api_available:
                self.log("APIä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦", level="warning")
                return ""
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""
è¯·ä¸ºä»¥ä¸‹æ–‡ç« ç”Ÿæˆä¸€ä¸ª50å­—å·¦å³çš„æ‘˜è¦ï¼Œè¦æ±‚ï¼š
1. å‡†ç¡®æ¦‚æ‹¬æ–‡ç« ä¸»è¦å†…å®¹
2. è¯­è¨€ç®€æ´æ˜äº†
3. å¸å¼•è¯»è€…é˜…è¯»
4. å­—æ•°æ§åˆ¶åœ¨50å­—å·¦å³

æ–‡ç« å†…å®¹ï¼š
{content[:2000]}  # åªå–å‰2000å­—ç¬¦é¿å…è¿‡é•¿
"""
            
            # è°ƒç”¨APIç”Ÿæˆæ‘˜è¦
            model = GenerativeModel(self.config['content_processing']['gemini']['model'])
            response = model.generate_content(
                prompt,
                generation_config=GenerationConfig(
                    temperature=0.7,
                    max_output_tokens=200,  # æ‘˜è¦ä¸éœ€è¦å¤ªé•¿
                    top_p=0.8,
                ),
                safety_settings=[
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                ]
            )
            
            # æ£€æŸ¥finish_reason
            if response and hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason') and candidate.finish_reason != 1:  # 1 = STOP (æ­£å¸¸å®Œæˆ)
                    self.log(f"APIå“åº”è¢«è¿‡æ»¤ï¼Œfinish_reason: {candidate.finish_reason}", level="warning")
                    return ""
            
            if response and hasattr(response, 'text') and response.text:
                excerpt = response.text.strip()
                self.log(f"ç”Ÿæˆæ‘˜è¦: {excerpt}", level="info")
                return excerpt
            elif response and hasattr(response, 'parts') and response.parts:
                # å°è¯•ä»partsè·å–æ–‡æœ¬
                text_parts = [part.text for part in response.parts if hasattr(part, 'text')]
                if text_parts:
                    excerpt = ''.join(text_parts).strip()
                    self.log(f"ç”Ÿæˆæ‘˜è¦: {excerpt}", level="info")
                    return excerpt
            
            self.log("APIæœªè¿”å›æœ‰æ•ˆæ‘˜è¦", level="warning")
            return ""
                
        except Exception as e:
            self.log(f"ç”Ÿæˆæ‘˜è¦æ—¶å‡ºé”™: {str(e)}", level="error")
            return ""

    def _generate_platform_content(self, content: str, platform: str, draft_path: Path) -> str:
        """ä¸ºç‰¹å®šå¹³å°ç”Ÿæˆå†…å®¹"""
        try:
            # è·å–å¹³å°é…ç½®
            platform_config = self.platforms_config.get(platform, {})
            
            # å°è¯•è§£æå†…å®¹
            try:
                post = frontmatter.loads(content)
            except Exception as e:
                self.log(f"âš ï¸ è§£æ front matter å¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤ front matter
                content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                    return content
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            is_valid, missing_fields = self._validate_required_fields(post)
            if not is_valid:
                self.log(f"âŒ è‰ç¨¿ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}", level="error", force=True)
                self.log(f"å¿…éœ€å­—æ®µåŒ…æ‹¬: title, date, header", level="error", force=True)
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
            
            # ç¡®ä¿å†…å®¹å®Œæ•´æ€§
            if not post.content:
                self.log("âŒ æ–‡ç« å†…å®¹ä¸ºç©º", level="error", force=True)
                return content
            content_text = post.content
            
            # åº”ç”¨é»˜è®¤æ¨¡æ¿ï¼ˆå¼ºåˆ¶è¦†ç›–è‡ªåŠ¨ç”Ÿæˆå­—æ®µï¼‰
            default_template = self.templates.get('front_matter', {}).get('default', {})
            for key, value in default_template.items():
                post[key] = value  # å¼ºåˆ¶è¦†ç›–ï¼Œä¸æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                self.log(f"åº”ç”¨é»˜è®¤æ¨¡æ¿: {key}={value}", level="info")
            
            # æ·»åŠ æˆ–æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            post['last_modified_at'] = current_time
            self.log(f"æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´: {current_time}", level="info")
            
            # æ™ºèƒ½å¤„ç†excerptå­—æ®µ
            if 'excerpt' not in post or not post['excerpt']:
                generated_excerpt = self._generate_excerpt(content_text)
                if generated_excerpt:
                    post['excerpt'] = generated_excerpt
                    self.log(f"ç”Ÿæˆæ–‡ç« æ‘˜è¦: {generated_excerpt}", level="info")
                else:
                    self.log("æœªèƒ½ç”Ÿæˆæ‘˜è¦", level="warning")
            else:
                excerpt_text = str(post.get('excerpt', ''))
                if excerpt_text:
                    self.log(f"ä¿ç•™ç°æœ‰æ‘˜è¦: {excerpt_text[:50]}...", level="info")
                else:
                    self.log("ç°æœ‰æ‘˜è¦ä¸ºç©º", level="warning")
            
            # å¤„ç†authorå­—æ®µï¼ˆå¦‚æœauthor_profileä¸ºtrueï¼Œç§»é™¤authorå­—æ®µä»¥é¿å…é‡å¤ï¼‰
            if post.get('author_profile', False) and 'author' in post:
                del post['author']
                self.log("ç§»é™¤å†—ä½™çš„authorå­—æ®µ", level="info")
            # å¦‚æœéœ€è¦è®¾ç½®ä½œè€…ä¿¡æ¯ä¸”author_profileä¸å­˜åœ¨ï¼Œåˆ™è®¾ç½®author
            elif platform_config.get('author', None) and not post.get('author_profile', False):
                post['author'] = platform_config.get('author')
                self.log(f"è®¾ç½®ä½œè€…: {post['author']}", level="info")
            
            
            # åˆ†æåˆ†ç±»å’Œæ ‡ç­¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if platform_config.get('analyze_content', True):
                # åˆ†æå†…å®¹è·å–åˆ†ç±»å’Œæ ‡ç­¾
                categories, tags = self._analyze_content_categories(content_text)
                
                # å§‹ç»ˆæ›´æ–°åˆ†ç±»
                if categories:
                    post['categories'] = categories
                    self.log(f"æ·»åŠ åˆ†ç±»: {categories}", level="info")
                
                # ä»…åœ¨æ²¡æœ‰tagsæ—¶æ‰æ·»åŠ AIç”Ÿæˆçš„tags
                if tags and ('tags' not in post or not post['tags']):
                    post['tags'] = tags
                    self.log(f"æ·»åŠ æ ‡ç­¾: {tags}", level="info")
                elif 'tags' in post and post['tags']:
                    self.log(f"ä¿ç•™ç°æœ‰æ ‡ç­¾: {post['tags']}", level="info")
            
            # æ¶¦è‰²å†…å®¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if platform_config.get('polish_content', True):
                polished_content = self._polish_content(content_text)
                if polished_content:
                    content_text = polished_content
            
            # æ·»åŠ é¡µè„šï¼ˆå¦‚æœéœ€è¦ï¼‰
            if platform_config.get('append_footer', False):
                # è·å–é¡µè„šæ¨¡æ¿
                footer_template = self.templates.get('footer', {}).get(platform, '')
                self.log(f"é¡µè„šæ¨¡æ¿: {footer_template[:50]}...", level="info")
                
                if footer_template:
                    # ç¡®ä¿é¡µè„šå‰æœ‰è¶³å¤Ÿçš„ç©ºè¡Œ
                    if not content_text.endswith('\n\n'):
                        content_text = content_text.rstrip() + '\n\n'
                    
                    content_text = f"{content_text}{footer_template}"
                    self.log(f"æ·»åŠ é¡µè„šæˆåŠŸ", level="info", force=True)
                else:
                    self.log(f"æœªæ‰¾åˆ°å¹³å° {platform} çš„é¡µè„šæ¨¡æ¿", level="warning", force=True)
            
            # æ›´æ–°å†…å®¹
            post.content = content_text
            
            # éªŒè¯å†…å®¹å®Œæ•´æ€§
            result = frontmatter.dumps(post)
            if len(result) < len(content) * 0.9:  # å¦‚æœå†…å®¹å‡å°‘è¶…è¿‡10%
                self.log("âš ï¸ è­¦å‘Šï¼šç”Ÿæˆçš„å†…å®¹å¯èƒ½ä¸å®Œæ•´", level="warning", force=True)
            
            # ç¡®ä¿layoutå­—æ®µåœ¨frontmatterçš„ç¬¬ä¸€è¡Œ
            if 'layout' in post:
                # ä½¿ç”¨OrderedDictç¡®ä¿layoutå­—æ®µåœ¨æœ€å‰é¢
                from collections import OrderedDict
                ordered_post = OrderedDict()
                ordered_post["layout"] = post["layout"]
                
                # æ·»åŠ å…¶ä»–å­—æ®µï¼ˆé™¤äº†layoutå’Œcontentï¼‰
                for key, value in post.metadata.items():
                    if key != 'layout':
                        ordered_post[key] = value
                
                # åˆ›å»ºæ–°çš„Postå¯¹è±¡å¹¶è®¾ç½®å†…å®¹
                final_post = frontmatter.Post(post.content, **ordered_post)
                result = frontmatter.dumps(final_post)
            
            return result
            
        except Exception as e:
            self.log(f"ç”Ÿæˆ{platform}å†…å®¹æ—¶å‡ºé”™: {str(e)}", level="error", force=True)
            return content
    
    def _publish_contents(self, draft_path: Path, 
                         platform_contents: Dict[str, str]):
        """å‘å¸ƒå†…å®¹åˆ°å„å¹³å°"""
        for platform, content in platform_contents.items():
            if platform == "github_pages":
                self._publish_to_github_pages(draft_path, content)
            elif platform == "wechat":
                self._publish_to_wechat(content)
            elif platform == "wordpress":
                self._publish_to_wordpress(content)
                
    def _archive_draft(self, draft_path: Path):
        """å½’æ¡£å·²å¤„ç†çš„è‰ç¨¿"""
        try:
            archive_dir = Path(self.config["paths"]["archive"])
            archive_dir.mkdir(parents=True, exist_ok=True)
            
            new_path = archive_dir / draft_path.name
            if new_path.exists():
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                new_path = archive_dir / f"{draft_path.stem}_{timestamp}{draft_path.suffix}"
                logging.info(f"ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨æ—¶é—´æˆ³é‡å‘½å: {new_path.name}")
            
            # æ·»åŠ æ›´è¯¦ç»†çš„è·¯å¾„ä¿¡æ¯
            logging.info(f"å½’æ¡£è‰ç¨¿:")
            logging.info(f"  ä»: {draft_path}")
            logging.info(f"  åˆ°: {new_path}")
            
            draft_path.rename(new_path)
            logging.info(f"âœ… å½’æ¡£å®Œæˆ")
            
            # è¿”å›æ–°çš„å½’æ¡£æ–‡ä»¶è·¯å¾„
            return new_path
            
        except Exception as e:
            logging.error(f"å½’æ¡£è‰ç¨¿æ—¶å‡ºé”™: {str(e)}")
            logging.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            return None
    
    def _convert_links_to_new_window(self, content: str) -> str:
        """å°†Markdowné“¾æ¥è½¬æ¢ä¸ºåœ¨æ–°çª—å£æ‰“å¼€çš„HTMLé“¾æ¥"""
        # åŒ¹é…Markdowné“¾æ¥æ ¼å¼ [text](url)
        pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        
        def replace_link(match):
            text = match.group(1)
            url = match.group(2)
            # è·³è¿‡å›¾ç‰‡é“¾æ¥
            if text.startswith('!'):
                return match.group(0)
            # è·³è¿‡å·²ç»æ˜¯HTMLé“¾æ¥çš„æƒ…å†µ
            if '<a ' in text and '</a>' in text:
                return match.group(0)
            # è½¬æ¢ä¸ºHTMLé“¾æ¥ï¼Œæ·»åŠ target="_blank"å±æ€§
            return f'<a href="{url}" target="_blank" rel="noopener noreferrer">{text}</a>'
        
        # æ›¿æ¢æ‰€æœ‰é“¾æ¥
        converted_content = re.sub(pattern, replace_link, content)
        
        # ä¹Ÿå¤„ç†å·²ç»å­˜åœ¨çš„HTMLé“¾æ¥ï¼Œä½†æ²¡æœ‰target="_blank"çš„æƒ…å†µ
        html_link_pattern = r'<a\s+(?![^>]*target="_blank")([^>]*)href="([^"]+)"([^>]*)>(.*?)</a>'
        
        def add_target_blank(match):
            attrs_before = match.group(1)
            url = match.group(2)
            attrs_after = match.group(3)
            text = match.group(4)
            return f'<a {attrs_before}href="{url}"{attrs_after} target="_blank" rel="noopener noreferrer">{text}</a>'
        
        # ä¸ºç°æœ‰HTMLé“¾æ¥æ·»åŠ target="_blank"
        converted_content = re.sub(html_link_pattern, add_target_blank, converted_content)
        
        self.log("âœ… å·²å°†æ‰€æœ‰é“¾æ¥è®¾ç½®ä¸ºåœ¨æ–°çª—å£æ‰“å¼€", level="debug")
        return converted_content

    def _generate_blog_content(self, content: str, images: Dict[str, str], draft_path: Path) -> str:
        """ç”Ÿæˆåšå®¢å†…å®¹"""
        try:
            # å°è¯•è§£æfront matter
            try:
                post = frontmatter.loads(content)
            except Exception as e:
                self.log(f"âš ï¸ è§£æ front matter å¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤ front matter
                content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                    return content
            
            # ç¡®ä¿å†…å®¹å®Œæ•´æ€§
            if not post.content:
                self.log("âŒ æ–‡ç« å†…å®¹ä¸ºç©º", level="error", force=True)
                return content
            
            # åº”ç”¨é»˜è®¤æ¨¡æ¿ï¼ˆå¼ºåˆ¶è¦†ç›–è‡ªåŠ¨ç”Ÿæˆå­—æ®µï¼‰
            default_template = self.templates.get('front_matter', {}).get('default', {})
            if default_template:
                for key, value in default_template.items():
                    post[key] = value  # å¼ºåˆ¶è¦†ç›–ï¼Œä¸æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                    self.log(f"åº”ç”¨é»˜è®¤æ¨¡æ¿: {key}={value}", level="info")
                self.log(f"å·²åº”ç”¨é»˜è®¤æ¨¡æ¿è®¾ç½®", level="info")
            else:
                self.log(f"æœªæ‰¾åˆ°é»˜è®¤æ¨¡æ¿è®¾ç½®", level="warning")
            
            # æ·»åŠ æˆ–æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            post['last_modified_at'] = current_time
            self.log(f"æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´: {current_time}", level="info")
            
            # æ›´æ–°æ–‡ç« ä¸­çš„å›¾ç‰‡é“¾æ¥ä¸ºæ ‡å‡†åŒ–æœ¬åœ°è·¯å¾„
            updated_content = post.content
            for local_name, _ in images.items():
                # æ„å»ºæ—§çš„æœ¬åœ°è·¯å¾„æ¨¡å¼
                date_str = draft_path.stem[:10]
                post_name = draft_path.stem[11:]
                old_local_path = f"/assets/images/posts/{date_str[:4]}/{date_str[5:7]}/{post_name}/{local_name}"
                # æ–°çš„æ ‡å‡†åŒ–æœ¬åœ°è·¯å¾„
                new_local_path = f"/assets/images/posts/{local_name}"
                
                # æ›¿æ¢å†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥
                updated_content = updated_content.replace(old_local_path, new_local_path)
                self.log(f"âœ… æ ‡å‡†åŒ–å›¾ç‰‡URL: {local_name} -> {new_local_path}", level="info")
                
                # æ›´æ–° front matter ä¸­çš„å›¾ç‰‡é“¾æ¥
                if hasattr(post, 'metadata') and "header" in post.metadata:
                    header_info = post.metadata["header"]
                    if isinstance(header_info, dict) and "image" in header_info:
                        if header_info["image"] == old_local_path:
                            header_info["image"] = new_local_path
                            post.metadata["header"] = header_info
                            self.log(f"æ›´æ–° header å›¾ç‰‡: {new_local_path}", level="info")
            
            # æ›´æ–°å†…å®¹
            post.content = updated_content
            
            # å°†Markdowné“¾æ¥è½¬æ¢ä¸ºåœ¨æ–°çª—å£æ‰“å¼€çš„HTMLé“¾æ¥
            post.content = self._convert_links_to_new_window(post.content)
            self.log("âœ… å·²å°†é“¾æ¥è®¾ç½®ä¸ºåœ¨æ–°çª—å£æ‰“å¼€", level="info")
            
            # æ·»åŠ é¡µè„š
            platform_config = self.platforms_config.get('github_pages', {})
            if platform_config.get('append_footer', False):
                footer_template = self.templates.get('footer', {}).get('github_pages', '')
                if footer_template:
                    # ç¡®ä¿é¡µè„šå‰æœ‰è¶³å¤Ÿçš„ç©ºè¡Œ
                    if not post.content.endswith('\n\n'):
                        post.content = post.content.rstrip() + '\n\n'
                    
                    post.content = f"{post.content}{footer_template}"
                    self.log(f"æ·»åŠ é¡µè„šæˆåŠŸ", level="info")
                else:
                    self.log(f"æœªæ‰¾åˆ° github_pages çš„é¡µè„šæ¨¡æ¿", level="warning")
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            self.log(f"å¤„ç†åçš„å†…å®¹é•¿åº¦: {len(post.content)}", level="debug")
            
            return frontmatter.dumps(post)
            
        except Exception as e:
            self.log(f"ç”Ÿæˆåšå®¢å†…å®¹æ—¶å‡ºé”™: {str(e)}", level="error")
            return content

    def _generate_wechat_content(self, content: str, images: Dict[str, str]) -> str:
        """ç”Ÿæˆå¾®ä¿¡å…¬ä¼—å·å†…å®¹"""
        # TODO: å®ç°å¾®ä¿¡å…¬ä¼—å·çš„å†…å®¹è½¬æ¢
        # 1. å¤„ç†å›¾ç‰‡é“¾æ¥
        # 2. è°ƒæ•´æ ¼å¼
        # 3. æ·»åŠ å¾®ä¿¡ç‰¹å®šçš„æ ·å¼
        return content

    def _generate_wordpress_content(self, content: str, images: Dict[str, str]) -> str:
        """ç”ŸæˆWordPresså†…å®¹"""
        # TODO: å®ç°WordPressçš„å†…å®¹è½¬æ¢
        # 1. å¤„ç†å›¾ç‰‡é“¾æ¥
        # 2. è½¬æ¢Markdownä¸ºHTML
        # 3. æ·»åŠ WordPressç‰¹å®šçš„æ ¼å¼
        return content

    def _publish_to_github_pages(self, draft_path: Path, content: str) -> bool:
        """å‘å¸ƒåˆ°GitHub Pagesï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
        try:
            publish_path = Path(self.config["paths"]["posts"]) / draft_path.name
            
            # å§‹ç»ˆè§£æå¹¶é‡æ–°æ ¼å¼åŒ–frontmatterï¼Œç¡®ä¿layoutå­—æ®µåœ¨æœ€å‰é¢
            try:
                post = frontmatter.loads(content)
                
                # ä½¿ç”¨OrderedDictç¡®ä¿layoutå­—æ®µåœ¨æœ€å‰é¢
                if 'layout' in post:
                    from collections import OrderedDict
                    ordered_post = OrderedDict()
                    ordered_post["layout"] = post["layout"]
                    
                    # æ·»åŠ å…¶ä»–å­—æ®µï¼ˆé™¤äº†layoutå’Œcontentï¼‰
                    for key, value in post.metadata.items():
                        if key != 'layout':
                            ordered_post[key] = value
                    
                    # åˆ›å»ºæ–°çš„Postå¯¹è±¡å¹¶è®¾ç½®å†…å®¹
                    final_post = frontmatter.Post(post.content, **ordered_post)
                    content = frontmatter.dumps(final_post)
                else:
                    # å¦‚æœæ²¡æœ‰layoutå­—æ®µï¼Œæ·»åŠ ä¸€ä¸ª
                    from collections import OrderedDict
                    ordered_post = OrderedDict()
                    ordered_post["layout"] = "single"
                    
                    # æ·»åŠ å…¶ä»–å­—æ®µ
                    for key, value in post.metadata.items():
                        ordered_post[key] = value
                    
                    # åˆ›å»ºæ–°çš„Postå¯¹è±¡å¹¶è®¾ç½®å†…å®¹
                    final_post = frontmatter.Post(post.content, **ordered_post)
                    content = frontmatter.dumps(final_post)
                
                # ç¡®ä¿å†…å®¹ä»¥front matterå¼€å¤´
                if not content.startswith('---'):
                    self.log("âŒ æ— æ³•ä¿®å¤front matteræ ¼å¼", level="error")
                    return False
            except Exception as e:
                self.log(f"âŒ è§£æfront matterå¤±è´¥: {str(e)}", level="error")
                return False
            
            # ä¿å­˜æ–‡ä»¶
            with open(publish_path, 'w', encoding='utf-8') as f:
                f.write(content)
            self.log(f"âœ… å†…å®¹å·²å‘å¸ƒåˆ°: {publish_path}", force=True)
            
            # Git æ“ä½œ
            try:
                # å…ˆæ‹‰å–æœ€æ–°ä»£ç 
                subprocess.run(["git", "pull"], check=True)
                
                # æ·»åŠ æ–‡ä»¶
                subprocess.run(["git", "add", str(publish_path)], check=True)
                
                # æ£€æŸ¥æ–‡ä»¶çŠ¶æ€
                status = subprocess.run(
                    ["git", "status", "--porcelain", str(publish_path)],
                    capture_output=True,
                    text=True
                ).stdout.strip()
                
                if not status:
                    self.log("æ²¡æœ‰éœ€è¦æäº¤çš„æ›´æ”¹", level="warning")
                    return False
                
                # æäº¤æ›´æ”¹
                subprocess.run(["git", "commit", "-m", f"å‘å¸ƒ: {draft_path.name}"], check=True)
                
                # æ¨é€
                subprocess.run(["git", "push"], check=True)
                self.log("âœ… å·²æ¨é€åˆ° GitHub", force=True)
                return True
                
            except Exception as e:
                self.log(f"âŒ Gitæ“ä½œå¤±è´¥: {str(e)}", level="error")
                return False
                
        except Exception as e:
            self.log(f"âŒ å‘å¸ƒåˆ°GitHub Pageså¤±è´¥: {str(e)}", level="error")
            return False

    def _publish_to_wechat(self, content: str) -> bool:
        """å‘å¸ƒåˆ°å¾®ä¿¡å…¬ä¼—å·ï¼Œæ ¹æ®é…ç½®å†³å®šæ˜¯APIå‘å¸ƒè¿˜æ˜¯ç”ŸæˆæŒ‡å—ã€‚"""
        self.log("å¼€å§‹å¤„ç†å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒ...", level="info", force=True)
        if not self.wechat_publisher:
            self.log("å¾®ä¿¡å‘å¸ƒå™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å‘å¸ƒã€‚", level="error", force=True)
            return False

        try:
            post = frontmatter.loads(content)
            platform_config = self.platforms_config.get("wechat", {})
            publish_mode = platform_config.get("publish_mode", "guide")  # é»˜è®¤ä¸º guide æ¨¡å¼

            self.log(f"å¾®ä¿¡å‘å¸ƒæ¨¡å¼: {publish_mode.upper()}", level="info", force=True)

            if publish_mode == "api":
                # APIæ¨¡å¼ï¼šç›´æ¥å‘å¸ƒåˆ°è‰ç¨¿ç®±
                media_id = self.wechat_publisher.publish_to_draft(
                    project_root=self.project_root,
                    front_matter=post.metadata,
                    markdown_content=post.content
                )
                if media_id:
                    self.log(f"âœ… æˆåŠŸåˆ›å»ºå¾®ä¿¡è‰ç¨¿ï¼ŒMedia ID: {media_id}", force=True)
                    return True
                else:
                    self.log("âŒ é€šè¿‡APIåˆ›å»ºå¾®ä¿¡è‰ç¨¿å¤±è´¥ã€‚", level="error", force=True)
                    return False
            else:
                # Guideæ¨¡å¼ï¼šç”Ÿæˆæ‰‹åŠ¨å‘å¸ƒæŒ‡å—
                success = self.wechat_publisher.generate_guide_file(
                    project_root=self.project_root,
                    front_matter=post.metadata,
                    markdown_content=post.content
                )
                if success:
                    self.log("âœ… æˆåŠŸç”Ÿæˆå¾®ä¿¡å‘å¸ƒæŒ‡å—æ–‡ä»¶ã€‚", force=True)
                else:
                    self.log("âŒ ç”Ÿæˆå¾®ä¿¡å‘å¸ƒæŒ‡å—æ–‡ä»¶å¤±è´¥ã€‚", level="error", force=True)
                return success

        except Exception as e:
            self.log(f"å‘å¸ƒåˆ°å¾®ä¿¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", level="error", force=True)
            self.logger.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            return False

    def _publish_to_wordpress(self, content: str):
        """å‘å¸ƒåˆ°WordPress"""
        # TODO: å®ç°WordPresså‘å¸ƒ
        logging.info("WordPresså‘å¸ƒåŠŸèƒ½å°šæœªå®ç°")

    def generate_test_content(self) -> Optional[Path]:
        """ä½¿ç”¨Geminiç”Ÿæˆæµ‹è¯•æ–‡ç« """
        try:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨AIç”Ÿæˆæµ‹è¯•æ–‡ç« ...")
            print("â³ æ­£åœ¨è¿æ¥Gemini AIæ¨¡å‹ï¼Œè¿™é€šå¸¸éœ€è¦15-30ç§’æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            print("ğŸ’¡ ç”Ÿæˆä¸­: æ¨¡å‹æ­£åœ¨æ ¹æ®CLAUDE.mdè§„èŒƒåˆ›å»ºå®Œæ•´çš„æŠ€æœ¯åšå®¢æ–‡ç« ...")
            
            # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
            if not hasattr(self, 'model') or self.model is None:
                print("âŒ Geminiæ¨¡å‹æœªåˆå§‹åŒ–")
                logging.error("Geminiæ¨¡å‹æœªåˆå§‹åŒ–")
                return None
            
            prompt = self.config["content_processing"]["gemini"]["prompts"]["test"]
            logging.debug(f"ä½¿ç”¨çš„prompté•¿åº¦: {len(prompt)}")
            
            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 2
            for attempt in range(max_retries):
                if attempt > 0:
                    print(f"âš ï¸ ç¬¬{attempt + 1}æ¬¡å°è¯•ç”Ÿæˆ...")
                    logging.info(f"é‡è¯•ç”Ÿæˆæµ‹è¯•æ–‡ç« ï¼Œç¬¬{attempt + 1}æ¬¡å°è¯•")
                
                # é…ç½®å®‰å…¨è®¾ç½®ä»¥å…è®¸æŠ€æœ¯å†…å®¹ç”Ÿæˆ
                safety_settings = [
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH"},
                ]
                
                response = self.model.generate_content(
                    prompt,
                    generation_config=GenerationConfig(
                        temperature=self.config["content_processing"]["gemini"]["temperature"],
                        max_output_tokens=self.config["content_processing"]["gemini"]["max_output_tokens"],
                        top_p=self.config["content_processing"]["gemini"]["top_p"]
                    ),
                    safety_settings=safety_settings
                )
                
                # æ£€æŸ¥è¿™æ¬¡å°è¯•æ˜¯å¦æˆåŠŸ
                if response and hasattr(response, 'candidates') and response.candidates:
                    if len(response.candidates) > 0 and response.candidates[0].content:
                        break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                
                if attempt == max_retries - 1:
                    print("âŒ å¤šæ¬¡å°è¯•åä»ç„¶ç”Ÿæˆå¤±è´¥")
                    logging.error("å¤šæ¬¡å°è¯•åä»ç„¶ç”Ÿæˆå¤±è´¥")
                    return None
            
            if response:
                logging.debug(f"Geminiå“åº”ç±»å‹: {type(response)}")
                logging.debug(f"Geminiå“åº”å±æ€§: candidates={hasattr(response, 'candidates')}, parts={hasattr(response, 'parts')}")
                try:
                    # è·å–å“åº”å†…å®¹
                    if hasattr(response, 'candidates') and response.candidates:
                        if len(response.candidates) > 0 and response.candidates[0].content:
                            content = response.candidates[0].content.parts[0].text
                        else:
                            print("âš ï¸ Geminiå“åº”ä¸­æ— å€™é€‰ç»“æœ")
                            logging.error("Geminiå“åº”ä¸­æ— å€™é€‰ç»“æœ")
                            return None
                    elif hasattr(response, 'parts') and response.parts:
                        content = ' '.join(part.text for part in response.parts)
                    else:
                        print("âš ï¸ Geminiå“åº”æ ¼å¼å¼‚å¸¸")
                        logging.error(f"Geminiå“åº”æ ¼å¼å¼‚å¸¸: {type(response)}, hasattr candidates: {hasattr(response, 'candidates')}, hasattr parts: {hasattr(response, 'parts')}")
                        return None
                    
                    logging.debug(f"åŸå§‹å“åº”ç±»å‹: {type(content)}")
                    logging.debug(f"åŸå§‹å“åº”å†…å®¹: {content[:200]}...")
                    
                    print("âœ… AIå†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨ä¿å­˜æ–‡ä»¶...")
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦å®Œæ•´ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ç»“å°¾ï¼‰
                    if not self._has_complete_ending(content):
                        print("âš ï¸ æ£€æµ‹åˆ°ç”Ÿæˆå†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ...")
                        # é‡æ–°ç”Ÿæˆä¸€æ¬¡ï¼Œä½¿ç”¨æ›´æ˜ç¡®çš„prompt
                        complete_prompt = prompt + "\n\nã€ç‰¹åˆ«å¼ºè°ƒã€‘æ–‡ç« å¿…é¡»æœ‰å®Œæ•´çš„ç»“å°¾æ®µè½ï¼ŒåŒ…å«æ€»ç»“æˆ–æ€è€ƒé—®é¢˜ã€‚"
                        response = self.model.generate_content(
                            complete_prompt,
                            generation_config=GenerationConfig(
                                temperature=0.6,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç¨³å®šæ€§
                                max_output_tokens=self.config["content_processing"]["gemini"]["max_output_tokens"],
                                top_p=0.8
                            ),
                            safety_settings=safety_settings
                        )
                        if hasattr(response, 'candidates') and response.candidates:
                            content = response.candidates[0].content.parts[0].text
                        else:
                            content = ' '.join(part.text for part in response.parts)
                    
                    # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶åé¿å…è¦†ç›–
                    timestamp = datetime.now().strftime("%Y-%m-%d-%H%M%S")
                    
                    # æ¸…ç†å’Œå¤„ç†AIç”Ÿæˆçš„å†…å®¹
                    cleaned_content = self._clean_ai_generated_content(content)
                    
                    # è°ƒè¯•ä¿¡æ¯
                    logging.debug(f"åŸå§‹å†…å®¹é•¿åº¦: {len(content)}")
                    logging.debug(f"æ¸…ç†åå†…å®¹é•¿åº¦: {len(cleaned_content)}")
                    logging.debug(f"åŸå§‹å†…å®¹å‰200å­—ç¬¦: {content[:200]}")
                    logging.debug(f"æ¸…ç†åå†…å®¹å‰200å­—ç¬¦: {cleaned_content[:200] if cleaned_content else 'EMPTY'}")
                    
                    if not cleaned_content.strip():
                        print("âŒ AIç”Ÿæˆçš„å†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆ")
                        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šåŸå§‹å†…å®¹é•¿åº¦ {len(content)}, æ¸…ç†åé•¿åº¦ {len(cleaned_content)}")
                        logging.error(f"AIç”Ÿæˆçš„å†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆ - åŸå§‹é•¿åº¦: {len(content)}, æ¸…ç†åé•¿åº¦: {len(cleaned_content)}")
                        logging.error(f"åŸå§‹å†…å®¹ç¤ºä¾‹: {content[:500] if content else 'NONE'}")
                        return None
                    
                    # æ£€æŸ¥æ˜¯å¦å·²åŒ…å«valid front matter
                    if cleaned_content.startswith('---') and cleaned_content.count('---') >= 2:
                        # AIç”Ÿæˆçš„å†…å®¹å·²åŒ…å«front matterï¼Œç›´æ¥ä½¿ç”¨
                        post_text = cleaned_content
                        print("ğŸ“ ä½¿ç”¨AIç”Ÿæˆçš„å®Œæ•´æ–‡ç« æ ¼å¼")
                    else:
                        # æ‰‹åŠ¨æ·»åŠ front matter
                        from collections import OrderedDict
                        post = OrderedDict()
                        post["title"] = f"AIç”Ÿæˆæµ‹è¯•æ–‡ç«  - {timestamp}"
                        post["date"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S +0000")
                        post["header"] = {
                            "overlay_image": "https://1drv.ms/i/c/b5f6bce7f0f6f9f8/EQl5xJjYnAJOhRfDgJ7HZFABL8y5c7d1e2f3g4h5i6j7k8l9?format=webp&width=1200",
                            "overlay_filter": 0.5
                        }
                        post_text = frontmatter.dumps(frontmatter.Post(cleaned_content, **post))
                        print("ğŸ“ æ·»åŠ äº†æ ‡å‡†front matter")
                    
                    # å†™å…¥æ–‡ä»¶
                    draft_path = Path(f"_drafts/test-article-{timestamp}.md")
                    draft_path.parent.mkdir(parents=True, exist_ok=True)
                    draft_path.write_text(post_text, encoding='utf-8')
                    
                    print(f"âœ… æµ‹è¯•æ–‡ç« å·²ç”Ÿæˆ: {draft_path}")
                    print(f"ğŸ“ æ–‡ç« é•¿åº¦: {len(content)} å­—ç¬¦")
                    logging.info(f"âœ… å·²ç”Ÿæˆæµ‹è¯•æ–‡ç« : {draft_path} (é•¿åº¦: {len(content)} å­—ç¬¦)")
                    
                    # è®°å½•æµ‹è¯•æ–‡ç« ç”Ÿæˆçš„è¯¦ç»†ä¿¡æ¯
                    lines = post_text.count('\n') + 1
                    self.log(f"æµ‹è¯•æ–‡ç« ç”Ÿæˆè¯¦æƒ… - æ–‡ä»¶: {draft_path}, æ€»é•¿åº¦: {len(content)}å­—ç¬¦, è¡Œæ•°: {lines}è¡Œ", level="info", force=True)
                    return draft_path
                    
                except Exception as e:
                    logging.error(f"å¤„ç†å“åº”å†…å®¹æ—¶å‡ºé”™: {str(e)}")
                    logging.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
                    return None
            else:
                print("âŒ Gemini APIè¿”å›ç©ºå“åº”")
                logging.error("Gemini APIè¿”å›ç©ºå“åº”")
                return None
                
        except Exception as e:
            logging.error(f"ç”Ÿæˆæµ‹è¯•æ–‡ç« å¤±è´¥: {str(e)}")
            logging.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            return None
    
    def _has_complete_ending(self, content: str) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦æœ‰å®Œæ•´çš„ç»“å°¾"""
        # æ£€æŸ¥æ˜¯å¦ä»¥å¥å·ã€é—®å·æˆ–æ„Ÿå¹å·ç»“å°¾
        content = content.strip()
        if not content:
            return False
            
        # æ£€æŸ¥æœ€åå‡ è¡Œæ˜¯å¦åŒ…å«æ˜æ˜¾çš„ç»“å°¾æ ‡è¯†
        lines = content.split('\n')
        last_lines = '\n'.join(lines[-5:])  # æ£€æŸ¥æœ€å5è¡Œ
        
        # æ£€æŸ¥ç»“å°¾ç‰¹å¾
        ending_indicators = [
            'ï¼Ÿ', 'ã€‚', 'ï¼',  # ä¸­æ–‡æ ‡ç‚¹
            '?', '.', '!',     # è‹±æ–‡æ ‡ç‚¹
            'æ€è€ƒ', 'æ€»ç»“', 'ç»“è®º', 'å±•æœ›', 'æœªæ¥',
            'é—®é¢˜', 'æŒ‘æˆ˜', 'æœºé‡', 'å‘å±•'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“å°¾æŒ‡ç¤ºè¯
        has_ending_word = any(indicator in last_lines for indicator in ending_indicators)
        
        # æ£€æŸ¥æœ€åä¸€è¡Œæ˜¯å¦çœ‹èµ·æ¥åƒå®Œæ•´çš„å¥å­
        last_line = lines[-1].strip() if lines else ""
        is_complete_sentence = len(last_line) > 10 and any(punct in last_line for punct in ['ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!'])
        
        return has_ending_word and is_complete_sentence
    
    def _clean_ai_generated_content(self, content: str) -> str:
        """æ¸…ç†AIç”Ÿæˆçš„å†…å®¹ï¼Œå»é™¤è§£é‡Šæ€§æ–‡å­—å’Œå¤šä½™çš„æ ¼å¼"""
        if not content:
            return ""
        
        lines = content.split('\n')
        cleaned_lines = []
        start_found = False
        in_yaml_block = False
        in_code_block = False
        yaml_block_start = -1
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # æ£€æµ‹ä»£ç å—
            if stripped.startswith('```'):
                in_code_block = not in_code_block
                # å¦‚æœæ˜¯åŒ…è£…YAMLçš„ä»£ç å—ï¼Œè·³è¿‡
                if 'yaml' in stripped.lower() or 'markdown' in stripped.lower():
                    continue
                # å…¶ä»–ä»£ç å—ä¿ç•™
                if not in_code_block and start_found:
                    cleaned_lines.append(line)
                continue
            
            # åœ¨ä»£ç å—å†…ä¸”æ˜¯YAMLåŒ…è£…ï¼Œç‰¹æ®Šå¤„ç†
            if in_code_block:
                # æ£€æŸ¥æ˜¯å¦æ˜¯åµŒå…¥çš„YAML front matter
                if stripped == '---':
                    if not in_yaml_block:
                        in_yaml_block = True
                        yaml_block_start = i
                    else:
                        in_yaml_block = False
                        # è·³è¿‡æ•´ä¸ªYAMLå—
                    continue
                elif in_yaml_block:
                    continue  # è·³è¿‡YAMLå—å†…å®¹
                elif start_found:
                    cleaned_lines.append(line)  # ä¿ç•™éåµŒå…¥YAMLçš„ä»£ç å—å†…å®¹
                continue
            
            # è·³è¿‡æ˜æ˜¾çš„AIè§£é‡Šæ€§æ–‡å­—
            if not start_found:
                # è·³è¿‡å¸¸è§çš„AIè§£é‡Šæ€§å¼€å¤´
                if (stripped.startswith('å¥½çš„') or 
                    stripped.startswith('éµç…§') or
                    stripped.startswith('æˆ‘å°†') or
                    stripped.startswith('æ ¹æ®') or
                    stripped.startswith('ä»¥ä¸‹æ˜¯') or
                    stripped.startswith('è¿™é‡Œæ˜¯') or
                    stripped.startswith('è¿™æ˜¯ä¸€ç¯‡') or
                    'æŒ‰ç…§æ‚¨çš„è§„èŒƒ' in stripped or
                    'ç”¨äºæµ‹è¯•' in stripped):
                    continue
                # ç©ºè¡Œè·³è¿‡
                elif not stripped:
                    continue
                # æ‰¾åˆ°æ­£å¼å†…å®¹å¼€å§‹
                else:
                    start_found = True
            
            # å·²æ‰¾åˆ°å¼€å§‹ï¼Œä¿ç•™æ­£å¼å†…å®¹
            if start_found:
                cleaned_lines.append(line)
        
        cleaned_content = '\n'.join(cleaned_lines)
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        cleaned_content = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned_content)
        cleaned_content = cleaned_content.strip()
        
        # å¦‚æœæ¸…ç†åå†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œè¿”å›åŸå§‹å†…å®¹
        if not cleaned_content or len(cleaned_content) < 100:
            logging.warning("å†…å®¹æ¸…ç†åä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè¿”å›åŸå§‹å†…å®¹")
            return content.strip()
        
        return cleaned_content

    def process_post_images(self, post_path: Path) -> Dict[str, str]:
        """å¤„ç†æ–‡ç« ä¸­çš„å›¾ç‰‡"""
        # è·å–æ–‡ç« ä¸­çš„æœ¬åœ°å›¾ç‰‡
        local_images = {}
        temp_dir = None
        
        try:
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨ä¸‹è½½çš„å›¾ç‰‡
            temp_dir = Path(tempfile.mkdtemp())
            self.log(f"åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨ä¸‹è½½çš„å›¾ç‰‡: {temp_dir}", level="debug")
            
            with open(post_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # å°è¯•è§£æ front matter
                try:
                    # ä»front matterä¸­æå–å›¾ç‰‡
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âš ï¸ è§£æ front matter å¤±è´¥: {str(e)}", level="warning")
                    # å°è¯•ä¿®å¤ front matter
                    content = self._fix_frontmatter_quotes(content)
                    try:
                        post = frontmatter.loads(content)
                    except Exception as e:
                        self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                        return {}
                
                if 'header' in post:
                    for img_field in ['image', 'og_image', 'overlay_image', 'teaser']:
                        header = post.get('header', {})
                        if isinstance(header, dict) and img_field in header:
                            img_path = header[img_field]
                            if not img_path:
                                continue
                                
                            # å¤„ç†OneDriveé“¾æ¥
                            if '1drv.ms' in img_path or 'onedrive.live.com' in img_path:
                                try:
                                    self.log(f"å‘ç°OneDriveå¤´å›¾: {img_field} = {img_path}", level="info")
                                    img_name = self._download_onedrive_image(img_path, temp_dir)
                                    if img_name:
                                        local_images[img_name] = temp_dir / img_name
                                        self.log(f"æˆåŠŸä¸‹è½½OneDriveå¤´å›¾: {img_name}", level="info")
                                except Exception as e:
                                    self.log(f"ä¸‹è½½OneDriveå¤´å›¾å¤±è´¥: {str(e)}", level="error")
                            # å¤„ç†æœ¬åœ°å›¾ç‰‡
                            elif img_path.startswith('/assets/images/'):
                                name = Path(img_path).name
                                full_path = Path.cwd() / img_path.lstrip('/')
                                if full_path.exists():
                                    local_images[name] = full_path
                                    self.log(f"æ‰¾åˆ°å¤´å›¾: {name}", level="debug")
                                else:
                                    self.log(f"å¤´å›¾ä¸å­˜åœ¨: {img_path}", level="warning")
                
                # æŸ¥æ‰¾markdownå›¾ç‰‡è¯­æ³•
                for match in re.finditer(r'!\[.*?\]\((.*?)\)', content):
                    img_path = match.group(1)
                    # è·³è¿‡å·²ç»æ˜¯æœ¬åœ°è·¯å¾„çš„å›¾ç‰‡
                    if img_path.startswith('/assets/images/'):
                        self.log(f"è·³è¿‡å·²æœ‰çš„æœ¬åœ°å›¾ç‰‡è·¯å¾„: {img_path}", level="debug")
                        continue
                    
                    # å¤„ç†OneDriveé“¾æ¥
                    if '1drv.ms' in img_path or 'onedrive.live.com' in img_path:
                        try:
                            self.log(f"å‘ç°OneDriveæ­£æ–‡å›¾ç‰‡: {img_path}", level="info")
                            img_name = self._download_onedrive_image(img_path, temp_dir)
                            if img_name:
                                local_images[img_name] = temp_dir / img_name
                                self.log(f"æˆåŠŸä¸‹è½½OneDriveæ­£æ–‡å›¾ç‰‡: {img_name}", level="info")
                        except Exception as e:
                            self.log(f"ä¸‹è½½OneDriveæ­£æ–‡å›¾ç‰‡å¤±è´¥: {str(e)}", level="error")
                    # å¤„ç†æœ¬åœ°å›¾ç‰‡
                    elif img_path.startswith('/assets/images/'):
                        name = Path(img_path).name
                        # è·å–å›¾ç‰‡çš„å®Œæ•´è·¯å¾„
                        full_path = Path.cwd() / img_path.lstrip('/')
                        
                        if full_path.exists():
                            local_images[name] = full_path
                            self.log(f"æ‰¾åˆ°æ­£æ–‡å›¾ç‰‡: {name}", level="debug")
                        else:
                            self.log(f"æ­£æ–‡å›¾ç‰‡ä¸å­˜åœ¨: {img_path}", level="warning")
            
            if not local_images:
                self.log("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å›¾ç‰‡", level="warning")
                return {}
            # å›¾ç‰‡å¤„ç†åŠŸèƒ½å·²ç§»é™¤ï¼ˆä¸å†ä½¿ç”¨Cloudflare Imagesï¼‰
            self.log(f"å‘ç° {len(local_images)} å¼ å›¾ç‰‡ï¼Œä½†å›¾ç‰‡ä¸Šä¼ åŠŸèƒ½å·²ç§»é™¤", level="info")
            return {}
        
        except Exception as e:
            self.log(f"å¤„ç†æ–‡ç« å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}", level="error")
            return {}
        
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if temp_dir and temp_dir.exists():
                try:
                    import shutil
                    shutil.rmtree(temp_dir)
                    self.log(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}", level="debug")
                except Exception as e:
                    self.log(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {str(e)}", level="warning")
    
    def _download_onedrive_image(self, url: str, temp_dir: Path) -> Optional[str]:
        """ä¸‹è½½OneDriveå›¾ç‰‡
        
        Args:
            url: OneDriveå›¾ç‰‡URL
            temp_dir: ä¸´æ—¶ç›®å½•
            
        Returns:
            æˆåŠŸè¿”å›å›¾ç‰‡æ–‡ä»¶åï¼Œå¤±è´¥è¿”å›None
        """
        try:
            self.log(f"ä¸‹è½½OneDriveå›¾ç‰‡: {url}", level="info")
            
            # æå–OneDrive URLä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦
            unique_id = None
            if 'onedrive.live.com' in url and 'resid=' in url:
                # ä¾‹å¦‚ï¼šhttps://onedrive.live.com/embed?resid=5644DAB129AFDA10%2169891&authkey=%21AFppTKcu8cfS2Eo&width=660
                resid_match = re.search(r'resid=([^&]+)', url)
                if resid_match:
                    resid = resid_match.group(1)
                    # è§£ç URLç¼–ç çš„å­—ç¬¦
                    import urllib.parse
                    resid = urllib.parse.unquote(resid)
                    self.log(f"ä»URLä¸­æå–çš„resid: {resid}", level="debug")
                    
                    # æå–residä¸­çš„æ•°å­—éƒ¨åˆ†ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                    id_match = re.search(r'([0-9]+)$', resid)
                    if id_match:
                        unique_id = id_match.group(1)
                        self.log(f"ä»residä¸­æå–çš„å”¯ä¸€æ ‡è¯†ç¬¦: {unique_id}", level="debug")
            
            # å¦‚æœæ— æ³•ä»URLä¸­æå–å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œåˆ™ä½¿ç”¨URLçš„å“ˆå¸Œå€¼
            if not unique_id:
                import hashlib
                unique_id = hashlib.md5(url.encode()).hexdigest()[:5]
                self.log(f"ä½¿ç”¨URLå“ˆå¸Œå€¼ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦: {unique_id}", level="debug")
            
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            # ç¡®å®šå›¾ç‰‡æ ¼å¼
            content_type = response.headers.get('content-type', '')
            self.log(f"å›¾ç‰‡Content-Type: {content_type}", level="debug")
            extension = self._get_extension_from_content_type(content_type)
            
            if not extension and 'content-disposition' in response.headers:
                # å°è¯•ä»Content-Dispositionå¤´ä¸­æå–æ–‡ä»¶å
                cd = response.headers['content-disposition']
                self.log(f"Content-Disposition: {cd}", level="debug")
                filename_match = re.search(r'filename="?([^";]+)"?', cd)
                if filename_match:
                    orig_filename = filename_match.group(1)
                    _, extension = os.path.splitext(orig_filename)
                    extension = extension.lstrip('.')
                    self.log(f"ä»Content-Dispositionæå–çš„æ‰©å±•å: {extension}", level="debug")
            
            # å¦‚æœä»ç„¶æ— æ³•ç¡®å®šæ‰©å±•åï¼Œåˆ™æ ¹æ®å†…å®¹è¿›è¡Œåˆ¤æ–­
            if not extension:
                import filetype
                img_data = response.content
                kind = filetype.guess(img_data)
                extension = kind.extension if kind else 'jpg'  # é»˜è®¤ä½¿ç”¨jpg
                self.log(f"ä»å†…å®¹åˆ¤æ–­çš„å›¾ç‰‡ç±»å‹: {extension}", level="debug")
            
            # æ„å»ºè¾“å‡ºæ–‡ä»¶å
            output_filename = f"onedrive_{unique_id}.{extension}"
            output_path = temp_dir / output_filename
            
            # ä¿å­˜å›¾ç‰‡
            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            self.log(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {url} -> {output_filename}", level="info")
            return output_filename
        except Exception as e:
            self.log(f"âŒ ä¸‹è½½OneDriveå›¾ç‰‡å¤±è´¥: {str(e)}", level="error")
            self.log("é”™è¯¯è¯¦æƒ…:", level="debug")
            return None

    def _setup_site_url(self):
        """è®¾ç½®ç«™ç‚¹URL"""
        # ä»å¹³å°é…ç½®ä¸­è·å–åŸŸå
        if 'platforms' in self.config and 'github_pages' in self.config['platforms']:
            self.site_url = self.config['platforms']['github_pages'].get('domain', 'arong.eu.org/youxinyanzhe')
        else:
            # é»˜è®¤å€¼
            self.site_url = 'arong.eu.org/youxinyanzhe'
        
        self.log(f"ç«™ç‚¹URL: {self.site_url}", level="debug")
    
    def _is_valid_draft(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ‰æ•ˆçš„è‰ç¨¿æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ front matter
            if not content.startswith('---'):
                return False
            
            # å°è¯•è§£æ front matter
            try:
                post = frontmatter.loads(content)
                # æ£€æŸ¥å¿…è¦çš„å­—æ®µï¼ˆlayoutä¸æ˜¯å¿…é¡»çš„ï¼Œå‘å¸ƒæ—¶ä¼šè‡ªåŠ¨æ·»åŠ ï¼‰
                required_fields = ['title', 'date']
                for field in required_fields:
                    if field not in post:
                        self.log(f"è‰ç¨¿ç¼ºå°‘å¿…è¦å­—æ®µ: {field}", level="warning")
                        return False
                return True
            except Exception as e:
                self.log(f"è§£æè‰ç¨¿ front matter å¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤
                fixed_content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(fixed_content)
                    return True
                except Exception:
                    return False
        except Exception:
            return False
    
    def _get_available_categories(self) -> Dict[str, List[str]]:
        """è·å–å¯ç”¨çš„åˆ†ç±»å’Œæ ‡ç­¾"""
        return self.templates.get('categories', {})
    
    def _suggest_categories(self, content: str) -> List[str]:
        """æ ¹æ®å†…å®¹å»ºè®®åˆ†ç±»"""
        categories = []
        available_cats = self._get_available_categories()
        
        if not available_cats:
            self.log("âŒ æ— æ³•è·å–å¯ç”¨åˆ†ç±»", level="error")
            return []
            
        # å°†å†…å®¹è½¬ä¸ºå°å†™ä»¥è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
        content_lower = content.lower()
        
        # å››å¤§æ ¸å¿ƒåˆ†ç±»å…³é”®è¯æ˜ å°„
        category_keywords = {
            "è®¤çŸ¥å‡çº§": ["æ€ç»´", "è®¤çŸ¥", "æ€è€ƒ", "å­¦ä¹ æ–¹æ³•", "å†³ç­–", "å¿ƒç†å­¦", "åè§", "æˆé•¿", "çŸ¥è¯†", "æ€ç»´æ¨¡å‹", "é˜…è¯»", "æ•™è‚²"],
            "æŠ€æœ¯èµ‹èƒ½": ["æŠ€æœ¯", "å·¥å…·", "è½¯ä»¶", "åº”ç”¨", "è‡ªåŠ¨åŒ–", "æ•ˆç‡", "ç¼–ç¨‹", "å¼€å‘", "äº‘æœåŠ¡", "ai", "äººå·¥æ™ºèƒ½", "æ•™ç¨‹", "æŒ‡å—"],
            "å…¨çƒè§†é‡": ["å…¨çƒ", "å›½é™…", "è¶‹åŠ¿", "æ–‡åŒ–", "è§‚å¯Ÿ", "ä¸–ç•Œ", "è·¨æ–‡åŒ–", "åˆ†æ", "tesla", "é©¬æ–¯å…‹", "ç§‘æŠ€", "åˆ›æ–°", "æœªæ¥"],
            "æŠ•èµ„ç†è´¢": ["æŠ•èµ„", "ç†è´¢", "é‡‘è", "è‚¡ç¥¨", "åŸºé‡‘", "é‡åŒ–", "äº¤æ˜“", "è´¢åŠ¡", "èµ„äº§", "æ”¶ç›Š", "é£é™©", "ç­–ç•¥", "ç¾è‚¡", "qdii"]
        }
        
        # å…ˆå°è¯•ä½¿ç”¨å…³é”®è¯åŒ¹é…
        for main_cat, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    categories.append(main_cat)
                    break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å…³é”®è¯ï¼Œå°è¯•ä½¿ç”¨å­åˆ†ç±»åŒ¹é…
        if not categories:
            for main_cat, sub_cats in available_cats.items():
                for sub_cat in sub_cats:
                    if sub_cat.lower() in content_lower:
                        categories.append(main_cat)
                        break
        
        # å¦‚æœä»ç„¶æ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
        if not categories:
            self.log("âš ï¸ æ— æ³•åŒ¹é…åˆ°åˆé€‚çš„åˆ†ç±»ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»", level="warning")
            return ["æŠ€æœ¯èµ‹èƒ½"]
            
        self.log(f"é€šè¿‡å…³é”®è¯åŒ¹é…æ‰¾åˆ°åˆ†ç±»: {categories}", level="info")
        return list(set(categories))  # å»é‡

    def _analyze_content_categories(self, content: str) -> Tuple[List[str], List[str]]:
        """ä½¿ç”¨ Gemini åˆ†ææ–‡ç« å†…å®¹ï¼Œè¿”å›å»ºè®®çš„åˆ†ç±»å’Œæ ‡ç­¾"""
        try:
            # è·å–å¯ç”¨åˆ†ç±»
            available_cats = self._get_available_categories()
            if not available_cats:
                self.log("âŒ æ— æ³•è·å–å¯ç”¨åˆ†ç±»", level="error")
                return [], []
                
            self.log(f"å¯ç”¨åˆ†ç±»: {list(available_cats.keys())}", level="debug")
            
            # æ„å»º prompt
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹æ–‡ç« å†…å®¹ï¼Œå¹¶ä»åšå®¢çš„å››å¤§æ ¸å¿ƒåˆ†ç±»ä½“ç³»ä¸­é€‰æ‹©æœ€åˆé€‚çš„åˆ†ç±»ï¼ŒåŒæ—¶ç”Ÿæˆç›¸å…³æ ‡ç­¾ã€‚

            å››å¤§æ ¸å¿ƒåˆ†ç±»ä½“ç³»ï¼š
            ğŸ§  è®¤çŸ¥å‡çº§ï¼šæ€ç»´æ¨¡å‹ã€å­¦ä¹ æ–¹æ³•ã€è®¤çŸ¥å¿ƒç†å­¦ã€å†³ç­–ç§‘å­¦ç›¸å…³å†…å®¹
            ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½ï¼šå®ç”¨å·¥å…·ã€æŠ€æœ¯æ•™ç¨‹ã€è‡ªåŠ¨åŒ–æ–¹æ¡ˆã€æ•ˆç‡æå‡ç›¸å…³å†…å®¹  
            ğŸŒ å…¨çƒè§†é‡ï¼šå›½é™…è¶‹åŠ¿ã€æ–‡åŒ–è§‚å¯Ÿã€å…¨çƒåŒ–æ€ç»´ã€ç§‘æŠ€è¶‹åŠ¿åˆ†æç›¸å…³å†…å®¹
            ğŸ’° æŠ•èµ„ç†è´¢ï¼šæŠ•èµ„ç­–ç•¥ã€ç†è´¢æ–¹æ³•ã€è´¢åŠ¡è‡ªç”±ã€é‡åŒ–åˆ†æç›¸å…³å†…å®¹

            è¦æ±‚ï¼š
            1. åªèƒ½ä»ä»¥ä¸Šå››ä¸ªåˆ†ç±»ä¸­é€‰æ‹©ä¸€ä¸ªæœ€åˆé€‚çš„ä¸»åˆ†ç±»
            2. åˆ†ç±»åç§°å¿…é¡»å®Œå…¨åŒ¹é…ï¼šè®¤çŸ¥å‡çº§ã€æŠ€æœ¯èµ‹èƒ½ã€å…¨çƒè§†é‡ã€æŠ•èµ„ç†è´¢
            3. ç”Ÿæˆ3-5ä¸ªç›¸å…³æ ‡ç­¾
            4. ä½¿ç”¨JSONæ ¼å¼è¿”å›ç»“æœï¼š
            {{
                "categories": ["é€‰æ‹©çš„ä¸»åˆ†ç±»"],
                "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"]
            }}
            
            æ–‡ç« å†…å®¹ï¼š
            {content[:3000]}
            """
            
            self.log("å¼€å§‹åˆ†ææ–‡ç« åˆ†ç±»å’Œæ ‡ç­¾...", level="info")
            response = self.model.generate_content(prompt)
            
            if response:
                try:
                    # å°è¯•è§£æJSONå“åº”
                    result_text = response.text.strip()
                    # å¦‚æœå“åº”ä¸æ˜¯ä»¥{å¼€å¤´ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                    if not result_text.startswith('{'):
                        json_start = result_text.find('{')
                        json_end = result_text.rfind('}') + 1
                        if json_start >= 0 and json_end > json_start:
                            result_text = result_text[json_start:json_end]
                    
                    result = json.loads(result_text)
                    categories = result.get('categories', [])
                    tags = result.get('tags', [])
                    
                    self.log(f"âœ… åˆ†æå®Œæˆï¼Œå»ºè®®åˆ†ç±»: {categories}", level="info")
                    self.log(f"âœ… åˆ†æå®Œæˆï¼Œå»ºè®®æ ‡ç­¾: {tags}", level="info")
                    
                    return categories, tags
                except json.JSONDecodeError as e:
                    self.log(f"JSONè§£æå¤±è´¥: {str(e)}", level="warning")
                    self.log(f"åŸå§‹å“åº”: {response.text[:200]}...", level="debug")
                    # å¤±è´¥æ—¶å›é€€åˆ°ç®€å•åŒ¹é…
                    categories = self._suggest_categories(content)
                    self.log(f"ä½¿ç”¨ç®€å•åŒ¹é…çš„åˆ†ç±»: {categories}", level="info")
                    return categories, []
            else:
                self.log("âŒ æ¨¡å‹æœªè¿”å›å“åº”", level="error")
                return self._suggest_categories(content), []
                
        except Exception as e:
            self.log(f"åˆ†ææ–‡ç« åˆ†ç±»æ—¶å‡ºé”™: {str(e)}", level="error")
            # å¤±è´¥æ—¶å›é€€åˆ°ç®€å•åŒ¹é…
            categories = self._suggest_categories(content)
            self.log(f"ä½¿ç”¨ç®€å•åŒ¹é…çš„åˆ†ç±»: {categories}", level="info")
            return categories, []
    
    def _replace_images(self, content: str, images: Dict[str, str], temp_dir_path: Path) -> str:
        """æ›¿æ¢æ–‡ç« ä¸­çš„å›¾ç‰‡é“¾æ¥ä¸ºCloudflareé“¾æ¥"""
        if not images:
            self.log("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡éœ€è¦æ›¿æ¢", level="warning")
            return content
            
        # é¦–å…ˆå¤„ç†OneDriveå›¾ç‰‡
        # å®šä¹‰OneDriveé“¾æ¥çš„åŒ¹é…æ¨¡å¼
        onedrive_patterns = [
            r'!\[([^\]]*)\]\((https?://onedrive\.live\.com/[^)]+)\)',  # Markdownæ ¼å¼
            r'<img\s+src="(https?://onedrive\.live\.com/[^"]+)".*?(?:alt="([^"]*)")?.*?>'  # HTMLæ ¼å¼
        ]
        
        # è®°å½•å·²å¤„ç†çš„OneDrive URLï¼Œé¿å…é‡å¤å¤„ç†
        processed_urls = {}
        total_replacements = 0
        
        # å¤„ç†OneDriveé“¾æ¥
        for pattern in onedrive_patterns:
            matches = re.finditer(pattern, content)
            match_count = 0
            
            for match in matches:
                match_count += 1
                if 'src=' in pattern:  # HTMLæ ¼å¼
                    onedrive_url = match.group(1)
                    alt_text = match.group(2) if (match.lastindex is not None and match.lastindex >= 2) else ""
                else:  # Markdownæ ¼å¼
                    alt_text = match.group(1)
                    onedrive_url = match.group(2)
                
                self.log(f"æ‰¾åˆ°OneDriveé“¾æ¥: {onedrive_url}", level="debug")
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªURL
                if onedrive_url in processed_urls:
                    local_url = processed_urls[onedrive_url]
                    self.log(f"ä½¿ç”¨å·²å¤„ç†çš„URL: {onedrive_url} -> {local_url}", level="debug")
                else:
                    # æŸ¥æ‰¾æ˜¯å¦æœ‰åŒ¹é…çš„å·²ä¸Šä¼ å›¾ç‰‡
                    found_match = False
                    for img_name, _ in images.items():
                        if self._is_same_onedrive_image(onedrive_url, img_name):
                            # ä½¿ç”¨æœ¬åœ°è·¯å¾„æ›¿ä»£Cloudflare URL
                            local_url = f"/assets/images/posts/{img_name}"
                            
                            processed_urls[onedrive_url] = local_url
                            found_match = True
                            self.log(f"âœ… æ‰¾åˆ°åŒ¹é…çš„æœ¬åœ°å›¾ç‰‡: {img_name} -> {local_url}", level="debug")
                            break
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ¨¡å‹ï¼Œä½¿ç”¨ä»»ä½•å¯ç”¨çš„ Gemini æ¨¡å‹
                    if not found_match:
                        self.log(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å·²ä¸Šä¼ å›¾ç‰‡ï¼Œå°è¯•ä¸‹è½½: {onedrive_url}", level="debug")
                        img_name = self._download_onedrive_image(onedrive_url, temp_dir_path)
                        if img_name:
                            img_path = temp_dir_path / img_name
                            # cloudflare_id = self.image_mapper.upload_image(img_path)
                            # if cloudflare_id:
                            #     cloudflare_url = f"https://imagedelivery.net/WQEpklwOF67ACUS0Tgsufw/{cloudflare_id}/public"
                            #     processed_urls[onedrive_url] = cloudflare_url
                            #     self.log(f"âœ… ä¸‹è½½å¹¶ä¸Šä¼ æˆåŠŸ: {onedrive_url} -> {cloudflare_url}", level="debug")
                            # else:
                            #     self.log(f"âŒ ä¸Šä¼ åˆ°Cloudflareå¤±è´¥: {img_name}", level="error")
                            #     continue
                            self.log("âŒ æœªå®ç°å›¾ç‰‡ä¸Šä¼ åŠŸèƒ½ï¼ˆimage_mapper æœªå®šä¹‰ï¼‰ï¼Œè¯·å®ç°ä¸Šä¼ é€»è¾‘", level="error")
                            continue
                        else:
                            self.log(f"âŒ ä¸‹è½½OneDriveå›¾ç‰‡å¤±è´¥: {onedrive_url}", level="error")
                            continue
                
                # æ›¿æ¢å†…å®¹ä¸­çš„OneDriveé“¾æ¥
                local_url = processed_urls.get(onedrive_url)
                if not local_url:
                    self.log(f"âš ï¸ æœªèƒ½è·å–æœ¬åœ°è·¯å¾„ï¼Œè·³è¿‡æ›¿æ¢: {onedrive_url}", level="warning")
                    continue
                if 'src=' in pattern:  # HTMLæ ¼å¼
                    replacement = f'<img src="{local_url}" alt="{alt_text}">'
                else:  # Markdownæ ¼å¼
                    replacement = f'![{alt_text}]({local_url})'
                
                # ä½¿ç”¨ç²¾ç¡®ä½ç½®æ›¿æ¢ï¼Œé¿å…å…¨å±€æ›¿æ¢å¯èƒ½å¯¼è‡´çš„é—®é¢˜
                start, end = match.span()
                content = content[:start] + replacement + content[end:]
                total_replacements += 1
                self.log(f"æ›¿æ¢OneDriveå›¾ç‰‡é“¾æ¥: {onedrive_url} -> {local_url}", level="debug")
        
        # å¤„ç†æœ¬åœ°å›¾ç‰‡è·¯å¾„æ ‡å‡†åŒ–
        for local_name, _ in images.items():
            # è·³è¿‡OneDriveå›¾ç‰‡ï¼Œå› ä¸ºå®ƒä»¬å·²ç»åœ¨ä¸Šé¢å¤„ç†è¿‡äº†
            if local_name.startswith('onedrive_'):
                continue
                
            # ä½¿ç”¨æ ‡å‡†åŒ–çš„æœ¬åœ°è·¯å¾„
            local_url = f"/assets/images/posts/{local_name}"
            
            # åŒ¹é…å„ç§å¯èƒ½çš„å›¾ç‰‡å¼•ç”¨æ ¼å¼
            patterns = [
                f'!\\[([^\\]]*)\\]\\(/assets/images/posts/.*?/{re.escape(local_name)}\\)',  # å®Œæ•´è·¯å¾„
                f'!\\[([^\\]]*)\\]\\(/assets/images/{re.escape(local_name)}\\)',           # ç®€åŒ–è·¯å¾„
                f'!\\[([^\\]]*)\\]\\({re.escape(local_name)}\\)'                           # ä»…æ–‡ä»¶å
            ]
            
            # æ£€æŸ¥è¿™ä¸ªç‰¹å®šå›¾ç‰‡æ˜¯å¦å·²ç»æœ‰æ­£ç¡®çš„è·¯å¾„ï¼Œé¿å…é‡å¤æ›¿æ¢
            local_pattern = f'!\\[([^\\]]*)\\]\\({re.escape(local_url)}\\)'
            if re.search(local_pattern, content):
                self.log(f"âš ï¸ å›¾ç‰‡ {local_name} å·²æœ‰æ­£ç¡®è·¯å¾„ï¼Œè·³è¿‡æ›¿æ¢", level="debug")
                continue
            
            replaced_this_image = False
            
            # å¤„ç†æ ‡å‡†è·¯å¾„
            for pattern in patterns:
                matches = re.finditer(pattern, content)
                for match in matches:
                    alt_text = match.group(1)
                    replacement = f'![{alt_text}]({local_url})'
                    
                    # ä½¿ç”¨ç²¾ç¡®ä½ç½®æ›¿æ¢ï¼Œé¿å…å…¨å±€æ›¿æ¢å¯èƒ½å¯¼è‡´çš„é—®é¢˜
                    start, end = match.span()
                    content = content[:start] + replacement + content[end:]
                    replaced_this_image = True
            
            if replaced_this_image:
                self.log(f"æ ‡å‡†åŒ–æœ¬åœ°å›¾ç‰‡è·¯å¾„: {local_name} -> {local_url}", level="debug")
        
        # è®°å½•æ€»æ›¿æ¢æ•°é‡
        if total_replacements > 0:
            self.log(f"âœ… æ€»å…±æ›¿æ¢äº† {total_replacements} ä¸ªå›¾ç‰‡å¼•ç”¨", level="info")
        else:
            self.log("âš ï¸ æœªæ‰¾åˆ°éœ€è¦æ›¿æ¢çš„å›¾ç‰‡å¼•ç”¨", level="warning")
            
        return content

    def _is_same_onedrive_image(self, onedrive_url: str, image_name: str) -> bool:
        """åˆ¤æ–­OneDrive URLæ˜¯å¦å¯¹åº”æŒ‡å®šçš„å›¾ç‰‡åç§°
        
        é€šè¿‡æ¯”è¾ƒOneDrive URLä¸­çš„residå‚æ•°å’Œå›¾ç‰‡åç§°ä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦æ¥åˆ¤æ–­
        """
        # å¦‚æœå›¾ç‰‡åç§°ä¸æ˜¯ä»¥onedrive_å¼€å¤´ï¼Œåˆ™æ— æ³•ç¡®å®šå¯¹åº”å…³ç³»
        if not image_name.startswith('onedrive_'):
            self.log(f"å›¾ç‰‡åç§°ä¸æ˜¯ä»¥onedrive_å¼€å¤´: {image_name}", level="debug")
            return False
        
        # ä»å›¾ç‰‡åç§°ä¸­æå–å”¯ä¸€æ ‡è¯†ç¬¦
        # æ ¼å¼ï¼šonedrive_UNIQUEID.extension
        match = re.match(r'onedrive_([^.]+)\.', image_name)
        if not match:
            self.log(f"æ— æ³•ä»å›¾ç‰‡åç§°ä¸­æå–å”¯ä¸€æ ‡è¯†ç¬¦: {image_name}", level="debug")
            return False
        
        image_unique_id = match.group(1)
        self.log(f"æ¯”è¾ƒOneDrive URLå’Œå›¾ç‰‡: URL={onedrive_url}, å›¾ç‰‡åç§°={image_name}, å”¯ä¸€ID={image_unique_id}", level="debug")
        
        # ä»OneDrive URLä¸­æå–residå‚æ•°
        if 'onedrive.live.com' in onedrive_url and 'resid=' in onedrive_url:
            resid_match = re.search(r'resid=([^&]+)', onedrive_url)
            if resid_match:
                resid = resid_match.group(1)
                # è§£ç URLç¼–ç çš„å­—ç¬¦
                import urllib.parse
                resid = urllib.parse.unquote(resid)
                
                self.log(f"ä»OneDrive URLä¸­æå–çš„resid: {resid}", level="debug")
                
                # æ£€æŸ¥residä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡åç§°ä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦
                if image_unique_id in resid:
                    self.log(f"âœ… åŒ¹é…æˆåŠŸ: å”¯ä¸€ID {image_unique_id} åœ¨resid {resid} ä¸­æ‰¾åˆ°", level="debug")
                    return True
                
                # æå–residä¸­çš„æ•°å­—éƒ¨åˆ†
                id_match = re.search(r'([0-9]+)$', resid)
                if id_match:
                    resid_number = id_match.group(1)
                    self.log(f"ä»residä¸­æå–çš„æ•°å­—éƒ¨åˆ†: {resid_number}", level="debug")
                    if resid_number == image_unique_id:
                        self.log(f"âœ… åŒ¹é…æˆåŠŸ: residçš„æ•°å­—éƒ¨åˆ† {resid_number} ä¸å”¯ä¸€ID {image_unique_id} ç›¸åŒ", level="debug")
                        return True
        
        # å¦‚æœæ— æ³•ä»URLä¸­æå–residï¼Œåˆ™ä½¿ç”¨URLçš„å“ˆå¸Œå€¼è¿›è¡Œæ¯”è¾ƒ
        if len(image_unique_id) == 5:  # åŸºäºURLçš„å“ˆå¸Œå€¼é•¿åº¦ä¸º5
            import hashlib
            url_hash = hashlib.md5(onedrive_url.encode()).hexdigest()[:5]
            self.log(f"URLå“ˆå¸Œå€¼: {url_hash}, å”¯ä¸€ID: {image_unique_id}", level="debug")
            if url_hash == image_unique_id:
                self.log(f"âœ… åŒ¹é…æˆåŠŸ: URLå“ˆå¸Œå€¼ {url_hash} ä¸å”¯ä¸€ID {image_unique_id} ç›¸åŒ", level="debug")
                return True
        
        # å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ— æ³•ç¡®å®šå¯¹åº”å…³ç³»ï¼Œåˆ™ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
        result = image_unique_id.lower() in onedrive_url.lower()
        if result:
            self.log(f"âœ… åŒ¹é…æˆåŠŸ: å”¯ä¸€ID {image_unique_id} åœ¨URL {onedrive_url} ä¸­æ‰¾åˆ°", level="debug")
        else:
            self.log(f"âŒ åŒ¹é…å¤±è´¥: å”¯ä¸€ID {image_unique_id} åœ¨URL {onedrive_url} ä¸­æœªæ‰¾åˆ°", level="debug")
        return result

    def _update_header_images(self, post: dict, images: Dict[str, str]) -> dict:
        """æ›´æ–°æ–‡ç« å¤´éƒ¨çš„å›¾ç‰‡URL"""
        if not images:
            self.log("æ²¡æœ‰å›¾ç‰‡éœ€è¦æ›´æ–°å¤´éƒ¨", level="warning")
            return post
        
        if 'header' not in post:
            self.log("æ–‡ç« æ²¡æœ‰headeréƒ¨åˆ†", level="warning")
            return post
        
        updated_count = 0
        for img_field in ['image', 'og_image', 'overlay_image', 'teaser']:
            if img_field in post['header']:
                img_path = post['header'][img_field]
                if not img_path:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯Cloudflare URL
                if img_path.startswith("https://imagedelivery.net"):
                    self.log(f"âš ï¸ å¤´å›¾ {img_field} å·²æ˜¯Cloudflare URLï¼Œè·³è¿‡æ›¿æ¢", level="debug")
                    continue
                
                # å¤„ç†OneDriveé“¾æ¥
                if '1drv.ms' in img_path or 'onedrive.live.com' in img_path:
                    # æŸ¥æ‰¾å¯¹åº”çš„å·²ä¸Šä¼ å›¾ç‰‡
                    found_match = False
                    for img_name, _ in images.items():
                        # å°è¯•åŒ¹é…OneDriveé“¾æ¥å’Œæœ¬åœ°å›¾ç‰‡
                        if self._is_same_onedrive_image(img_path, img_name):
                            # ä½¿ç”¨æœ¬åœ°è·¯å¾„æ›¿ä»£Cloudflare URL
                            local_url = f"/assets/images/posts/{img_name}"
                            
                            post['header'][img_field] = local_url
                            updated_count += 1
                            self.log(f"âœ… æ›´æ–°OneDriveå¤´å›¾: {img_field} = {img_path} -> {local_url}", level="info")
                            found_match = True
                            break
                    
                    if not found_match:
                        self.log(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„OneDriveå¤´å›¾: {img_field} = {img_path}", level="warning")
                # å¤„ç†æœ¬åœ°å›¾ç‰‡
                else:
                    img_name = Path(img_path).name
                    
                    if img_name in images:
                        # ä½¿ç”¨æœ¬åœ°è·¯å¾„æ›¿ä»£Cloudflare URL
                        local_url = f"/assets/images/posts/{img_name}"
                        post['header'][img_field] = local_url
                        updated_count += 1
                        self.log(f"âœ… æ›´æ–°å¤´å›¾: {img_field} = {img_name} -> {local_url}", level="info")
        
        if updated_count > 0:
            self.log(f"æ€»å…±æ›´æ–°äº† {updated_count} å¤„å¤´éƒ¨å›¾ç‰‡", level="info")
        return post

    def _get_extension_from_content_type(self, content_type: str) -> Optional[str]:
        """ä»Content-Typeå¤´ä¸­æå–æ–‡ä»¶æ‰©å±•å
        
        Args:
            content_type: Content-Typeå¤´çš„å€¼
            
        Returns:
            æ–‡ä»¶æ‰©å±•åï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™è¿”å›None
        """
        content_type = content_type.lower()
        if 'image/' not in content_type:
            return None
            
        # å¸¸è§çš„MIMEç±»å‹æ˜ å°„
        mime_to_ext = {
            'image/jpeg': 'jpg',
            'image/jpg': 'jpg',
            'image/png': 'png',
            'image/gif': 'gif',
            'image/webp': 'webp',
            'image/svg+xml': 'svg',
            'image/bmp': 'bmp',
            'image/tiff': 'tiff'
        }
        
        for mime, ext in mime_to_ext.items():
            if mime in content_type:
                return ext
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„MIMEç±»å‹ï¼Œå°è¯•ä»content-typeä¸­æå–å­ç±»å‹
        if '/' in content_type:
            subtype = content_type.split('/')[-1].split(';')[0].strip()
            if subtype and subtype != 'octet-stream':
                return subtype
                
        return None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='config/pipeline_config.yml', help='Path to config file')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose logging')
    args = parser.parse_args()

    pipeline = ContentPipeline(args.config, args.verbose)
    
    # é€‰æ‹©æ“ä½œ
    print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
    print("1. å¤„ç†ç°æœ‰è‰ç¨¿")
    print("2. é‡æ–°å‘å¸ƒå·²å‘å¸ƒæ–‡ç« ")
    print("3. ç”Ÿæˆæµ‹è¯•æ–‡ç« ")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip()
    
    if choice == "1":
        # å¤„ç†ç°æœ‰è‰ç¨¿
        draft = pipeline.select_draft()
        if not draft:
            return
    elif choice == "2":
        # é‡æ–°å‘å¸ƒå·²å‘å¸ƒæ–‡ç« 
        post = pipeline.select_published_post()
        if not post:
            return
        draft = pipeline.copy_post_to_draft(post)
        if not draft:
            return
    elif choice == "3":
        # ç”Ÿæˆæµ‹è¯•æ–‡ç« 
        draft = pipeline.generate_test_content()
        if not draft:
            print("ç”Ÿæˆæµ‹è¯•æ–‡ç« å¤±è´¥")
            return
    else:
        print("æ— æ•ˆçš„é€‰æ‹©")
        return
        
    # é€‰æ‹©å‘å¸ƒå¹³å°
    platforms = pipeline.select_platforms(draft)
    if not platforms:
        print("æœªé€‰æ‹©ä»»ä½•å‘å¸ƒå¹³å°")
        return
        
    # å¤„ç†å¹¶å‘å¸ƒ
    success = pipeline.process_draft(draft, platforms)
    if success:
        print("âœ… å¤„ç†å®Œæˆ!")
    else:
        print("âš ï¸ å¤„ç†æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main()