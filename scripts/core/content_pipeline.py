import os
import re
import yaml
import logging
import subprocess
import frontmatter
# tempfileåœ¨image_processorä¸­ä½¿ç”¨
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.console import Console
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
# google.generativeaiå¯¼å…¥ç§»åŠ¨åˆ°AIå¤„ç†å™¨ä¸­
from google.generativeai.client import configure
from google.generativeai.generative_models import GenerativeModel
from google.generativeai.types import GenerationConfig
# BlockedPromptExceptionç§»åŠ¨åˆ°AIå¤„ç†å™¨ä¸­
from google.api_core.exceptions import ResourceExhausted
import argparse
import requests
from dotenv import load_dotenv

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from .wechat_publisher import WechatPublisher
from .managers.publish_manager import PublishingStatusManager
from .processors.image_processor import ImageProcessor
from .processors.ai_processor import AIProcessor
from .processors.platform_processor import PlatformProcessor
from ..utils.reward_system_manager import RewardSystemManager


class ContentPipeline:
    _instance = None  # ç±»å±æ€§ç”¨äºå•ä¾‹æ¨¡å¼
    _initialized = False  # è®°å½•æ˜¯å¦å·²åˆå§‹åŒ–
    
    def __init__(self, config_path: str = "config/pipeline_config.yml", verbose: bool = False):
        """åˆå§‹åŒ–å†…å®¹å¤„ç†ç®¡é“
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        self.verbose = verbose
        self.logger = logging.getLogger("ContentPipeline")
        self.project_root = Path(__file__).parent.parent
        
        # åˆå§‹åŒ–APIçŠ¶æ€
        self.api_available = True
        
        # è®°å½•æ˜¯å¦æ˜¯é¦–æ¬¡åˆå§‹åŒ–
        self.is_first_init = not ContentPipeline._initialized
        
        # åŠ è½½é…ç½®
        try:
            # åŠ è½½ä¸»é…ç½®æ–‡ä»¶
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            self.logger.debug(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            
            # åŠ è½½å®Œæ•´é…ç½®ï¼ˆåŒ…æ‹¬å¯¼å…¥çš„é…ç½®æ–‡ä»¶ï¼‰
            self.config = self._load_config()
            
            # åˆå§‹åŒ–å‘å¸ƒçŠ¶æ€ç®¡ç†å™¨
            drafts_dir = Path(self.config["paths"]["drafts"])
            self.status_manager = PublishingStatusManager(drafts_dir)
            
            # åˆå§‹åŒ–å›¾ç‰‡å¤„ç†å™¨
            self.image_processor = ImageProcessor(self.logger)
            
            # AIå¤„ç†å™¨å°†åœ¨æ¨¡å‹åˆå§‹åŒ–åè®¾ç½®
            self.ai_processor = None
            
            # åˆå§‹åŒ–å­˜é‡æ–‡æ¡£çŠ¶æ€
            posts_dir = Path(self.config["paths"]["posts"])
            self.status_manager.initialize_legacy_post_status(posts_dir)
            
            # åˆå§‹åŒ–å†…å®¹å˜ç°ç³»ç»Ÿç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
            self.reward_manager = None
            if self.reward_manager:
                try:
                    self.reward_manager = RewardSystemManager()
                    self.logger.debug("å†…å®¹å˜ç°ç³»ç»Ÿç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    self.logger.warning(f"å†…å®¹å˜ç°ç³»ç»Ÿç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            else:
                self.logger.debug("å†…å®¹å˜ç°ç³»ç»Ÿæ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡åˆå§‹åŒ–")
            

        except Exception as e:
            self.logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}", exc_info=True)
            raise
        
        self._setup_logging()
        
        # åŠ è½½æ¨¡æ¿å’Œå¹³å°é…ç½®
        # æ£€æŸ¥æ˜¯å¦æœ‰post_templatesé”®ï¼Œå¦‚æœæ²¡æœ‰ä½†æœ‰front_matteré”®ï¼Œåˆ™ä½¿ç”¨front_matter
        if 'post_templates' in self.config:
            self.templates = self.config['post_templates']
        elif 'front_matter' in self.config:
            self.templates = {'front_matter': self.config['front_matter']}
            if 'categories' in self.config:
                self.templates['categories'] = self.config['categories']
            if 'footer' in self.config:
                self.templates['footer'] = self.config['footer']
            self.logger.debug("ä»é…ç½®ä¸­åŠ è½½æ¨¡æ¿æˆåŠŸ")
        else:
            self.templates = {}
            self.logger.warning("æœªåŠ è½½æ¨¡æ¿æˆ–æ¨¡æ¿ä¸ºç©º")
        
        self.platforms_config = self.config.get('platforms', {})
        
        # è®¾ç½®API
        self._setup_apis()
        self._setup_site_url()

        # åˆå§‹åŒ–å‘å¸ƒå™¨
        self.wechat_publisher = None
        try:
            if self.platforms_config.get("wechat", {}).get("enabled", False):
                # Pass the initialized Gemini model to the publisher
                self.wechat_publisher = WechatPublisher(gemini_model=self.model)
                self.log("âœ… å¾®ä¿¡å‘å¸ƒå™¨åˆå§‹åŒ–æˆåŠŸ", level="debug")
        except Exception as e:
            self.log(f"âš ï¸ å¾®ä¿¡å‘å¸ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}", level="warning")
            self.log("å¾®ä¿¡å‘å¸ƒåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†ä¸å½±å“å…¶ä»–åŠŸèƒ½", level="info")
        
        # æ ‡è®°åˆå§‹åŒ–å®Œæˆ
        ContentPipeline._initialized = True
        if self.is_first_init:
            self.log("ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ", level="info")
        
    def log(self, message: str, level: str = "info", force: bool = False):
        """ç»Ÿä¸€çš„æ—¥å¿—å¤„ç†
        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            level: æ—¥å¿—çº§åˆ« (debug/info/warning/error)
            force: æ˜¯å¦å¼ºåˆ¶æ˜¾ç¤ºï¼ˆå¿½ç•¥verboseè®¾ç½®ï¼‰
        """
        # ç»Ÿä¸€ä½¿ç”¨loggingç³»ç»Ÿï¼Œè®©å¤„ç†å™¨å†³å®šçº§åˆ«è¿‡æ»¤
        logger_method = getattr(self.logger, level, self.logger.info)
        
        # å¦‚æœforce=Trueæˆ–è€…æ˜¯é«˜çº§åˆ«æ—¥å¿—ï¼Œåˆ™ç›´æ¥è®°å½•
        if force or level in ["error", "warning"]:
            logger_method(message)
        elif level == "debug":
            # DEBUGçº§åˆ«åªåœ¨verboseæ¨¡å¼ä¸‹è®°å½•
            if self.verbose:
                logger_method(message)
        else:
            # INFOçº§åˆ«æ­£å¸¸è®°å½•
            logger_method(message)
    
    def _load_config(self) -> dict:
        """åŠ è½½æ‰€æœ‰é…ç½®"""
        config_dir = Path("config")
        config = {}
        
        try:
            # åŠ è½½ä¸»é…ç½®
            with open(config_dir / "pipeline_config.yml", 'r', encoding='utf-8') as f:
                config.update(yaml.safe_load(f))
            
            # åŠ è½½å¯¼å…¥çš„é…ç½®
            for import_file in config.get("imports", []):
                try:
                    with open(config_dir / import_file, 'r', encoding='utf-8') as f:
                        imported_config = yaml.safe_load(f)
                        if imported_config:
                            # é€’å½’æ›´æ–°é…ç½®ï¼Œä¿æŒåµŒå¥—ç»“æ„
                            self._deep_update(config, imported_config)
                            self.logger.debug(f"æˆåŠŸå¯¼å…¥é…ç½®: {import_file}")
                        else:
                            self.logger.warning(f"å¯¼å…¥çš„é…ç½®ä¸ºç©º: {import_file}")
                except FileNotFoundError:
                    self.logger.warning(f"å¯¼å…¥çš„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {import_file}")
                except yaml.YAMLError as e:
                    self.logger.warning(f"å¯¼å…¥çš„é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {import_file}, {str(e)}")
                    
            return config
            
        except FileNotFoundError as e:
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {e.filename}")
            raise
        except yaml.YAMLError as e:
            logging.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
            raise
    
    def _deep_update(self, d: dict, u: dict) -> dict:
        """é€’å½’æ›´æ–°å­—å…¸ï¼Œä¿æŒåµŒå¥—ç»“æ„"""
        for k, v in u.items():
            if isinstance(v, dict):
                d[k] = self._deep_update(d.get(k, {}), v)
            else:
                d[k] = v
        return d
    
    def _setup_logging(self):
        """é…ç½®æ—¥å¿—"""
        log_path = Path(self.config["paths"]["logs"])
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ¸…é™¤æ ¹è®°å½•å™¨çš„å¤„ç†å™¨ä»¥é¿å…é‡å¤è®°å½•
        root_logger = logging.getLogger()
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # æ–‡ä»¶å¤„ç†å™¨ - ä½¿ç”¨è½®è½¬å¤„ç†å™¨é˜²æ­¢æ—¥å¿—æ–‡ä»¶è¿‡å¤§
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            log_path, 
            maxBytes=1024*1024,  # 1MB
            backupCount=3,       # ä¿ç•™3ä¸ªå¤‡ä»½æ–‡ä»¶
            encoding='utf-8'
        )
        # åªè®°å½•INFOçº§åˆ«åŠä»¥ä¸Šçš„æ¶ˆæ¯åˆ°æ–‡ä»¶
        file_handler.setLevel(logging.INFO)
        file_formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
        file_handler.setFormatter(file_formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨ - æ ¹æ®è¯¦ç»†æ¨¡å¼å†³å®šçº§åˆ«
        console_handler = logging.StreamHandler()
        if self.verbose:
            console_handler.setLevel(logging.DEBUG)
        else:
            console_handler.setLevel(logging.WARNING)  # åªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯
        console_formatter = logging.Formatter("%(levelname)s - %(message)s")
        console_handler.setFormatter(console_formatter)
        
        # ä¸å†è®¾ç½®æ ¹è®°å½•å™¨çš„å¤„ç†å™¨ï¼Œåªä½¿ç”¨ContentPipelineç‰¹å®šè®°å½•å™¨
        
        # è®¾ç½®ContentPipelineç‰¹å®šçš„loggerï¼Œä½†ä¸æ·»åŠ é‡å¤å¤„ç†å™¨
        self.logger.setLevel(logging.DEBUG)
        # é˜²æ­¢æ¶ˆæ¯ä¼ æ’­åˆ°æ ¹è®°å½•å™¨ï¼Œé¿å…é‡å¤è®°å½•
        self.logger.propagate = False
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        # åªç»™ContentPipeline loggeræ·»åŠ å¤„ç†å™¨
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # è®°å½•åˆå§‹åŒ–çŠ¶æ€ï¼ˆä»…åœ¨è¯¦ç»†æ¨¡å¼ä¸‹ï¼‰
        if self.verbose:
            self.log("ğŸ“„ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ", level="debug")
    
    def _setup_apis(self):
        """è®¾ç½®APIå®¢æˆ·ç«¯"""
        load_dotenv(override=True)  # ç¡®ä¿é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        try:
            configure(api_key=api_key)
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åç§°
            model_name = self.config["content_processing"]["gemini"]["model"]
            if self.is_first_init:
                self.log(f"ä½¿ç”¨é…ç½®çš„æ¨¡å‹: {model_name}", level="info")
            else:
                self.log(f"ä½¿ç”¨é…ç½®çš„æ¨¡å‹: {model_name}", level="debug")
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.model = GenerativeModel(model_name)
            
            # ç°åœ¨å¯ä»¥åˆå§‹åŒ–AIå¤„ç†å™¨
            self.ai_processor = AIProcessor(self.model, self.logger)
            
            # åˆå§‹åŒ–å¹³å°å¤„ç†å™¨
            self.platform_processor = PlatformProcessor(self.platforms_config, self.project_root, self.logger)
            
            # æµ‹è¯•è¿æ¥
            try:
                response = self.model.generate_content(
                    "Test connection",
                    generation_config=GenerationConfig(
                        temperature=0.1,
                        max_output_tokens=10
                    )
                )
                if response:
                    if self.is_first_init:
                        self.log("âœ… Gemini API è¿æ¥æˆåŠŸ", level="info")
                    else:
                        self.log("âœ… Gemini API è¿æ¥æˆåŠŸ", level="debug")
                    
                    # éªŒè¯æ¨¡æ¿åŠ è½½
                    self._validate_templates()
            except ResourceExhausted as e:
                self.log(f"âŒ API é…é¢å·²è€—å°½ï¼Œè¯·ç¨åå†è¯•: {str(e)}", level="error", force=True)
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç¨‹åºç»§ç»­è¿è¡Œï¼Œä½†æ ‡è®°APIä¸å¯ç”¨
                self.api_available = False
            except Exception as e:
                self.log(f"âŒ Gemini API è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}", level="error", force=True)
                self.api_available = False
        except Exception as e:
            self.log(f"âŒ è®¾ç½®APIå¤±è´¥: {str(e)}", level="error", force=True)
            raise
            
    def _validate_templates(self):
        """éªŒè¯æ¨¡æ¿æ˜¯å¦æ­£ç¡®åŠ è½½"""
        if not hasattr(self, 'templates') or not self.templates:
            self.log("æœªåŠ è½½æ¨¡æ¿æˆ–æ¨¡æ¿ä¸ºç©º", level="warning")
            return
            
        self.log(f"å·²åŠ è½½æ¨¡æ¿: {list(self.templates.keys())}", level="debug")
        self.log(f"æ¨¡æ¿å†…å®¹: {self.templates}", level="debug")
        
        # éªŒè¯å‰ç«¯æ¨¡æ¿
        if 'front_matter' in self.templates:
            if 'default' in self.templates['front_matter']:
                default_template = self.templates['front_matter']['default']
                self.log(f"é»˜è®¤å‰ç«¯æ¨¡æ¿åŒ…å« {len(default_template)} ä¸ªè®¾ç½®", level="debug")
                # æ£€æŸ¥å…³é”®è®¾ç½®
                if 'toc' in default_template and default_template['toc']:
                    self.log("âœ… ç›®å½•è®¾ç½®å·²åŠ è½½", level="debug")
                else:
                    self.log("âš ï¸ ç›®å½•è®¾ç½®æœªåŠ è½½æˆ–æœªå¯ç”¨", level="warning")
            else:
                self.log("âš ï¸ æœªæ‰¾åˆ°é»˜è®¤å‰ç«¯æ¨¡æ¿", level="warning")
                self.log(f"å¯ç”¨çš„å‰ç«¯æ¨¡æ¿: {list(self.templates['front_matter'].keys())}", level="debug")
        else:
            self.log("âš ï¸ æœªæ‰¾åˆ°å‰ç«¯æ¨¡æ¿é…ç½®", level="warning")
            
        # éªŒè¯é¡µè„šæ¨¡æ¿
        if 'footer' in self.templates:
            footer_platforms = list(self.templates['footer'].keys())
            self.log(f"é¡µè„šæ¨¡æ¿å¹³å°: {footer_platforms}", level="debug")
            
            # æ£€æŸ¥GitHub Pagesé¡µè„š
            if 'github_pages' in self.templates['footer']:
                footer_content = self.templates['footer']['github_pages']
                if footer_content and len(footer_content) > 10:
                    self.log("âœ… GitHub Pagesé¡µè„šæ¨¡æ¿å·²åŠ è½½", level="debug")
                else:
                    self.log("âš ï¸ GitHub Pagesé¡µè„šæ¨¡æ¿ä¸ºç©ºæˆ–å†…å®¹è¿‡çŸ­", level="warning")
            else:
                self.log("âš ï¸ æœªæ‰¾åˆ°GitHub Pagesé¡µè„šæ¨¡æ¿", level="warning")
        else:
            self.log("âš ï¸ æœªæ‰¾åˆ°é¡µè„šæ¨¡æ¿é…ç½®", level="warning")
    
    def list_drafts(self, filter_valid: bool = True) -> List[Path]:
        """åˆ—å‡ºæ‰€æœ‰è‰ç¨¿æ–‡ä»¶

        Args:
            filter_valid: æ˜¯å¦åªè¿”å›æœ‰æ•ˆçš„è‰ç¨¿ï¼ˆé»˜è®¤Trueï¼Œç”¨äºå‘å¸ƒï¼‰
        """
        drafts_dir = Path(self.config["paths"]["drafts"])
        all_drafts = list(drafts_dir.glob("*.md"))

        if not filter_valid:
            # è¿”å›æ‰€æœ‰è‰ç¨¿ï¼ˆç”¨äºæ ¼å¼åŒ–ç­‰æ“ä½œï¼‰
            return all_drafts

        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„è‰ç¨¿æ–‡ä»¶ï¼ˆç”¨äºå‘å¸ƒï¼‰
        valid_drafts = []
        for draft in all_drafts:
            if self._is_valid_draft(draft):
                valid_drafts.append(draft)
            # ä¸åœ¨è¿™é‡Œè¾“å‡ºæ—¥å¿—ï¼Œåœ¨select_draftä¸­ç»Ÿä¸€æ˜¾ç¤º

        return valid_drafts
    
    def analyze_draft_status(self, draft_path: Path) -> str:
        """
        åˆ†æè‰ç¨¿çŠ¶æ€ï¼Œåªæ˜¾ç¤ºä¸¥é‡é—®é¢˜ï¼ˆå‘å¸ƒæ— æ³•è‡ªåŠ¨å¤„ç†çš„ï¼‰

        Args:
            draft_path: è‰ç¨¿æ–‡ä»¶è·¯å¾„

        Returns:
            çŠ¶æ€ä¿¡æ¯å­—ç¬¦ä¸²
        """
        serious_issues = []

        try:
            # è¯»å–è‰ç¨¿å†…å®¹
            with open(draft_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åªæ£€æŸ¥ä¸¥é‡é—®é¢˜
            # 1. æ£€æŸ¥å›¾ç‰‡è·¯å¾„é—®é¢˜ï¼ˆéœ€è¦æ‰‹åŠ¨å¤„ç†ï¼‰
            image_issues = self.check_image_paths(content)
            if image_issues:
                serious_issues.append("ğŸ–¼ï¸ å›¾ç‰‡")

            # 2. æ£€æŸ¥Front Matterï¼ˆå¿…é¡»å­˜åœ¨ï¼‰
            if not content.strip().startswith('---'):
                serious_issues.append("ğŸ“‹ æ ¼å¼")

            # 3. å†…å®¹è¿‡çŸ­ï¼ˆå°äº200å­—ç¬¦æ‰ç®—ä¸¥é‡é—®é¢˜ï¼‰
            clean_content = content.replace('---', '').replace('<!-- more -->', '')
            if len(clean_content.strip()) < 200:
                serious_issues.append("ğŸ“ å†…å®¹è¿‡çŸ­")

            # æ³¨æ„ï¼šä»¥ä¸‹é—®é¢˜å‘å¸ƒæ—¶å¯è‡ªåŠ¨å¤„ç†ï¼Œä¸æ˜¾ç¤º
            # - ç¼ºå°‘<!-- more -->ï¼ˆæ ¼å¼åŒ–æ—¶ä¼šæ·»åŠ ï¼‰
            # - ç¼ºå°‘åˆ†ç±»/æ ‡ç­¾ï¼ˆå‘å¸ƒæ—¶ä¼šç”Ÿæˆï¼‰
            # - excerpté—®é¢˜ï¼ˆå‘å¸ƒæ—¶ä¼šå¤„ç†ï¼‰

        except Exception:
            serious_issues.append("âŒ è¯»å–")

        if serious_issues:
            return f" âš ï¸ [{', '.join(serious_issues)}]"
        else:
            return " âœ…"
    
    def check_image_paths(self, content: str) -> List[str]:
        """
        æ£€æŸ¥å†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„é—®é¢˜
        
        Args:
            content: æ–‡ç« å†…å®¹
            
        Returns:
            é—®é¢˜å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        return self.image_processor.check_image_paths(content)
    
    def check_draft_issues(self, draft_path: Path) -> List[str]:
        """
        æ£€æŸ¥è‰ç¨¿çš„å…·ä½“é—®é¢˜
        
        Args:
            draft_path: è‰ç¨¿æ–‡ä»¶è·¯å¾„
            
        Returns:
            é—®é¢˜æè¿°åˆ—è¡¨
        """
        issues = []
        
        try:
            with open(draft_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # 1. æ£€æŸ¥å›¾ç‰‡è·¯å¾„é—®é¢˜
            image_issues = self.check_image_paths(content)
            if image_issues:
                issues.append(f"ğŸ–¼ï¸ å›¾ç‰‡è·¯å¾„ä¸è§„èŒƒ ({len(image_issues)}ä¸ªå›¾ç‰‡éœ€è¦OneDriveå¤„ç†)")
                for img in image_issues[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ªç¤ºä¾‹
                    issues.append(f"      ä¾‹å¦‚: {img}")
                if len(image_issues) > 2:
                    issues.append(f"      ... è¿˜æœ‰{len(image_issues)-2}ä¸ªå›¾ç‰‡")
            
            # 2. æ£€æŸ¥Front Matter
            if not content.strip().startswith('---'):
                issues.append("ğŸ“‹ ç¼ºå°‘Jekyll Front Matter (éœ€è¦æ ‡é¢˜ã€åˆ†ç±»ã€æ ‡ç­¾ç­‰)")
            else:
                # è§£æFront Matteræ£€æŸ¥å¿…éœ€å­—æ®µ
                try:
                    import frontmatter
                    post = frontmatter.loads(content)
                    required_fields = ['title', 'date', 'header']
                    missing_fields = [field for field in required_fields if field not in post.metadata]
                    if missing_fields:
                        issues.append(f"ğŸ“‹ Front Matterç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
                    
                    # æ£€æŸ¥ç‰¹å®šå­—æ®µæ ¼å¼
                    if 'title' in post.metadata:
                        title_len = len(str(post.metadata['title']))
                        if title_len < 10:
                            issues.append("ğŸ“ æ ‡é¢˜è¿‡çŸ­ï¼Œå»ºè®®25-35å­—ç¬¦")
                        elif title_len > 60:
                            issues.append("ğŸ“ æ ‡é¢˜è¿‡é•¿ï¼Œå»ºè®®25-35å­—ç¬¦")
                    
                    if 'header' in post.metadata and isinstance(post.metadata['header'], dict):
                        if 'teaser' in post.metadata['header']:
                            teaser_path = str(post.metadata['header']['teaser'])
                            if teaser_path.startswith('c:') or teaser_path.startswith('C:'):
                                issues.append("ğŸ–¼ï¸ å¤´å›¾ä½¿ç”¨äº†æœ¬åœ°è·¯å¾„ï¼Œéœ€è¦OneDriveå¤„ç†")
                    
                    # æ£€æŸ¥VIPæ–‡ç« çš„ç‰¹æ®Šè¦æ±‚
                    member_tier = post.metadata.get('member_tier')
                    if member_tier and member_tier != 'free':
                        # æ£€æŸ¥VIPæ–‡ç« å¿…é¡»æœ‰member-postå¸ƒå±€
                        if post.metadata.get('layout') != 'member-post':
                            issues.append("ğŸ” VIPæ–‡ç« ç¼ºå°‘ 'layout: member-post' è®¾ç½®ï¼Œè®¿é—®æ§åˆ¶å°†å¤±æ•ˆ")
                        
                        # æ£€æŸ¥VIPç­‰çº§åˆæ³•æ€§
                        valid_tiers = ['experience', 'monthly', 'quarterly', 'yearly']
                        if member_tier not in valid_tiers:
                            issues.append(f"ğŸ” æ— æ•ˆçš„ä¼šå‘˜ç­‰çº§: {member_tier}ï¼Œæœ‰æ•ˆå€¼: {', '.join(valid_tiers)}")
                        
                        # æ£€æŸ¥VIPæ–‡ç« æ ‡é¢˜æ˜¯å¦åŒ…å«ç­‰çº§æ ‡è¯†
                        title = str(post.metadata.get('title', ''))
                        vip_indicators = ['VIP2', 'VIP3', 'VIP4', 'ä¸“äº«', 'ä¼šå‘˜']
                        if not any(indicator in title for indicator in vip_indicators):
                            issues.append("ğŸ” VIPæ–‡ç« æ ‡é¢˜å»ºè®®åŒ…å«ç­‰çº§æ ‡è¯† (å¦‚ VIP2ä¸“äº«ã€VIP3ä¸“äº«)")
                
                except Exception as e:
                    # åªæŠ¥å‘Šä¸€æ¬¡Front Matteré”™è¯¯ï¼Œé¿å…é‡å¤
                    if "while parsing" not in str(e):
                        issues.append(f"ğŸ“‹ Front Matteræ ¼å¼é”™è¯¯: {str(e)}")
            
            # 3. æ£€æŸ¥å†…å®¹ç»“æ„
            if '<!-- more -->' not in content:
                issues.append("âœ‚ï¸ ç¼ºå°‘é¦–é¡µåˆ†é¡µæ ‡è®° <!-- more -->ï¼Œæ ¼å¼åŒ–å·¥å…·ä¼šè‡ªåŠ¨æ·»åŠ ")
            
            if 'excerpt:' not in content and content.strip().startswith('---'):
                issues.append("ğŸ“„ ç¼ºå°‘æ‘˜è¦å­—æ®µ (excerpt) å½±å“SEO")
            
            # æ£€æŸ¥æ‘˜è¦é•¿åº¦è§„èŒƒï¼ˆæ–°å¢ï¼‰
            summary_issues = self._check_summary_lengths(content)
            issues.extend(summary_issues)
            
            # 4. æ£€æŸ¥å†…å®¹è´¨é‡
            clean_content = content.replace('---', '').replace('<!-- more -->', '')
            content_lines = [line.strip() for line in clean_content.split('\n') if line.strip()]
            
            if len(clean_content.strip()) < 500:
                issues.append("ğŸ“ å†…å®¹è¿‡çŸ­ (å»ºè®®è‡³å°‘500å­—ç¬¦)")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„ç»“å°¾
            if len(content_lines) > 0:
                # è¿‡æ»¤æ‰Jekyllæ ¼å¼çš„ç»“å°¾è¡Œï¼Œåªæ£€æŸ¥å®é™…æ–‡ç« å†…å®¹
                content_ending_lines = []
                for line in reversed(content_lines):
                    # è·³è¿‡Jekyllæ¨¡æ¿ã€æ‰“èµé“¾æ¥ã€è¯„è®ºæç¤ºç­‰æ ¼å¼åŒ–å†…å®¹
                    if any(pattern in line for pattern in [
                        '{% ', '%}', '{{', '}}',  # Jekyllæ¶²ä½“æ¨¡æ¿
                        'GitHub è´¦å·', 'å‘è¡¨è¯„è®º', 'è¯·æˆ‘å–å’–å•¡',  # æ ‡å‡†é¡µè„š
                        '<a href', '<img src', '](http',  # HTMLå’Œé“¾æ¥
                        'ğŸ’¬', 'â˜•', 'ğŸ’°', 'ğŸ¯'  # é¡µè„šå¸¸ç”¨emoji
                    ]):
                        continue
                    # æ‰¾åˆ°å®é™…å†…å®¹è¡Œ
                    content_ending_lines.append(line)
                    if len(content_ending_lines) >= 3:  # æ£€æŸ¥æœ€å3è¡Œå®é™…å†…å®¹
                        break
                
                # æ£€æŸ¥æœ€åçš„å®é™…å†…å®¹æ˜¯å¦æœ‰åˆé€‚çš„ç»“å°¾
                if content_ending_lines:
                    last_content_line = content_ending_lines[0]
                    # é™ä½ç»“å°¾è¦æ±‚ï¼Œè€ƒè™‘åˆ°æœ‰äº›æ–‡ç« ä»¥æ¸…å•ã€å¼•ç”¨ç­‰ç»“å°¾
                    if (len(last_content_line) < 15 and 
                        not any(punct in last_content_line for punct in ['ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!']) and
                        not any(ending in last_content_line for ending in ['æ€è€ƒ', 'æ€»ç»“', 'å±•æœ›', 'å‚è€ƒ', 'èµ„æ–™', 'æ¸…å•'])):
                        issues.append("ğŸ“ æ–‡ç« å¯èƒ½æ²¡æœ‰åˆé€‚çš„ç»“å°¾æ®µè½")
            
            # 5. æ£€æŸ¥åˆ†ç±»æ ‡ç­¾
            if content.strip().startswith('---'):
                try:
                    import frontmatter
                    post = frontmatter.loads(content)
                    if 'categories' not in post.metadata and 'category' not in post.metadata:
                        issues.append("ğŸ·ï¸ ç¼ºå°‘åˆ†ç±»ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨å››å¤§åˆ†ç±»ä¹‹ä¸€")
                    
                    if 'tags' not in post.metadata or not post.metadata.get('tags'):
                        issues.append("ğŸ·ï¸ ç¼ºå°‘æ ‡ç­¾ä¿¡æ¯ï¼Œæœ‰åŠ©äºå†…å®¹å‘ç°")
                except:
                    pass  # Front Matterå·²æ£€æŸ¥è¿‡
                    
        except Exception as e:
            issues.append(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
        
        return issues
    
    def _clean_content_for_length_check(self, content: str) -> str:
        """æ¸…ç†å†…å®¹ç”¨äºé•¿åº¦æ£€æŸ¥ï¼Œç§»é™¤Markdownè¯­æ³•æ ‡è®°"""
        import re
        clean = re.sub(r'!\[[^\]]*\]\([^)]*\)', '', content)  # å›¾ç‰‡
        clean = re.sub(r'\[[^\]]*\]\([^)]*\)', '', clean)     # é“¾æ¥
        clean = re.sub(r'`[^`]*`', '', clean)                 # å†…è”ä»£ç 
        clean = re.sub(r'```[^`]*```', '', clean, flags=re.DOTALL)  # ä»£ç å—
        clean = re.sub(r'^#+\s*', '', clean, flags=re.MULTILINE)    # æ ‡é¢˜
        clean = re.sub(r'^\s*[-*+]\s*', '', clean, flags=re.MULTILINE)  # åˆ—è¡¨
        clean = re.sub(r'^\s*>\s*', '', clean, flags=re.MULTILINE)      # å¼•ç”¨
        clean = re.sub(r'\*\*([^*]*)\*\*', r'\1', clean)     # ç²—ä½“
        clean = re.sub(r'\*([^*]*)\*', r'\1', clean)         # æ–œä½“
        clean = re.sub(r'~~([^~]*)~~', r'\1', clean)         # åˆ é™¤çº¿
        return clean
    
    def _extract_body_before_more(self, content: str) -> str:
        """æå–Front Matterååˆ°<!-- more -->ä¹‹é—´çš„å†…å®¹"""
        if content.strip().startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                body_content = parts[2].strip()
                more_pos = body_content.find('<!-- more -->')
                if more_pos != -1:
                    return body_content[:more_pos].strip()
        return ""
    
    def _check_summary_lengths(self, content: str) -> List[str]:
        """æ£€æŸ¥excerptå­—æ®µå’Œ<!-- more -->å‰å†…å®¹çš„é•¿åº¦è§„èŒƒ"""
        issues = []

        try:
            # 1. æ£€æŸ¥excerptå­—æ®µé•¿åº¦
            if content.strip().startswith('---'):
                import frontmatter
                post = frontmatter.loads(content)
                excerpt = post.metadata.get('excerpt', '')

                if not excerpt:
                    issues.append("ğŸ“ ç¼ºå°‘excerptå­—æ®µï¼Œå°†ä½¿ç”¨Geminiè‡ªåŠ¨ç”Ÿæˆ")
                else:
                    excerpt_len = len(excerpt.strip())
                    if excerpt_len < 40:
                        issues.append(f"ğŸ“ excerptè¿‡çŸ­({excerpt_len}å­—ç¬¦)ï¼Œå»ºè®®50å­—ç¬¦å·¦å³")
                    elif excerpt_len > 70:
                        issues.append(f"ğŸ“ excerptè¿‡é•¿({excerpt_len}å­—ç¬¦)ï¼Œå»ºè®®50å­—ç¬¦å·¦å³")

            # 2. æ£€æŸ¥<!-- more -->å‰å†…å®¹é•¿åº¦
            # æ³¨æ„ï¼šå¦‚æœæ–‡ä»¶åˆšè¢«æ ¼å¼åŒ–è¿‡ï¼Œä¸å†é‡å¤æ£€æŸ¥<!-- more -->å‰å†…å®¹
            # æ ¼å¼åŒ–å·¥å…·å·²ç»å¤„ç†äº†<!-- more -->çš„æ’å…¥ä½ç½®
            more_pos = content.find('<!-- more -->')
            if more_pos != -1:
                before_more = self._extract_body_before_more(content)
                if before_more:
                    # æ¸…ç†å†…å®¹ï¼Œç§»é™¤å¼•ç”¨å—ã€æ ‡é¢˜ç­‰
                    clean_content = self._clean_content_for_length_check(before_more)
                    # è¿‡æ»¤æ‰åªåŒ…å«å¼•ç”¨æˆ–ä¿¡æ¯çŠ¶æ€çš„å†…å®¹
                    actual_content_lines = []
                    for line in clean_content.split('\n'):
                        line = line.strip()
                        if line and not line.startswith(('>', '*', '-', '#')):
                            actual_content_lines.append(line)

                    actual_content = ' '.join(actual_content_lines)
                    clean_length = len(actual_content.strip())

                    # åªæœ‰å½“å®é™…å†…å®¹ç¡®å®è¿‡çŸ­æˆ–è¿‡é•¿æ—¶æ‰æŠ¥å‘Š
                    # è€ƒè™‘åˆ°å¼•ç”¨å—ç­‰ç‰¹æ®Šæƒ…å†µï¼Œæ”¾å®½é™åˆ¶
                    if actual_content and clean_length < 30:
                        issues.append(f"ğŸ“ <!-- more -->å‰å†…å®¹è¿‡çŸ­({clean_length}å­—ç¬¦)ï¼Œå»ºè®®æ·»åŠ ç®€çŸ­ä»‹ç»")
                    elif clean_length > 150:
                        issues.append(f"ğŸ“ <!-- more -->å‰å†…å®¹è¿‡é•¿({clean_length}å­—ç¬¦)ï¼Œå»ºè®®ç²¾ç®€é¦–é¡µé¢„è§ˆ")

        except Exception as e:
            # é™é»˜å¤„ç†ï¼Œé¿å…é‡å¤æŠ¥é”™
            pass

        return issues
    
    def _auto_generate_excerpt_if_missing(self, draft_path: Path, content: str) -> bool:
        """å¦‚æœç¼ºå°‘excerptå­—æ®µï¼Œè‡ªåŠ¨ç”Ÿæˆå¹¶æ›´æ–°æ–‡ä»¶"""
        try:
            if not content.strip().startswith('---'):
                return False
                
            import frontmatter
            post = frontmatter.loads(content)
            
            if 'excerpt' not in post.metadata or not post.metadata['excerpt']:
                self.log("æ£€æµ‹åˆ°ç¼ºå°‘excerptï¼Œæ­£åœ¨ä½¿ç”¨Geminiç”Ÿæˆ...", level="info", force=True)
                print("ğŸ¤– æ£€æµ‹åˆ°ç¼ºå°‘excerptï¼Œæ­£åœ¨ä½¿ç”¨Geminiç”Ÿæˆ...")
                
                # è°ƒç”¨AIç”Ÿæˆexcerpt
                if self.ai_processor:
                    generated_excerpt = self.ai_processor.generate_excerpt(content)
                    if generated_excerpt and generated_excerpt != "è¿™æ˜¯ä¸€ç¯‡æœ‰ä»·å€¼çš„æ–‡ç« ï¼Œå€¼å¾—é˜…è¯»ã€‚":
                        # æ›´æ–°front matter
                        post.metadata['excerpt'] = generated_excerpt
                        
                        # é‡æ–°æ„å»ºæ–‡ä»¶å†…å®¹
                        updated_content = frontmatter.dumps(post)
                        
                        # å†™å›æ–‡ä»¶
                        with open(draft_path, 'w', encoding='utf-8') as f:
                            f.write(updated_content)
                        
                        print(f"âœ… å·²è‡ªåŠ¨ç”Ÿæˆexcerpt: {generated_excerpt}")
                        self.log(f"âœ… è‡ªåŠ¨ç”ŸæˆexcerptæˆåŠŸ: {generated_excerpt}", level="info", force=True)
                        return True
                    else:
                        print("âŒ Gemini excerptç”Ÿæˆå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ·»åŠ ")
                        self.log("âŒ Gemini excerptç”Ÿæˆå¤±è´¥", level="warning")
                        return False
                else:
                    print("âŒ AIå¤„ç†å™¨ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆexcerpt")
                    self.log("âŒ AIå¤„ç†å™¨ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆexcerpt", level="warning")
                    return False
            
            return True
            
        except Exception as e:
            print(f"âŒ excerptç”Ÿæˆå¼‚å¸¸: {str(e)}")
            self.log(f"âŒ excerptç”Ÿæˆå¼‚å¸¸: {str(e)}", level="error")
            return False
    
    def _get_summary_fix_suggestions(self, issues: List[str]) -> List[str]:
        """æ ¹æ®æ‘˜è¦é—®é¢˜æä¾›ä¿®å¤å»ºè®®"""
        suggestions = []
        
        for issue in issues:
            if "excerptè¿‡çŸ­" in issue:
                suggestions.append("ğŸ’¡ å»ºè®®: ä¸°å¯Œexcerptæè¿°ï¼Œæˆ–ä½¿ç”¨Geminié‡æ–°ç”Ÿæˆ")
            elif "excerptè¿‡é•¿" in issue:
                suggestions.append("ğŸ’¡ å»ºè®®: ç²¾ç®€excerptå†…å®¹ï¼Œä¿ç•™æ ¸å¿ƒè¦ç‚¹")
            elif "<!-- more -->å‰å†…å®¹è¿‡çŸ­" in issue:
                suggestions.append("ğŸ’¡ å»ºè®®: åœ¨<!-- more -->å‰æ·»åŠ èƒŒæ™¯è¯´æ˜æˆ–å¼•è¨€")
            elif "<!-- more -->å‰å†…å®¹è¿‡é•¿" in issue:
                suggestions.append("ğŸ’¡ å»ºè®®: å°†éƒ¨åˆ†å†…å®¹ç§»è‡³<!-- more -->åï¼Œä¿ç•™ç²¾åå¼€å¤´")
            elif "ç¼ºå°‘excerpt" in issue:
                suggestions.append("ğŸ’¡ ç³»ç»Ÿå°†è‡ªåŠ¨è°ƒç”¨Geminiç”Ÿæˆexcerpt")
        
        return suggestions
    
    def comprehensive_content_check(self, file_path: Path, auto_fix: bool = False) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„å†…å®¹è´¨é‡æ£€æŸ¥å’Œä¿®å¤æ¥å£
        
        Args:
            file_path: è¦æ£€æŸ¥çš„æ–‡ä»¶è·¯å¾„
            auto_fix: æ˜¯å¦è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸ï¼ŒåŒ…å«é—®é¢˜åˆ—è¡¨ã€ä¿®å¤çŠ¶æ€ç­‰
        """
        results = {
            'file_path': str(file_path),
            'issues': [],
            'auto_fixes_applied': [],
            'manual_fixes_needed': [],
            'check_passed': False,
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            # 1. æ‰§è¡Œå®Œæ•´çš„è‰ç¨¿é—®é¢˜æ£€æŸ¥
            issues = self.check_draft_issues(file_path)
            results['issues'] = issues
            
            if not issues:
                results['check_passed'] = True
                self.log(f"âœ… å†…å®¹è´¨é‡æ£€æŸ¥é€šè¿‡: {file_path.name}", level="info")
                return results
            
            # 2. å°è¯•è‡ªåŠ¨ä¿®å¤
            if auto_fix:
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è‡ªåŠ¨ä¿®å¤excerptç¼ºå¤±
                excerpt_issues = [issue for issue in issues if "ç¼ºå°‘excerptå­—æ®µ" in issue]
                if excerpt_issues:
                    if self._auto_generate_excerpt_if_missing(file_path, content):
                        results['auto_fixes_applied'].append("è‡ªåŠ¨ç”Ÿæˆexcerptå­—æ®µ")
                        # é‡æ–°è¯»å–æ›´æ–°åçš„å†…å®¹
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                
                # é‡æ–°æ£€æŸ¥ï¼Œæ›´æ–°é—®é¢˜åˆ—è¡¨
                updated_issues = self.check_draft_issues(file_path)
                results['issues'] = updated_issues
                
                if not updated_issues:
                    results['check_passed'] = True
            
            # 3. åˆ†ç±»å‰©ä½™é—®é¢˜
            for issue in results['issues']:
                if any(keyword in issue for keyword in ["excerpt", "more", "æ‘˜è¦"]):
                    # æ‘˜è¦ç›¸å…³é—®é¢˜éœ€è¦æ‰‹åŠ¨å¤„ç†
                    results['manual_fixes_needed'].append({
                        'issue': issue,
                        'category': 'summary',
                        'suggestions': self._get_summary_fix_suggestions([issue])
                    })
                elif "å›¾ç‰‡" in issue:
                    # å›¾ç‰‡ç›¸å…³é—®é¢˜
                    results['manual_fixes_needed'].append({
                        'issue': issue,
                        'category': 'images',
                        'suggestions': ["ä½¿ç”¨OneDriveå›¾åºŠç®¡ç†å¤„ç†å›¾ç‰‡è·¯å¾„"]
                    })
                elif any(keyword in issue for keyword in ["æ ¼å¼", "åˆ†é¡µ"]):
                    # æ ¼å¼ç›¸å…³é—®é¢˜ï¼ˆé•¿åº¦é—®é¢˜å•ç‹¬å¤„ç†ï¼‰
                    results['manual_fixes_needed'].append({
                        'issue': issue,
                        'category': 'format',
                        'suggestions': ["ä½¿ç”¨å†…å®¹è§„èŒƒåŒ–å¤„ç†ä¿®å¤æ ¼å¼é—®é¢˜"]
                    })
                elif "é•¿åº¦" in issue and "<!-- more -->" in issue:
                    # <!-- more -->å‰å†…å®¹é•¿åº¦é—®é¢˜ï¼Œé€šå¸¸å·²ç”±æ ¼å¼åŒ–å·¥å…·å¤„ç†
                    # é™ä½ä¼˜å…ˆçº§ï¼Œä½œä¸ºæç¤ºè€Œéé”™è¯¯
                    results['manual_fixes_needed'].append({
                        'issue': issue,
                        'category': 'info',
                        'suggestions': ["æ ¼å¼åŒ–å·¥å…·å·²ä¼˜åŒ–<!-- more -->ä½ç½®ï¼Œæ­¤æç¤ºä»…ä¾›å‚è€ƒ"]
                    })
                else:
                    # å…¶ä»–é—®é¢˜
                    results['manual_fixes_needed'].append({
                        'issue': issue,
                        'category': 'other',
                        'suggestions': ["éœ€è¦æ‰‹åŠ¨æ£€æŸ¥å’Œä¿®å¤"]
                    })
            
            # 4. è®°å½•å¤„ç†ç»“æœ
            if results['auto_fixes_applied']:
                self.log(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤å®Œæˆ: {', '.join(results['auto_fixes_applied'])}", level="info")
            
            if results['manual_fixes_needed']:
                self.log(f"âš ï¸ éœ€è¦æ‰‹åŠ¨å¤„ç† {len(results['manual_fixes_needed'])} ä¸ªé—®é¢˜", level="warning")
            else:
                results['check_passed'] = True
                
        except Exception as e:
            self.log(f"âŒ å†…å®¹è´¨é‡æ£€æŸ¥å¼‚å¸¸: {str(e)}", level="error")
            results['issues'].append(f"æ£€æŸ¥è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        
        return results
    
    def get_preprocessing_suggestions(self, issues: List[str]) -> List[str]:
        """
        æ ¹æ®é—®é¢˜æä¾›é¢„å¤„ç†å»ºè®®
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            
        Returns:
            å»ºè®®åˆ—è¡¨
        """
        suggestions = []
        
        # åˆ†æé—®é¢˜ç±»å‹å¹¶ç»™å‡ºç›¸åº”å»ºè®®
        has_image_issues = any('å›¾ç‰‡' in issue for issue in issues)
        has_format_issues = any(any(keyword in issue for keyword in ['Front Matter', 'åˆ†é¡µ', 'æ‘˜è¦', 'å†…å®¹è¿‡çŸ­']) for issue in issues)
        
        if has_image_issues:
            suggestions.append("ğŸ–¼ï¸  14. OneDriveå›¾åºŠç®¡ç† - å¤„ç†å›¾ç‰‡ä¸Šä¼ å’Œè·¯å¾„è§„èŒƒåŒ–")
        
        if has_format_issues:
            suggestions.append("ğŸ“ 4. å†…å®¹è§„èŒƒåŒ–å¤„ç† - å®Œå–„Front Matterå’Œå†…å®¹ç»“æ„")
        
        if not suggestions:
            suggestions.append("ğŸ“‹ å»ºè®®å…ˆæ£€æŸ¥æ–‡ä»¶å†…å®¹å’Œæ ¼å¼æ˜¯å¦ç¬¦åˆJekyllè§„èŒƒ")
        
        suggestions.append("ğŸ’¡ æˆ–è€…ç»§ç»­å‘å¸ƒï¼Œç³»ç»Ÿä¼šå°è¯•è‡ªåŠ¨å¤„ç†éƒ¨åˆ†é—®é¢˜")
        
        return suggestions
    
    def select_draft(self) -> Optional[Path] | str:
        """è®©ç”¨æˆ·é€‰æ‹©è¦å¤„ç†çš„è‰ç¨¿"""
        # è·å–æ‰€æœ‰è‰ç¨¿ï¼ŒåŒ…æ‹¬æ— æ•ˆçš„
        all_drafts = self.list_drafts(filter_valid=False)
        valid_drafts = self.list_drafts(filter_valid=True)

        # åˆ†ç¦»æœ‰æ•ˆå’Œæ— æ•ˆè‰ç¨¿
        invalid_drafts = [d for d in all_drafts if d not in valid_drafts]

        if not valid_drafts and not invalid_drafts:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°è§„èŒƒåŒ–è‰ç¨¿æ–‡ä»¶")
            print("\nğŸ” å¿«é€Ÿåˆ›ä½œå»ºè®®ï¼š")
            print("   ğŸ¯ 5. ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨ - AIç”Ÿæˆæ–‡ç« ä¸»é¢˜å’Œå¤§çº²")
            print("   ğŸ¬ 8. YouTubeæ’­å®¢ç”Ÿæˆå™¨ - å°†YouTubeè§†é¢‘è½¬æ¢ä¸ºæ–‡ç« ")
            print("   ğŸ“ 4. å†…å®¹è§„èŒƒåŒ–å¤„ç† - å¤„ç†æ‰‹å·¥è‰ç¨¿æˆ–å…¶ä»–å†…å®¹")
            print("   ğŸ“„ 3. ç”Ÿæˆæµ‹è¯•æ–‡ç«  - å¿«é€Ÿç”Ÿæˆç¤ºä¾‹å†…å®¹")
            
            print("\nğŸ› ï¸ å…¶ä»–é€‰é¡¹ï¼š")
            print("   ğŸ“ æ‰‹å·¥åˆ›å»ºï¼šåœ¨ _drafts/ ç›®å½•åˆ›å»º .md æ–‡ä»¶")
            print("   ğŸ“° 2. é‡æ–°å‘å¸ƒå·²å‘å¸ƒæ–‡ç«  - å°†å·²å‘å¸ƒæ–‡ç« è½¬ä¸ºè‰ç¨¿")
            
            print("\nğŸ’¡ æ¨èå·¥ä½œæµç¨‹ï¼š")
            print("   åˆ›ä½œå†…å®¹ â†’ 4.å†…å®¹è§„èŒƒåŒ–å¤„ç† â†’ 1.å‘å¸ƒè§„èŒƒåŒ–è‰ç¨¿")
            
            while True:
                choice = input("\né€‰æ‹©å¿«é€Ÿæ“ä½œ (5=çµæ„Ÿç”Ÿæˆ/8=YouTube/4=è§„èŒƒåŒ–/3=æµ‹è¯•/N=è¿”å›): ").strip().lower()
                if choice == '5':
                    print("ğŸ¯ æ­£åœ¨è·³è½¬åˆ°ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨...")
                    return 'redirect_to_inspiration'  # ç‰¹æ®Šè¿”å›å€¼
                elif choice == '8':
                    print("ğŸ¬ æ­£åœ¨è·³è½¬åˆ°YouTubeæ’­å®¢ç”Ÿæˆå™¨...")
                    return 'redirect_to_youtube'  # ç‰¹æ®Šè¿”å›å€¼
                elif choice == '4':
                    print("ğŸ“ æ­£åœ¨è·³è½¬åˆ°å†…å®¹è§„èŒƒåŒ–å¤„ç†...")
                    return 'redirect_to_normalization'  # ç‰¹æ®Šè¿”å›å€¼
                elif choice == '3':
                    return self.generate_test_content()
                elif choice in ['n', 'no', '']:
                    return None
                else:
                    print("è¯·è¾“å…¥ 5ã€8ã€4ã€3 æˆ– N")
            
        # æ˜¾ç¤ºè‰ç¨¿åˆ—è¡¨
        if invalid_drafts:
            invalid_names = [d.name for d in invalid_drafts]
            if len(invalid_names) == 1:
                print(f"\nWARNING - âš ï¸ è‰ç¨¿ç¼ºå°‘Front Matterï¼Œéœ€è¦å…ˆæ ¼å¼åŒ–: {invalid_names[0]}")
            else:
                print(f"\nWARNING - âš ï¸ ä»¥ä¸‹è‰ç¨¿ç¼ºå°‘Front Matterï¼Œéœ€è¦å…ˆæ ¼å¼åŒ–:")
                for name in invalid_names:
                    print(f"  - {name}")
            print("")

        print("å¯ç”¨çš„è‰ç¨¿æ–‡ä»¶ï¼š")
        if valid_drafts:
            for i, draft in enumerate(valid_drafts, 1):
                # æ£€æŸ¥è‰ç¨¿çŠ¶æ€å’Œé—®é¢˜
                status_info = self.analyze_draft_status(draft)
                print(f"{i}. {draft.name}{status_info}")
        else:
            print("ï¼ˆæ²¡æœ‰æœ‰æ•ˆçš„è‰ç¨¿æ–‡ä»¶ï¼‰")
        print("0. é€€å‡º")
            
        while True:
            try:
                choice = int(input("\nè¯·é€‰æ‹©è¦å¤„ç†çš„è‰ç¨¿ (è¾“å…¥åºå·ï¼Œ0é€€å‡º): "))
                if choice == 0:
                    return None
                if 1 <= choice <= len(valid_drafts):
                    selected_draft = valid_drafts[choice-1]
                    
                    # æ£€æŸ¥é€‰æ‹©çš„è‰ç¨¿æ˜¯å¦æœ‰ä¸¥é‡é—®é¢˜
                    issues = self.check_draft_issues(selected_draft)

                    # è¿‡æ»¤å‡ºä¸¥é‡é—®é¢˜ï¼ˆå‘å¸ƒæ— æ³•è‡ªåŠ¨è§£å†³çš„ï¼‰
                    serious_issues = []
                    for issue in issues:
                        # ä»¥ä¸‹é—®é¢˜å‘å¸ƒæ—¶å¯ä»¥è‡ªåŠ¨å¤„ç†ï¼Œä¸éœ€è¦æç¤º
                        auto_fixable = [
                            'ç¼ºå°‘åˆ†ç±»ä¿¡æ¯',
                            'ç¼ºå°‘æ ‡ç­¾ä¿¡æ¯',
                            'excerptè¿‡çŸ­',
                            'excerptè¿‡é•¿',
                            'ç¼ºå°‘excerptå­—æ®µ'
                        ]
                        if not any(fixable in issue for fixable in auto_fixable):
                            serious_issues.append(issue)

                    if serious_issues:
                        print(f"\nâš ï¸  è‰ç¨¿ '{selected_draft.name}' æ£€æµ‹åˆ°éœ€è¦æ‰‹åŠ¨å¤„ç†çš„é—®é¢˜ï¼š")
                        for issue in serious_issues:
                            print(f"   â€¢ {issue}")

                        print("\nğŸ”§ å»ºè®®çš„é¢„å¤„ç†æ­¥éª¤ï¼š")
                        print("   ğŸ“ 4. å†…å®¹è§„èŒƒåŒ–å¤„ç† - ä¿®å¤ç»“æ„é—®é¢˜")

                        proceed = input("\næ˜¯å¦ç»§ç»­å‘å¸ƒï¼Ÿç³»ç»Ÿå°†å°è¯•è‡ªåŠ¨å¤„ç†å…¶ä»–é—®é¢˜ (y/N): ").strip().lower()
                        if proceed not in ['y', 'yes']:
                            print("ğŸ’¡ æ‚¨å¯ä»¥å…ˆå¤„ç†è¿™äº›é—®é¢˜ï¼Œç„¶åå†å›æ¥å‘å¸ƒ")
                            continue
                    
                    return selected_draft
                print("æ— æ•ˆçš„é€‰æ‹©")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def list_published_posts(self, days_limit: int = 30) -> List[Path]:
        """åˆ—å‡ºå·²å‘å¸ƒçš„æ–‡ç« 

        Args:
            days_limit: åªæ˜¾ç¤ºæœ€è¿‘Nå¤©å†…çš„æ–‡ç« ï¼Œé»˜è®¤30å¤©
        """
        posts_dir = Path(self.config["paths"]["posts"])
        if not posts_dir.exists():
            return []

        import time
        from datetime import datetime, timedelta

        # è®¡ç®—æ—¶é—´é™åˆ¶
        cutoff_time = time.time() - (days_limit * 24 * 60 * 60)

        posts = []
        older_posts_count = 0

        for file in posts_dir.glob("*.md"):
            if file.is_file():
                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                if file.stat().st_mtime >= cutoff_time:
                    posts.append(file)
                else:
                    older_posts_count += 1

        # å¦‚æœæœ‰æ›´æ—©çš„æ–‡ç« ï¼Œæç¤ºç”¨æˆ·
        if older_posts_count > 0:
            print(f"\nğŸ’¡ æç¤ºï¼šè¿˜æœ‰ {older_posts_count} ç¯‡è¶…è¿‡ {days_limit} å¤©çš„æ–‡ç« æœªæ˜¾ç¤º")
            print(f"   å¦‚éœ€å‘å¸ƒæ›´æ—©çš„æ–‡ç« ï¼Œè¯·æ‰‹å·¥ç¼–è¾‘ _drafts/.publishing/ ç›®å½•ä¸‹å¯¹åº”çš„ymlæ–‡ä»¶")
            print(f"   å°† 'published_platforms: - github_pages' æ·»åŠ åˆ°æ–‡ä»¶ä¸­\n")

        return sorted(posts, key=lambda x: x.stat().st_mtime, reverse=True)
    
    def select_published_post(self) -> Optional[Path]:
        """è®©ç”¨æˆ·é€‰æ‹©è¦é‡æ–°å‘å¸ƒçš„å·²å‘å¸ƒæ–‡ç« """
        posts = self.list_published_posts()
        if not posts:
            print("æ²¡æœ‰æ‰¾åˆ°å·²å‘å¸ƒçš„æ–‡ç« ")
            return None
            
        print("\nå¯ç”¨çš„å·²å‘å¸ƒæ–‡ç« ï¼š")
        for i, post in enumerate(posts, 1):
            # è·å–æ–‡ç« çš„å‘å¸ƒçŠ¶æ€
            article_name = post.stem
            published_platforms = self.status_manager.get_published_platforms(article_name)
            
            if published_platforms:
                platforms_str = ", ".join(published_platforms)
                print(f"{i}. {post.name} [å·²å‘å¸ƒ: {platforms_str}]")
            else:
                print(f"{i}. {post.name} [æœªå‘å¸ƒåˆ°ä»»ä½•å¹³å°]")
        print("0. é€€å‡º")
            
        while True:
            try:
                choice = int(input("\nè¯·é€‰æ‹©è¦é‡æ–°å‘å¸ƒçš„æ–‡ç«  (è¾“å…¥åºå·ï¼Œ0é€€å‡º): "))
                if choice == 0:
                    return None
                if 1 <= choice <= len(posts):
                    return posts[choice-1]
                print("æ— æ•ˆçš„é€‰æ‹©")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    def copy_post_to_draft(self, post_path: Path) -> Optional[Path]:
        """å°†å·²å‘å¸ƒæ–‡ç« ä½œä¸ºæºæ–‡ä»¶å¤åˆ¶åˆ°è‰ç¨¿ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
        try:
            drafts_dir = Path(self.config["paths"]["drafts"])
            drafts_dir.mkdir(exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰åŒåè‰ç¨¿ï¼ˆæºæ–‡ä»¶ï¼‰
            original_draft_path = drafts_dir / post_path.name
            
            if original_draft_path.exists():
                # å¦‚æœè‰ç¨¿å·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨è‰ç¨¿ä½œä¸ºæºæ–‡ä»¶
                self.log(f"ä½¿ç”¨ç°æœ‰è‰ç¨¿ä½œä¸ºæºæ–‡ä»¶: {original_draft_path}", level="info", force=True)
                return original_draft_path
            else:
                # å¦‚æœè‰ç¨¿ä¸å­˜åœ¨ï¼Œä»å·²å‘å¸ƒæ–‡ç« åˆ›å»ºæºæ–‡ä»¶
                # éœ€è¦æ¸…ç†å‘å¸ƒæ—¶æ·»åŠ çš„å†…å®¹ï¼Œæ¢å¤ä¸ºæºæ–‡ä»¶æ ¼å¼
                source_content = self._convert_published_to_source(post_path)
                
                with open(original_draft_path, 'w', encoding='utf-8') as f:
                    f.write(source_content)
                
                self.log(f"å·²ä»å‘å¸ƒæ–‡ç« åˆ›å»ºæºæ–‡ä»¶: {original_draft_path}", level="info", force=True)
                return original_draft_path
            
        except Exception as e:
            self.log(f"å¤„ç†æ–‡ç« æºæ–‡ä»¶å¤±è´¥: {str(e)}", level="error", force=True)
            return None
    
    def _convert_published_to_source(self, post_path: Path) -> str:
        """å°†å·²å‘å¸ƒæ–‡ç« è½¬æ¢å›æºæ–‡ä»¶æ ¼å¼"""
        try:
            with open(post_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æfront matter
            post = frontmatter.loads(content)
            
            # ç§»é™¤å‘å¸ƒæ—¶è‡ªåŠ¨æ·»åŠ çš„å­—æ®µ
            auto_generated_fields = [
                'layout', 'author_profile', 'breadcrumbs', 'comments', 
                'related', 'share', 'toc', 'toc_icon', 'toc_label', 
                'toc_sticky', 'last_modified_at'
            ]
            
            for field in auto_generated_fields:
                if field in post.metadata:
                    del post.metadata[field]
            
            # ç§»é™¤é¡µè„šå†…å®¹ï¼ˆä»æœ€åä¸€ä¸ª "---" å¼€å§‹çš„éƒ¨åˆ†ï¼‰
            content_lines = post.content.split('\n')
            footer_start = -1
            
            # ä»åå¾€å‰æŸ¥æ‰¾é¡µè„šåˆ†éš”ç¬¦
            for i in range(len(content_lines) - 1, -1, -1):
                if content_lines[i].strip() == '---' and i < len(content_lines) - 5:
                    # æ£€æŸ¥åé¢å‡ è¡Œæ˜¯å¦åŒ…å«é¡µè„šç‰¹å¾ï¼ˆå¦‚"å­¦ä¹ åˆ†äº«å£°æ˜"æˆ–"è¯·æˆ‘å–å’–å•¡"ï¼‰
                    footer_section = '\n'.join(content_lines[i:])
                    if any(keyword in footer_section for keyword in 
                          ['å­¦ä¹ åˆ†äº«å£°æ˜', 'è¯·æˆ‘å–å’–å•¡', 'Buy Me A Coffee', 'å‘è¡¨è¯„è®º']):
                        footer_start = i
                        break
            
            if footer_start > 0:
                post.content = '\n'.join(content_lines[:footer_start]).rstrip()
            
            # é‡æ–°ç»„è£…ä¸ºsourceæ ¼å¼
            return frontmatter.dumps(post)
            
        except Exception as e:
            self.log(f"è½¬æ¢å‘å¸ƒæ–‡ç« ä¸ºæºæ–‡ä»¶å¤±è´¥: {str(e)}", level="warning")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå†…å®¹
            with open(post_path, 'r', encoding='utf-8') as f:
                return f.read()
    
    def select_platforms(self, draft_path: Optional[Path] = None) -> List[str]:
        """è®©ç”¨æˆ·é€‰æ‹©å‘å¸ƒå¹³å°ï¼Œæ”¯æŒåŸºäºå‘å¸ƒçŠ¶æ€çš„è¿‡æ»¤"""
        all_platforms = [name for name, config in self.config["platforms"].items() 
                        if config.get("enabled", False)]
        
        if draft_path:
            # è·å–æ–‡ç« åç§°
            article_name = draft_path.stem
            
            # è·å–å·²å‘å¸ƒå¹³å°å’Œå¯ç”¨å¹³å°
            published_platforms = self.status_manager.get_published_platforms(article_name)
            available_platforms = self.status_manager.get_available_platforms(article_name, all_platforms)
            
            if published_platforms:
                print(f"\næ–‡ç«  '{article_name}' å·²å‘å¸ƒå¹³å°: {', '.join(published_platforms)}")
            
            if not available_platforms:
                print("è¯¥æ–‡ç« å·²åœ¨æ‰€æœ‰å¯ç”¨çš„å¹³å°å‘å¸ƒ")
                return []
                
            print("\nå¯é€‰çš„å‘å¸ƒå¹³å°ï¼š")
            for i, platform in enumerate(available_platforms, 1):
                print(f"{i}. {platform}")
            print("0. é€€å‡º")
                
            platform_list = available_platforms
        else:
            # æ–°æ–‡ç« ï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨å¹³å°
            print("\nå¯ç”¨çš„å‘å¸ƒå¹³å°ï¼š")
            for i, platform in enumerate(all_platforms, 1):
                print(f"{i}. {platform}")
            print("0. é€€å‡º")
                
            platform_list = all_platforms
            
        if not platform_list:
            return []
            
        selections = input("\nè¯·é€‰æ‹©å‘å¸ƒå¹³å° (å¤šä¸ªå¹³å°ç”¨é€—å·åˆ†éš”ï¼Œ0é€€å‡º): ").split(",")
        selected_platforms = []
        
        for sel in selections:
            sel_stripped = sel.strip()
            if not sel_stripped:  # è·³è¿‡ç©ºå­—ç¬¦ä¸²
                continue
            try:
                idx = int(sel_stripped)
                if idx == 0:
                    return []  # ç”¨æˆ·é€‰æ‹©é€€å‡º
                elif 1 <= idx <= len(platform_list):
                    selected_platforms.append(platform_list[idx - 1])
                else:
                    print(f"æ— æ•ˆé€‰æ‹©: {sel_stripped}")
            except ValueError:
                print(f"æ— æ•ˆè¾“å…¥: {sel_stripped}")
                
        return selected_platforms
    
    def select_member_tier(self) -> Optional[str]:
        """è®©ç”¨æˆ·é€‰æ‹©æ–‡ç« çš„ä¼šå‘˜åˆ†çº§"""
        print("\nğŸ‘¥ ä¼šå‘˜åˆ†çº§é€‰é¡¹ï¼š")
        print("  1. å…è´¹å†…å®¹ - æ‰€æœ‰ç”¨æˆ·å¯è®¿é—®")
        print("  2. ä½“éªŒä¼šå‘˜ (VIP1) - Â¥35/7å¤©")
        print("  3. æœˆåº¦ä¼šå‘˜ (VIP2) - Â¥108/30å¤©")
        print("  4. å­£åº¦ä¼šå‘˜ (VIP3) - Â¥288/90å¤©")
        print("  5. å¹´åº¦ä¼šå‘˜ (VIP4) - Â¥720/365å¤©")
        print("  0. è·³è¿‡è®¾ç½®")
        
        tier_mapping = {
            '1': 'free',
            '2': 'experience', 
            '3': 'monthly',
            '4': 'quarterly',
            '5': 'yearly'
        }
        
        try:
            choice = input("\nè¯·é€‰æ‹©ä¼šå‘˜åˆ†çº§ (1-5ï¼Œé»˜è®¤ä¸º1): ").strip()
            
            if choice == '0':
                print("â­ï¸  è·³è¿‡ä¼šå‘˜åˆ†çº§è®¾ç½®")
                return None
            elif choice in tier_mapping:
                tier = tier_mapping[choice]
                tier_names = {
                    'free': 'å…è´¹å†…å®¹',
                    'experience': 'ä½“éªŒä¼šå‘˜',
                    'monthly': 'æœˆåº¦ä¼šå‘˜', 
                    'quarterly': 'å­£åº¦ä¼šå‘˜',
                    'yearly': 'å¹´åº¦ä¼šå‘˜'
                }
                print(f"âœ… å·²è®¾ç½®ä¸º {tier_names[tier]}")
                return tier
            else:
                print("âœ… é»˜è®¤è®¾ç½®ä¸ºå…è´¹å†…å®¹")
                return 'free'
        except (EOFError, KeyboardInterrupt):
            print("\nâœ… é»˜è®¤è®¾ç½®ä¸ºå…è´¹å†…å®¹")
            return 'free'

    def ask_monetization_preference(self) -> bool:
        """è¯¢é—®ç”¨æˆ·æ˜¯å¦å¯ç”¨å†…å®¹å˜ç°åŠŸèƒ½"""
        if not self.reward_manager:
            return False
        
        print("\nğŸ’° å†…å®¹å˜ç°é€‰é¡¹ï¼š")
        print("  1. å¯ç”¨ - è‡ªåŠ¨ç”Ÿæˆèµ„æ–™åŒ…å¹¶ä¸Šä¼ åˆ°GitHub Release")
        print("  2. è·³è¿‡ - ä»…è¿›è¡Œå¸¸è§„å‘å¸ƒ")
        
        try:
            choice = input("\nè¯·é€‰æ‹© (1/2ï¼Œé»˜è®¤ä¸º2): ").strip()
            
            if choice == "1":
                print("âœ… å·²å¯ç”¨å†…å®¹å˜ç°åŠŸèƒ½")
                return True
            else:
                print("â­ï¸  è·³è¿‡å†…å®¹å˜ç°åŠŸèƒ½")
                return False
        except (EOFError, KeyboardInterrupt):
            print("\nâ­ï¸  è·³è¿‡å†…å®¹å˜ç°åŠŸèƒ½")
            return False
    
    def process_draft(self, draft_path: Path, platforms: List[str], enable_monetization: bool = False, member_tier: Optional[str] = None) -> dict:
        """å¤„ç†è‰ç¨¿æ–‡ä»¶"""
        try:
            self.log(f"============================== å¼€å§‹å¤„ç†è‰ç¨¿ ==============================", force=True)
            self.log(f"è‰ç¨¿æ–‡ä»¶: {draft_path}", force=True)
            
            all_success = True  # è·Ÿè¸ªæ‰€æœ‰æ“ä½œæ˜¯å¦æˆåŠŸ
            console = Console()
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console,
            ) as progress:
                # 1. è¯»å–å†…å®¹
                task = progress.add_task("ğŸ“– è¯»å–æ–‡ç« å†…å®¹...", total=None)
                with open(draft_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                progress.update(task, completed=True)
                
                # æ£€æŸ¥å†…å®¹å®Œæ•´æ€§
                if len(content) < 100:
                    self.log("âŒ æ–‡ç« å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´", level="error", force=True)
                    return {
                        'success': False,
                        'successful_platforms': [],
                        'total_platforms': len(platforms),
                        'published_platforms': [],
                        'article_name': draft_path.stem,
                        'error': 'æ–‡ç« å†…å®¹è¿‡çŸ­'
                    }
                
                # é¢„å¤„ç† front matter ä¸­çš„å¼•å·é—®é¢˜
                try:
                    # å°è¯•è§£æ front matter
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âš ï¸ Front matter è§£æé”™è¯¯: {str(e)}", level="warning")
                    # å°è¯•ä¿®å¤å¸¸è§çš„å¼•å·é—®é¢˜
                    content = self._fix_frontmatter_quotes(content)
                    try:
                        post = frontmatter.loads(content)
                    except Exception as e:
                        self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                        return {
                            'success': False,
                            'successful_platforms': [],
                            'total_platforms': len(platforms),
                            'published_platforms': [],
                            'article_name': draft_path.stem,
                            'error': f'front matterè§£æå¤±è´¥: {str(e)}',
                        }
                
                # æ·»åŠ ä¼šå‘˜åˆ†çº§ä¿¡æ¯
                if member_tier:
                    post['member_tier'] = member_tier
                    # å¦‚æœä¸æ˜¯å…è´¹å†…å®¹ï¼Œä½¿ç”¨ä¼šå‘˜æ–‡ç« å¸ƒå±€
                    if member_tier != 'free':
                        post['layout'] = 'member-post'
                    tier_names = {
                        'free': 'å…è´¹å†…å®¹',
                        'experience': 'ä½“éªŒä¼šå‘˜',
                        'monthly': 'æœˆåº¦ä¼šå‘˜', 
                        'quarterly': 'å­£åº¦ä¼šå‘˜',
                        'yearly': 'å¹´åº¦ä¼šå‘˜'
                    }
                    self.log(f"è®¾ç½®ä¼šå‘˜åˆ†çº§: {tier_names.get(member_tier, member_tier)}", level="info")
                
                # 2. å›¾ç‰‡å¤„ç†æ­¥éª¤ï¼ˆå·²ç§»é™¤Cloudflare ImagesåŠŸèƒ½ï¼‰
                progress.update(progress.add_task("ğŸ–¼ï¸ å›¾ç‰‡å¤„ç†ï¼ˆè·³è¿‡ï¼‰", total=1), completed=True)
                
                # 3. æ¶¦è‰²å†…å®¹
                task = progress.add_task("âœ¨ æ¶¦è‰²æ–‡ç« å†…å®¹...", total=None)
                polished_content = self._polish_content(content)
                if not polished_content:
                    self.log("âŒ å†…å®¹æ¶¦è‰²å¤±è´¥ï¼Œä½¿ç”¨åŸå†…å®¹", level="warning", force=True)
                    polished_content = content
                progress.update(task, completed=True)
                
                # 4. ç”Ÿæˆå„å¹³å°å†…å®¹
                platform_contents = {}
                platform_success = {}  # è·Ÿè¸ªæ¯ä¸ªå¹³å°çš„å¤„ç†ç»“æœ
                
                for platform in platforms:
                    task = progress.add_task(f"ğŸ“ å¤„ç† {platform} å¹³å°...", total=None)
                    try:
                        platform_content = self._generate_platform_content(
                            polished_content,
                            platform,
                            draft_path
                        )
                        
                        # éªŒè¯å†…å®¹å®Œæ•´æ€§
                        if len(platform_content) < len(polished_content) * 0.9:
                            self.log(f"âŒ {platform}å¹³å°å†…å®¹å¯èƒ½ä¸å®Œæ•´", level="error", force=True)
                            platform_success[platform] = False
                        else:
                            platform_contents[platform] = platform_content
                            platform_success[platform] = True
                    except ValueError as e:
                        # å¤„ç†å¿…éœ€å­—æ®µéªŒè¯å¤±è´¥
                        self.log(f"âŒ {platform}å¹³å°å¤„ç†å¤±è´¥: {str(e)}", level="error", force=True)
                        platform_success[platform] = False
                        all_success = False
                    except Exception as e:
                        # å¤„ç†å…¶ä»–é”™è¯¯
                        self.log(f"âŒ {platform}å¹³å°å¤„ç†å‡ºé”™: {str(e)}", level="error", force=True)
                        platform_success[platform] = False
                        all_success = False
                    
                    progress.update(task, completed=True)
                
                # 5. å‘å¸ƒå†…å®¹
                for platform, content in platform_contents.items():
                    if not platform_success.get(platform, False):
                        continue
                        
                    task = progress.add_task(f"ğŸš€ å‘å¸ƒåˆ° {platform}...", total=None)
                    if platform == "github_pages":
                        publish_success = self._publish_to_github_pages(draft_path, content)
                        platform_success[platform] = publish_success
                    elif platform == "wechat":
                        publish_success = self._publish_to_wechat(content)
                        platform_success[platform] = publish_success
                    elif platform == "wordpress":
                        publish_success = self._publish_to_wordpress(content)
                        platform_success[platform] = publish_success
                    progress.update(task, completed=True)
                
                # æ£€æŸ¥æ‰€æœ‰å¹³å°æ˜¯å¦éƒ½æˆåŠŸ
                all_success = all_success and all(platform_success.values())
                
                # 6. æ›´æ–°å‘å¸ƒçŠ¶æ€
                successful_platforms = [platform for platform, success in platform_success.items() if success]
                if successful_platforms:
                    task = progress.add_task("ğŸ“Š æ›´æ–°å‘å¸ƒçŠ¶æ€...", total=None)
                    article_name = draft_path.stem
                    self.status_manager.update_published_platforms(article_name, successful_platforms)
                    self.log(f"å·²æ›´æ–°å‘å¸ƒçŠ¶æ€: {successful_platforms}", level="info", force=True)
                    progress.update(task, completed=True)
                
                # 7. å½’æ¡£è‰ç¨¿å¤„ç†
                archived_file_path = None
                published_platforms = self.status_manager.get_published_platforms(draft_path.stem)
                
                if all_success:
                    # å¦‚æœæœ¬æ¬¡å‘å¸ƒçš„æ‰€æœ‰å¹³å°éƒ½æˆåŠŸï¼Œè¯¢é—®æ˜¯å¦å½’æ¡£
                    self.log(f"ğŸ“‹ æœ¬æ¬¡å‘å¸ƒæˆåŠŸçš„å¹³å°: {', '.join(successful_platforms)}", level="info", force=True)
                    
                    # æ£€æŸ¥è¿™æ˜¯å¦æ˜¯é¦–æ¬¡å‘å¸ƒï¼ˆå³ä¹‹å‰æ²¡æœ‰å‘å¸ƒè¿‡ä»»ä½•å¹³å°ï¼‰
                    previous_platforms = set(published_platforms) - set(successful_platforms)
                    is_first_time = len(previous_platforms) == 0
                    
                    if is_first_time:
                        # é¦–æ¬¡å‘å¸ƒï¼Œè‡ªåŠ¨å½’æ¡£ï¼ˆé¿å…äº¤äº’å¼è¾“å…¥å¡æ­»ï¼‰
                        self.log("âœ… é¦–æ¬¡å‘å¸ƒæˆåŠŸï¼è‡ªåŠ¨å½’æ¡£è‰ç¨¿åˆ° archived/ ç›®å½•", level="info", force=True)
                        task = progress.add_task("ğŸ“¦ å½’æ¡£è‰ç¨¿...", total=None)
                        archived_file_path = self._archive_draft(draft_path)
                        progress.update(task, completed=True)
                        self.log("âœ… è‰ç¨¿å·²è‡ªåŠ¨å½’æ¡£", level="info", force=True)
                    else:
                        # éé¦–æ¬¡å‘å¸ƒï¼Œæ£€æŸ¥æ˜¯å¦å·²åœ¨æ‰€æœ‰å¯ç”¨å¹³å°å‘å¸ƒ
                        all_enabled_platforms = [name for name, config in self.config["platforms"].items() 
                                               if config.get("enabled", False)]
                        if set(published_platforms) >= set(all_enabled_platforms):
                            # å·²åœ¨æ‰€æœ‰å¯ç”¨å¹³å°å‘å¸ƒï¼Œè‡ªåŠ¨å½’æ¡£
                            task = progress.add_task("ğŸ“¦ å½’æ¡£è‰ç¨¿...", total=None)
                            archived_file_path = self._archive_draft(draft_path)
                            progress.update(task, completed=True)
                            self.log("âœ… å·²åœ¨æ‰€æœ‰å¯ç”¨å¹³å°å‘å¸ƒï¼Œè‰ç¨¿å·²è‡ªåŠ¨å½’æ¡£", level="info", force=True)
                        else:
                            unpublished_platforms = set(all_enabled_platforms) - set(published_platforms)
                            self.log(f"ğŸ’¾ å·²å‘å¸ƒåˆ°: {', '.join(published_platforms)}", level="info", force=True)
                            self.log(f"ğŸ“‹ æœªå‘å¸ƒå¹³å°: {', '.join(unpublished_platforms)} (å¯ç¨åå‘å¸ƒ)", level="info", force=True)
                else:
                    self.log("âš ï¸ éƒ¨åˆ†å‘å¸ƒå¤±è´¥ï¼Œè·³è¿‡å½’æ¡£æ­¥éª¤", level="warning", force=True)
                
            # å†…å®¹å˜ç°å¤„ç†
            monetization_result = None
            if enable_monetization and self.reward_manager and all_success:
                try:
                    task = progress.add_task("ğŸ’° åˆ›å»ºå†…å®¹å˜ç°åŒ…...", total=None)
                    
                    # ä½¿ç”¨å·²å‘å¸ƒçš„æ–‡ç« è·¯å¾„ï¼ˆå¦‚æœå·²å‘å¸ƒåˆ°GitHub Pagesï¼‰
                    if 'github' in published_platforms:
                        # ä½¿ç”¨_postsç›®å½•ä¸­çš„æ–‡ç« 
                        posts_dir = Path(self.config["paths"]["posts"])
                        # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä¸ç®¡æ˜¯å¦å·²å½’æ¡£
                        original_filename = archived_file_path.name if archived_file_path else draft_path.name
                        published_article_path = posts_dir / original_filename
                        
                        if published_article_path.exists():
                            monetization_success, monetization_data = self.reward_manager.create_article_package(
                                str(published_article_path), 
                                upload_to_github=True
                            )
                            
                            if monetization_success:
                                monetization_result = {
                                    'success': True,
                                    'package_path': monetization_data.get('package_path'),
                                    'github_release': monetization_data.get('github_release', {})
                                }
                                self.log(f"âœ… å†…å®¹å˜ç°åŒ…åˆ›å»ºæˆåŠŸ", level="info", force=True)
                                if monetization_data.get('github_release', {}).get('success'):
                                    download_url = monetization_data['github_release']['download_url']
                                    self.log(f"ğŸ“¦ ä¸‹è½½é“¾æ¥: {download_url}", level="info", force=True)
                            else:
                                monetization_result = {
                                    'success': False,
                                    'error': monetization_data.get('error', 'æœªçŸ¥é”™è¯¯')
                                }
                                self.log(f"âš ï¸ å†…å®¹å˜ç°åŒ…åˆ›å»ºå¤±è´¥: {monetization_data.get('error')}", level="warning", force=True)
                        else:
                            self.log(f"âš ï¸ å·²å‘å¸ƒæ–‡ç« æœªæ‰¾åˆ°: {published_article_path}", level="warning", force=True)
                    else:
                        # ä½¿ç”¨è‰ç¨¿æ–‡ä»¶æˆ–å½’æ¡£æ–‡ä»¶
                        source_file_path = archived_file_path if archived_file_path and archived_file_path.exists() else draft_path
                        
                        if not source_file_path.exists():
                            self.log(f"âš ï¸ æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file_path}", level="warning", force=True)
                            monetization_result = {
                                'success': False,
                                'error': f'æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file_path}'
                            }
                        else:
                            monetization_success, monetization_data = self.reward_manager.create_article_package(
                                str(source_file_path), 
                                upload_to_github=True
                            )
                            
                            if monetization_success:
                                monetization_result = {
                                    'success': True,
                                    'package_path': monetization_data.get('package_path'),
                                    'github_release': monetization_data.get('github_release', {})
                                }
                                self.log(f"âœ… å†…å®¹å˜ç°åŒ…åˆ›å»ºæˆåŠŸ", level="info", force=True)
                                if monetization_data.get('github_release', {}).get('success'):
                                    download_url = monetization_data['github_release']['download_url']
                                    self.log(f"ğŸ“¦ ä¸‹è½½é“¾æ¥: {download_url}", level="info", force=True)
                            else:
                                monetization_result = {
                                    'success': False,
                                    'error': monetization_data.get('error', 'æœªçŸ¥é”™è¯¯')
                                }
                                self.log(f"âš ï¸ å†…å®¹å˜ç°åŒ…åˆ›å»ºå¤±è´¥: {monetization_data.get('error')}", level="warning", force=True)
                    
                    progress.update(task, completed=True)
                    
                except Exception as e:
                    monetization_result = {
                        'success': False,
                        'error': str(e)
                    }
                    self.log(f"âŒ å†…å®¹å˜ç°å¤„ç†å¼‚å¸¸: {str(e)}", level="error", force=True)
                
            # è¿”å›è¯¦ç»†çš„å‘å¸ƒç»“æœ
            result = {
                'success': all_success,
                'successful_platforms': successful_platforms if 'successful_platforms' in locals() else [],
                'total_platforms': len(platforms),
                'published_platforms': published_platforms if 'published_platforms' in locals() else [],
                'article_name': draft_path.stem,
                'monetization': monetization_result
            }
            return result
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è‰ç¨¿æ—¶å‡ºé”™: {str(e)}")
            return {
                'success': False,
                'successful_platforms': [],
                'total_platforms': len(platforms),
                'published_platforms': [],
                'article_name': draft_path.stem,
                'error': str(e),
            }
    
    def _preprocess_content(self, text: str) -> str:
        """é¢„å¤„ç†å†…å®¹ï¼Œå¤„ç†ç‰¹æ®Šæ ¼å¼"""
        lines = text.split('\n')
        for i, line in enumerate(lines):
            if line.strip().startswith('excerpt:'):
                # å°†å•è¡Œ excerpt è½¬æ¢ä¸ºå¤šè¡Œæ ¼å¼
                content = line.split(':', 1)[1].strip().strip('"')
                lines[i] = 'excerpt: |'
                lines.insert(i + 1, '  ' + content)
        return '\n'.join(lines)
    
    def _fix_frontmatter_quotes(self, content: str) -> str:
        """ä¿®å¤ front matter ä¸­çš„å¼•å·é—®é¢˜"""
        # åˆ†ç¦» front matter å’Œæ­£æ–‡
        parts = content.split('---', 2)
        if len(parts) < 3:
            self.log("âŒ æ— æ³•è¯†åˆ« front matterï¼Œæ ¼å¼å¯èƒ½ä¸æ­£ç¡®", level="error")
            return content
        
        front_matter = parts[1]
        body = parts[2]
        
        # å¤„ç† front matter ä¸­çš„å¼•å·é—®é¢˜
        lines = front_matter.split('\n')
        for i, line in enumerate(lines):
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip()
                
                # å¤„ç† excerpt å­—æ®µ
                if key == 'excerpt' and value.startswith('"') and '"' in value[1:]:
                    # å°† excerpt è½¬æ¢ä¸ºå¤šè¡Œæ ¼å¼
                    lines[i] = 'excerpt: |'
                    # å»æ‰å¼•å·ï¼Œæ·»åŠ ç¼©è¿›
                    clean_value = value.strip('"')
                    lines.insert(i + 1, '  ' + clean_value)
                
                # å¤„ç†å…¶ä»–åŒ…å«å¼•å·çš„å­—æ®µ
                elif '"' in value and not (value.startswith('"') and value.endswith('"')):
                    # ä½¿ç”¨ | è¯­æ³•å¤„ç†å¤šè¡Œå†…å®¹
                    lines[i] = f'{key}: |'
                    lines.insert(i + 1, '  ' + value.strip('"'))
        
        # é‡æ–°ç»„åˆå†…å®¹
        fixed_front_matter = '\n'.join(lines)
        return f"---\n{fixed_front_matter}\n---{body}"
    
    def _polish_content(self, content: str) -> Optional[str]:
        """ä½¿ç”¨AIæ¶¦è‰²æ–‡ç« å†…å®¹"""
        return self.ai_processor.polish_content(content)
    
    def _validate_required_fields(self, post: frontmatter.Post) -> Tuple[bool, List[str]]:
        """éªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
        
        Args:
            post: frontmatter.Postå¯¹è±¡
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦é€šè¿‡éªŒè¯, ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨)
        """
        required_fields = ['title', 'date', 'header']
        missing_fields = []
        
        for field in required_fields:
            if field not in post or not post[field]:
                missing_fields.append(field)
        
        return len(missing_fields) == 0, missing_fields

    def _generate_excerpt(self, content: str) -> str:
        """ç”Ÿæˆæ–‡ç« æ‘˜è¦
        
        Args:
            content: æ–‡ç« å†…å®¹
            
        Returns:
            str: ç”Ÿæˆçš„æ‘˜è¦
        """
        return self.ai_processor.generate_excerpt(content)

    def _generate_platform_content(self, content: str, platform: str, draft_path: Path) -> str:
        """ä¸ºç‰¹å®šå¹³å°ç”Ÿæˆå†…å®¹"""
        try:
            # è·å–å¹³å°é…ç½®
            platform_config = self.platforms_config.get(platform, {})
            
            # å°è¯•è§£æå†…å®¹
            try:
                post = frontmatter.loads(content)
            except Exception as e:
                self.log(f"âš ï¸ è§£æ front matter å¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤ front matter
                content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                    return content
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            is_valid, missing_fields = self._validate_required_fields(post)
            if not is_valid:
                self.log(f"âŒ è‰ç¨¿ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}", level="error", force=True)
                self.log(f"å¿…éœ€å­—æ®µåŒ…æ‹¬: title, date, header", level="error", force=True)
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
            
            # ç¡®ä¿å†…å®¹å®Œæ•´æ€§
            if not post.content:
                self.log("âŒ æ–‡ç« å†…å®¹ä¸ºç©º", level="error", force=True)
                return content
            content_text = post.content
            
            # åº”ç”¨é»˜è®¤æ¨¡æ¿ï¼ˆå¼ºåˆ¶è¦†ç›–è‡ªåŠ¨ç”Ÿæˆå­—æ®µï¼‰
            default_template = self.templates.get('front_matter', {}).get('default', {})
            for key, value in default_template.items():
                post[key] = value  # å¼ºåˆ¶è¦†ç›–ï¼Œä¸æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                self.log(f"åº”ç”¨é»˜è®¤æ¨¡æ¿: {key}={value}", level="info")
            
            # æ·»åŠ æˆ–æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            post['last_modified_at'] = current_time
            self.log(f"æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´: {current_time}", level="info")
            
            # æ™ºèƒ½å¤„ç†excerptå­—æ®µ
            if 'excerpt' not in post or not post['excerpt']:
                generated_excerpt = self._generate_excerpt(content_text)
                if generated_excerpt:
                    post['excerpt'] = generated_excerpt
                    self.log(f"ç”Ÿæˆæ–‡ç« æ‘˜è¦: {generated_excerpt}", level="info")
                else:
                    self.log("æœªèƒ½ç”Ÿæˆæ‘˜è¦", level="warning")
            else:
                excerpt_text = str(post.get('excerpt', ''))
                if excerpt_text:
                    self.log(f"ä¿ç•™ç°æœ‰æ‘˜è¦: {excerpt_text[:50]}...", level="info")
                else:
                    self.log("ç°æœ‰æ‘˜è¦ä¸ºç©º", level="warning")
            
            # å¤„ç†authorå­—æ®µï¼ˆå¦‚æœauthor_profileä¸ºtrueï¼Œç§»é™¤authorå­—æ®µä»¥é¿å…é‡å¤ï¼‰
            if post.get('author_profile', False) and 'author' in post:
                del post['author']
                self.log("ç§»é™¤å†—ä½™çš„authorå­—æ®µ", level="info")
            # å¦‚æœéœ€è¦è®¾ç½®ä½œè€…ä¿¡æ¯ä¸”author_profileä¸å­˜åœ¨ï¼Œåˆ™è®¾ç½®author
            elif platform_config.get('author', None) and not post.get('author_profile', False):
                post['author'] = platform_config.get('author')
                self.log(f"è®¾ç½®ä½œè€…: {post['author']}", level="info")
            
            
            # åˆ†æåˆ†ç±»å’Œæ ‡ç­¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if platform_config.get('analyze_content', True):
                # åˆ†æå†…å®¹è·å–åˆ†ç±»å’Œæ ‡ç­¾
                categories, tags = self._analyze_content_categories(content_text)
                
                # å§‹ç»ˆæ›´æ–°åˆ†ç±»
                if categories:
                    post['categories'] = categories
                    self.log(f"æ·»åŠ åˆ†ç±»: {categories}", level="info")
                
                # ä»…åœ¨æ²¡æœ‰tagsæ—¶æ‰æ·»åŠ AIç”Ÿæˆçš„tags
                if tags and ('tags' not in post or not post['tags']):
                    post['tags'] = tags
                    self.log(f"æ·»åŠ æ ‡ç­¾: {tags}", level="info")
                elif 'tags' in post and post['tags']:
                    self.log(f"ä¿ç•™ç°æœ‰æ ‡ç­¾: {post['tags']}", level="info")
            
            # æ¶¦è‰²å†…å®¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if platform_config.get('polish_content', True):
                polished_content = self._polish_content(content_text)
                if polished_content:
                    content_text = polished_content
            
            # æ·»åŠ é¡µè„šï¼ˆå¦‚æœéœ€è¦ï¼‰
            append_footer = platform_config.get('append_footer', False)
            self.log(f"å¹³å° {platform} append_footer é…ç½®: {append_footer}", level="info", force=True)
            
            if append_footer:
                # è·å–é¡µè„šæ¨¡æ¿ - å…¼å®¹ä¸åŒçš„é…ç½®ç»“æ„
                footer_templates = self.templates.get('footer', {})
                if not footer_templates and 'footer' in self.config:
                    # ç›´æ¥ä»configä¸­è·å–footeré…ç½®
                    footer_templates = self.config.get('footer', {})
                
                self.log(f"å¯ç”¨çš„é¡µè„šæ¨¡æ¿: {list(footer_templates.keys())}", level="info", force=True)
                
                footer_template = footer_templates.get(platform, '')
                self.log(f"è·å–åˆ°çš„é¡µè„šæ¨¡æ¿é•¿åº¦: {len(footer_template) if footer_template else 0}", level="info", force=True)
                
                if footer_template:
                    # ç¡®ä¿é¡µè„šå‰æœ‰è¶³å¤Ÿçš„ç©ºè¡Œ
                    if not content_text.endswith('\n\n'):
                        content_text = content_text.rstrip() + '\n\n'
                    
                    content_text = f"{content_text}{footer_template}"
                    self.log(f"âœ… æ·»åŠ é¡µè„šæˆåŠŸï¼Œé¡µè„šé•¿åº¦: {len(footer_template)} å­—ç¬¦", level="info", force=True)
                else:
                    self.log(f"âŒ æœªæ‰¾åˆ°å¹³å° {platform} çš„é¡µè„šæ¨¡æ¿", level="warning", force=True)
            else:
                self.log(f"å¹³å° {platform} æœªå¯ç”¨é¡µè„šæ·»åŠ ", level="info")
            
            # æ›´æ–°å†…å®¹
            post.content = content_text
            
            # éªŒè¯å†…å®¹å®Œæ•´æ€§
            result = frontmatter.dumps(post)
            if len(result) < len(content) * 0.9:  # å¦‚æœå†…å®¹å‡å°‘è¶…è¿‡10%
                self.log("âš ï¸ è­¦å‘Šï¼šç”Ÿæˆçš„å†…å®¹å¯èƒ½ä¸å®Œæ•´", level="warning", force=True)
            
            # ç¡®ä¿layoutå­—æ®µåœ¨frontmatterçš„ç¬¬ä¸€è¡Œ
            if 'layout' in post:
                # ä½¿ç”¨OrderedDictç¡®ä¿layoutå­—æ®µåœ¨æœ€å‰é¢
                from collections import OrderedDict
                ordered_post = OrderedDict()
                ordered_post["layout"] = post["layout"]
                
                # æ·»åŠ å…¶ä»–å­—æ®µï¼ˆé™¤äº†layoutå’Œcontentï¼‰
                for key, value in post.metadata.items():
                    if key != 'layout':
                        ordered_post[key] = value
                
                # åˆ›å»ºæ–°çš„Postå¯¹è±¡å¹¶è®¾ç½®å†…å®¹
                final_post = frontmatter.Post(post.content, **ordered_post)
                result = frontmatter.dumps(final_post)
            
            return result
            
        except Exception as e:
            self.log(f"ç”Ÿæˆ{platform}å†…å®¹æ—¶å‡ºé”™: {str(e)}", level="error", force=True)
            return content
    
    def _publish_contents(self, draft_path: Path, 
                         platform_contents: Dict[str, str]):
        """å‘å¸ƒå†…å®¹åˆ°å„å¹³å°"""
        for platform, content in platform_contents.items():
            if platform == "github_pages":
                self._publish_to_github_pages(draft_path, content)
            elif platform == "wechat":
                self._publish_to_wechat(content)
            elif platform == "wordpress":
                self._publish_to_wordpress(content)
                
    def _archive_draft(self, draft_path: Path):
        """å½’æ¡£å·²å¤„ç†çš„è‰ç¨¿"""
        try:
            archive_dir = Path(self.config["paths"]["archive"])
            archive_dir.mkdir(parents=True, exist_ok=True)
            
            new_path = archive_dir / draft_path.name
            if new_path.exists():
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                new_path = archive_dir / f"{draft_path.stem}_{timestamp}{draft_path.suffix}"
                logging.info(f"ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨æ—¶é—´æˆ³é‡å‘½å: {new_path.name}")
            
            # æ·»åŠ æ›´è¯¦ç»†çš„è·¯å¾„ä¿¡æ¯
            logging.info(f"å½’æ¡£è‰ç¨¿:")
            logging.info(f"  ä»: {draft_path}")
            logging.info(f"  åˆ°: {new_path}")
            
            draft_path.rename(new_path)
            logging.info(f"âœ… å½’æ¡£å®Œæˆ")
            
            # è¿”å›æ–°çš„å½’æ¡£æ–‡ä»¶è·¯å¾„
            return new_path
            
        except Exception as e:
            logging.error(f"å½’æ¡£è‰ç¨¿æ—¶å‡ºé”™: {str(e)}")
            logging.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            return None
    
    def _convert_links_to_new_window(self, content: str) -> str:
        """å°†Markdowné“¾æ¥è½¬æ¢ä¸ºåœ¨æ–°çª—å£æ‰“å¼€çš„HTMLé“¾æ¥"""
        # åŒ¹é…Markdowné“¾æ¥æ ¼å¼ [text](url)
        pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        
        def replace_link(match):
            text = match.group(1)
            url = match.group(2)
            # è·³è¿‡å›¾ç‰‡é“¾æ¥
            if text.startswith('!'):
                return match.group(0)
            # è·³è¿‡å·²ç»æ˜¯HTMLé“¾æ¥çš„æƒ…å†µ
            if '<a ' in text and '</a>' in text:
                return match.group(0)
            # è½¬æ¢ä¸ºHTMLé“¾æ¥ï¼Œæ·»åŠ target="_blank"å±æ€§
            return f'<a href="{url}" target="_blank" rel="noopener noreferrer">{text}</a>'
        
        # æ›¿æ¢æ‰€æœ‰é“¾æ¥
        converted_content = re.sub(pattern, replace_link, content)
        
        # ä¹Ÿå¤„ç†å·²ç»å­˜åœ¨çš„HTMLé“¾æ¥ï¼Œä½†æ²¡æœ‰target="_blank"çš„æƒ…å†µ
        html_link_pattern = r'<a\s+(?![^>]*target="_blank")([^>]*)href="([^"]+)"([^>]*)>(.*?)</a>'
        
        def add_target_blank(match):
            attrs_before = match.group(1)
            url = match.group(2)
            attrs_after = match.group(3)
            text = match.group(4)
            return f'<a {attrs_before}href="{url}"{attrs_after} target="_blank" rel="noopener noreferrer">{text}</a>'
        
        # ä¸ºç°æœ‰HTMLé“¾æ¥æ·»åŠ target="_blank"
        converted_content = re.sub(html_link_pattern, add_target_blank, converted_content)
        
        self.log("âœ… å·²å°†æ‰€æœ‰é“¾æ¥è®¾ç½®ä¸ºåœ¨æ–°çª—å£æ‰“å¼€", level="debug")
        return converted_content

    def _generate_blog_content(self, content: str, images: Dict[str, str], draft_path: Path) -> str:
        """ç”Ÿæˆåšå®¢å†…å®¹"""
        try:
            # å°è¯•è§£æfront matter
            try:
                post = frontmatter.loads(content)
            except Exception as e:
                self.log(f"âš ï¸ è§£æ front matter å¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤ front matter
                content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(content)
                except Exception as e:
                    self.log(f"âŒ ä¿®å¤åä»æ— æ³•è§£æ front matter: {str(e)}", level="error")
                    return content
            
            # ç¡®ä¿å†…å®¹å®Œæ•´æ€§
            if not post.content:
                self.log("âŒ æ–‡ç« å†…å®¹ä¸ºç©º", level="error", force=True)
                return content
            
            # åº”ç”¨é»˜è®¤æ¨¡æ¿ï¼ˆå¼ºåˆ¶è¦†ç›–è‡ªåŠ¨ç”Ÿæˆå­—æ®µï¼‰
            default_template = self.templates.get('front_matter', {}).get('default', {})
            if default_template:
                for key, value in default_template.items():
                    post[key] = value  # å¼ºåˆ¶è¦†ç›–ï¼Œä¸æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                    self.log(f"åº”ç”¨é»˜è®¤æ¨¡æ¿: {key}={value}", level="info")
                self.log(f"å·²åº”ç”¨é»˜è®¤æ¨¡æ¿è®¾ç½®", level="info")
            else:
                self.log(f"æœªæ‰¾åˆ°é»˜è®¤æ¨¡æ¿è®¾ç½®", level="warning")
            
            # æ·»åŠ æˆ–æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            post['last_modified_at'] = current_time
            self.log(f"æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´: {current_time}", level="info")
            
            # æ›´æ–°æ–‡ç« ä¸­çš„å›¾ç‰‡é“¾æ¥ä¸ºæ ‡å‡†åŒ–æœ¬åœ°è·¯å¾„
            updated_content = post.content
            for local_name, _ in images.items():
                # æ„å»ºæ—§çš„æœ¬åœ°è·¯å¾„æ¨¡å¼
                date_str = draft_path.stem[:10]
                post_name = draft_path.stem[11:]
                old_local_path = f"/assets/images/posts/{date_str[:4]}/{date_str[5:7]}/{post_name}/{local_name}"
                # æ–°çš„æ ‡å‡†åŒ–æœ¬åœ°è·¯å¾„
                new_local_path = f"/assets/images/posts/{local_name}"
                
                # æ›¿æ¢å†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥
                updated_content = updated_content.replace(old_local_path, new_local_path)
                self.log(f"âœ… æ ‡å‡†åŒ–å›¾ç‰‡URL: {local_name} -> {new_local_path}", level="info")
                
                # æ›´æ–° front matter ä¸­çš„å›¾ç‰‡é“¾æ¥
                if hasattr(post, 'metadata') and "header" in post.metadata:
                    header_info = post.metadata["header"]
                    if isinstance(header_info, dict) and "image" in header_info:
                        if header_info["image"] == old_local_path:
                            header_info["image"] = new_local_path
                            post.metadata["header"] = header_info
                            self.log(f"æ›´æ–° header å›¾ç‰‡: {new_local_path}", level="info")
            
            # æ›´æ–°å†…å®¹
            post.content = updated_content
            
            # å°†Markdowné“¾æ¥è½¬æ¢ä¸ºåœ¨æ–°çª—å£æ‰“å¼€çš„HTMLé“¾æ¥
            post.content = self._convert_links_to_new_window(post.content)
            self.log("âœ… å·²å°†é“¾æ¥è®¾ç½®ä¸ºåœ¨æ–°çª—å£æ‰“å¼€", level="info")
            
            # é¡µè„šå·²åœ¨ _generate_platform_content ä¸­å¤„ç†ï¼Œæ­¤å¤„ä¸é‡å¤æ·»åŠ 
            self.log("é¡µè„šå¤„ç†å·²åœ¨å†…å®¹ç”Ÿæˆé˜¶æ®µå®Œæˆ", level="info")
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            self.log(f"å¤„ç†åçš„å†…å®¹é•¿åº¦: {len(post.content)}", level="debug")
            
            return frontmatter.dumps(post)
            
        except Exception as e:
            self.log(f"ç”Ÿæˆåšå®¢å†…å®¹æ—¶å‡ºé”™: {str(e)}", level="error")
            return content

    def _generate_wechat_content(self, content: str, images: Dict[str, str]) -> str:
        """ç”Ÿæˆå¾®ä¿¡å…¬ä¼—å·å†…å®¹"""
        # TODO: å®ç°å¾®ä¿¡å…¬ä¼—å·çš„å†…å®¹è½¬æ¢
        # 1. å¤„ç†å›¾ç‰‡é“¾æ¥
        # 2. è°ƒæ•´æ ¼å¼
        # 3. æ·»åŠ å¾®ä¿¡ç‰¹å®šçš„æ ·å¼
        return content

    def _generate_wordpress_content(self, content: str, images: Dict[str, str]) -> str:
        """ç”ŸæˆWordPresså†…å®¹"""
        # TODO: å®ç°WordPressçš„å†…å®¹è½¬æ¢
        # 1. å¤„ç†å›¾ç‰‡é“¾æ¥
        # 2. è½¬æ¢Markdownä¸ºHTML
        # 3. æ·»åŠ WordPressç‰¹å®šçš„æ ¼å¼
        return content

    def _publish_to_github_pages(self, draft_path: Path, content: str) -> bool:
        """å‘å¸ƒåˆ°GitHub Pagesï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
        try:
            publish_path = Path(self.config["paths"]["posts"]) / draft_path.name
            
            # å§‹ç»ˆè§£æå¹¶é‡æ–°æ ¼å¼åŒ–frontmatterï¼Œç¡®ä¿layoutå­—æ®µåœ¨æœ€å‰é¢
            try:
                post = frontmatter.loads(content)
                
                # ä½¿ç”¨OrderedDictç¡®ä¿layoutå­—æ®µåœ¨æœ€å‰é¢
                if 'layout' in post:
                    from collections import OrderedDict
                    ordered_post = OrderedDict()
                    ordered_post["layout"] = post["layout"]
                    
                    # æ·»åŠ å…¶ä»–å­—æ®µï¼ˆé™¤äº†layoutå’Œcontentï¼‰
                    for key, value in post.metadata.items():
                        if key != 'layout':
                            ordered_post[key] = value
                    
                    # åˆ›å»ºæ–°çš„Postå¯¹è±¡å¹¶è®¾ç½®å†…å®¹
                    final_post = frontmatter.Post(post.content, **ordered_post)
                    content = frontmatter.dumps(final_post)
                else:
                    # å¦‚æœæ²¡æœ‰layoutå­—æ®µï¼Œæ·»åŠ ä¸€ä¸ª
                    from collections import OrderedDict
                    ordered_post = OrderedDict()
                    ordered_post["layout"] = "single"
                    
                    # æ·»åŠ å…¶ä»–å­—æ®µ
                    for key, value in post.metadata.items():
                        ordered_post[key] = value
                    
                    # åˆ›å»ºæ–°çš„Postå¯¹è±¡å¹¶è®¾ç½®å†…å®¹
                    final_post = frontmatter.Post(post.content, **ordered_post)
                    content = frontmatter.dumps(final_post)
                
                # ç¡®ä¿å†…å®¹ä»¥front matterå¼€å¤´
                if not content.startswith('---'):
                    self.log("âŒ æ— æ³•ä¿®å¤front matteræ ¼å¼", level="error")
                    return False
                    
            except Exception as e:
                self.log(f"âŒ è§£æfront matterå¤±è´¥: {str(e)}", level="error")
                return False
            
            # åœ¨ä¿å­˜å‰æ›¿æ¢éŸ³é¢‘é“¾æ¥ä¸ºYouTubeåµŒå…¥
            try:
                from ..utils.audio_link_replacer import AudioLinkReplacer
                replacer = AudioLinkReplacer()
                content, replaced_count = replacer.replace_audio_links(content, draft_path.stem)
                if replaced_count > 0:
                    self.log(f"ğŸ¬ å·²æ›¿æ¢ {replaced_count} ä¸ªéŸ³é¢‘é“¾æ¥ä¸ºYouTubeåµŒå…¥", level="info", force=True)
            except Exception as e:
                self.log(f"âš ï¸ éŸ³é¢‘é“¾æ¥æ›¿æ¢å¤±è´¥: {e}", level="warning")
            
            # ä¿å­˜æ–‡ä»¶
            with open(publish_path, 'w', encoding='utf-8') as f:
                f.write(content)
            self.log(f"âœ… å†…å®¹å·²å‘å¸ƒåˆ°: {publish_path}", force=True)
            
            # Git æ“ä½œ
            try:
                # æ£€æŸ¥å½“å‰åˆ†æ”¯æ˜¯å¦æœ‰ä¸Šæ¸¸è·Ÿè¸ªåˆ†æ”¯
                try:
                    result = subprocess.run(
                        ["git", "rev-parse", "--abbrev-ref", "--symbolic-full-name", "@{u}"],
                        capture_output=True,
                        text=True,
                        check=False
                    )
                    has_upstream = result.returncode == 0 and result.stdout.strip()
                except:
                    has_upstream = False
                
                # å¦‚æœæœ‰ä¸Šæ¸¸åˆ†æ”¯ï¼Œå…ˆæ‹‰å–æœ€æ–°ä»£ç 
                if has_upstream:
                    try:
                        subprocess.run(["git", "pull"], check=True)
                    except subprocess.CalledProcessError:
                        self.log("æ‹‰å–ä»£ç å¤±è´¥ï¼Œç»§ç»­å‘å¸ƒæµç¨‹", level="warning")
                else:
                    self.log("å½“å‰åˆ†æ”¯æ— ä¸Šæ¸¸è·Ÿè¸ªåˆ†æ”¯ï¼Œè·³è¿‡æ‹‰å–", level="info")
                
                # æ·»åŠ æ–‡ä»¶
                subprocess.run(["git", "add", str(publish_path)], check=True)
                
                # æ£€æŸ¥æ–‡ä»¶çŠ¶æ€
                status = subprocess.run(
                    ["git", "status", "--porcelain", str(publish_path)],
                    capture_output=True,
                    text=True
                ).stdout.strip()
                
                if not status:
                    self.log("æ²¡æœ‰éœ€è¦æäº¤çš„æ›´æ”¹", level="warning")
                    return False
                
                # æäº¤æ›´æ”¹
                subprocess.run(["git", "commit", "-m", f"å‘å¸ƒ: {draft_path.name}"], check=True)
                
                # æ¨é€ï¼ˆå¦‚æœæ— ä¸Šæ¸¸åˆ†æ”¯ï¼Œè‡ªåŠ¨è®¾ç½®ï¼‰
                if has_upstream:
                    subprocess.run(["git", "push"], check=True)
                else:
                    # è·å–å½“å‰åˆ†æ”¯å
                    current_branch = subprocess.run(
                        ["git", "branch", "--show-current"],
                        capture_output=True,
                        text=True,
                        check=True
                    ).stdout.strip()
                    
                    # è®¾ç½®ä¸Šæ¸¸åˆ†æ”¯å¹¶æ¨é€
                    subprocess.run(["git", "push", "--set-upstream", "origin", current_branch], check=True)
                self.log("âœ… å·²æ¨é€åˆ° GitHub", force=True)
                return True
                
            except Exception as e:
                self.log(f"âŒ Gitæ“ä½œå¤±è´¥: {str(e)}", level="error")
                return False
                
        except Exception as e:
            self.log(f"âŒ å‘å¸ƒåˆ°GitHub Pageså¤±è´¥: {str(e)}", level="error")
            return False

    def _publish_to_wechat(self, content: str) -> bool:
        """å‘å¸ƒåˆ°å¾®ä¿¡å…¬ä¼—å·ï¼Œæ ¹æ®é…ç½®å†³å®šæ˜¯APIå‘å¸ƒè¿˜æ˜¯ç”ŸæˆæŒ‡å—ã€‚"""
        self.log("å¼€å§‹å¤„ç†å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒ...", level="info", force=True)
        print("\nğŸ“± === å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒ ===")

        if not self.wechat_publisher:
            self.log("å¾®ä¿¡å‘å¸ƒå™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å‘å¸ƒã€‚", level="error", force=True)
            print("âŒ å¾®ä¿¡å‘å¸ƒå™¨æœªåˆå§‹åŒ–")
            return False

        try:
            post = frontmatter.loads(content)
            platform_config = self.platforms_config.get("wechat", {})
            publish_mode = platform_config.get("publish_mode", "guide")  # é»˜è®¤ä¸º guide æ¨¡å¼

            self.log(f"å¾®ä¿¡å‘å¸ƒæ¨¡å¼: {publish_mode.upper()}", level="info", force=True)
            print(f"ğŸ”„ å‘å¸ƒæ¨¡å¼: {publish_mode.upper()}")

            if publish_mode == "api":
                # APIæ¨¡å¼ï¼šç›´æ¥å‘å¸ƒåˆ°è‰ç¨¿ç®±
                print("ğŸŒ ä½¿ç”¨APIæ¨¡å¼ç›´æ¥å‘å¸ƒåˆ°å¾®ä¿¡è‰ç¨¿ç®±...")
                media_id = self.wechat_publisher.publish_to_draft(
                    project_root=self.project_root,
                    front_matter=post.metadata,
                    markdown_content=post.content
                )
                if media_id:
                    self.log(f"âœ… æˆåŠŸåˆ›å»ºå¾®ä¿¡è‰ç¨¿ï¼ŒMedia ID: {media_id}", force=True)
                    return True
                else:
                    self.log("âŒ é€šè¿‡APIåˆ›å»ºå¾®ä¿¡è‰ç¨¿å¤±è´¥ã€‚", level="error", force=True)
                    return False
            else:
                # Guideæ¨¡å¼ï¼šç”Ÿæˆæ‰‹åŠ¨å‘å¸ƒæŒ‡å—
                print("ğŸ“ ä½¿ç”¨æŒ‡å—æ¨¡å¼ç”Ÿæˆæ‰‹åŠ¨å‘å¸ƒæŒ‡å—...")
                success = self.wechat_publisher.generate_guide_file(
                    project_root=self.project_root,
                    front_matter=post.metadata,
                    markdown_content=post.content
                )
                if success:
                    # Find the latest guide file
                    import time
                    guide_dir = self.project_root / ".tmp/output/wechat_guides"
                    if guide_dir.exists():
                        latest_files = sorted(guide_dir.glob("*_guide.md"), key=lambda p: p.stat().st_mtime, reverse=True)
                        if latest_files:
                            self.log(f"âœ… æˆåŠŸç”Ÿæˆå¾®ä¿¡å‘å¸ƒæŒ‡å—æ–‡ä»¶: {latest_files[0]}", force=True)
                        else:
                            self.log("âœ… æˆåŠŸç”Ÿæˆå¾®ä¿¡å‘å¸ƒæŒ‡å—æ–‡ä»¶ã€‚", force=True)
                    else:
                        self.log("âœ… æˆåŠŸç”Ÿæˆå¾®ä¿¡å‘å¸ƒæŒ‡å—æ–‡ä»¶ã€‚", force=True)
                else:
                    self.log("âŒ ç”Ÿæˆå¾®ä¿¡å‘å¸ƒæŒ‡å—æ–‡ä»¶å¤±è´¥ã€‚", level="error", force=True)
                return success

        except Exception as e:
            self.log(f"å‘å¸ƒåˆ°å¾®ä¿¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", level="error", force=True)
            print(f"âŒ å‘å¸ƒåˆ°å¾®ä¿¡æ—¶å‡ºé”™: {e}")
            self.logger.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            return False

    def _publish_to_wordpress(self, content: str):
        """å‘å¸ƒåˆ°WordPress"""
        # TODO: å®ç°WordPresså‘å¸ƒ
        logging.info("WordPresså‘å¸ƒåŠŸèƒ½å°šæœªå®ç°")

    def generate_test_content(self) -> Optional[Path]:
        """ä½¿ç”¨Geminiç”Ÿæˆæµ‹è¯•æ–‡ç« """
        try:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨AIç”Ÿæˆæµ‹è¯•æ–‡ç« ...")
            print("â³ æ­£åœ¨è¿æ¥Gemini AIæ¨¡å‹ï¼Œè¿™é€šå¸¸éœ€è¦15-30ç§’æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            print("ğŸ’¡ ç”Ÿæˆä¸­: æ¨¡å‹æ­£åœ¨æ ¹æ®CLAUDE.mdè§„èŒƒåˆ›å»ºå®Œæ•´çš„æŠ€æœ¯åšå®¢æ–‡ç« ...")
            
            # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
            if not hasattr(self, 'model') or self.model is None:
                print("âŒ Geminiæ¨¡å‹æœªåˆå§‹åŒ–")
                logging.error("Geminiæ¨¡å‹æœªåˆå§‹åŒ–")
                return None
            
            prompt = self.config["content_processing"]["gemini"]["prompts"]["test"]
            logging.debug(f"ä½¿ç”¨çš„prompté•¿åº¦: {len(prompt)}")
            
            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 2
            response = None
            # é…ç½®å®‰å…¨è®¾ç½®ä»¥å…è®¸æŠ€æœ¯å†…å®¹ç”Ÿæˆ
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH"},
            ]
            
            for attempt in range(max_retries):
                if attempt > 0:
                    print(f"âš ï¸ ç¬¬{attempt + 1}æ¬¡å°è¯•ç”Ÿæˆ...")
                    logging.info(f"é‡è¯•ç”Ÿæˆæµ‹è¯•æ–‡ç« ï¼Œç¬¬{attempt + 1}æ¬¡å°è¯•")
                
                response = self.model.generate_content(
                    prompt,
                    generation_config=GenerationConfig(
                        temperature=self.config["content_processing"]["gemini"]["temperature"],
                        max_output_tokens=self.config["content_processing"]["gemini"]["max_output_tokens"],
                        top_p=self.config["content_processing"]["gemini"]["top_p"]
                    ),
                    safety_settings=safety_settings
                )
                
                # æ£€æŸ¥è¿™æ¬¡å°è¯•æ˜¯å¦æˆåŠŸ
                if response and hasattr(response, 'candidates') and response.candidates:
                    if len(response.candidates) > 0 and response.candidates[0].content:
                        break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                
                if attempt == max_retries - 1:
                    print("âŒ å¤šæ¬¡å°è¯•åä»ç„¶ç”Ÿæˆå¤±è´¥")
                    logging.error("å¤šæ¬¡å°è¯•åä»ç„¶ç”Ÿæˆå¤±è´¥")
                    return None
            
            if response:
                logging.debug(f"Geminiå“åº”ç±»å‹: {type(response)}")
                logging.debug(f"Geminiå“åº”å±æ€§: candidates={hasattr(response, 'candidates')}, parts={hasattr(response, 'parts')}")
                try:
                    # è·å–å“åº”å†…å®¹
                    if hasattr(response, 'candidates') and response.candidates:
                        if len(response.candidates) > 0 and response.candidates[0].content:
                            content = response.candidates[0].content.parts[0].text
                        else:
                            print("âš ï¸ Geminiå“åº”ä¸­æ— å€™é€‰ç»“æœ")
                            logging.error("Geminiå“åº”ä¸­æ— å€™é€‰ç»“æœ")
                            return None
                    elif hasattr(response, 'parts') and response.parts:
                        content = ' '.join(part.text for part in response.parts)
                    else:
                        print("âš ï¸ Geminiå“åº”æ ¼å¼å¼‚å¸¸")
                        logging.error(f"Geminiå“åº”æ ¼å¼å¼‚å¸¸: {type(response)}, hasattr candidates: {hasattr(response, 'candidates')}, hasattr parts: {hasattr(response, 'parts')}")
                        return None
                    
                    logging.debug(f"åŸå§‹å“åº”ç±»å‹: {type(content)}")
                    logging.debug(f"åŸå§‹å“åº”å†…å®¹: {content[:200]}...")
                    
                    print("âœ… AIå†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨ä¿å­˜æ–‡ä»¶...")
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦å®Œæ•´ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ç»“å°¾ï¼‰
                    if not self._has_complete_ending(content):
                        print("âš ï¸ æ£€æµ‹åˆ°ç”Ÿæˆå†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ...")
                        # é‡æ–°ç”Ÿæˆä¸€æ¬¡ï¼Œä½¿ç”¨æ›´æ˜ç¡®çš„prompt
                        complete_prompt = prompt + "\n\nã€ç‰¹åˆ«å¼ºè°ƒã€‘æ–‡ç« å¿…é¡»æœ‰å®Œæ•´çš„ç»“å°¾æ®µè½ï¼ŒåŒ…å«æ€»ç»“æˆ–æ€è€ƒé—®é¢˜ã€‚"
                        response = self.model.generate_content(
                            complete_prompt,
                            generation_config=GenerationConfig(
                                temperature=0.6,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç¨³å®šæ€§
                                max_output_tokens=self.config["content_processing"]["gemini"]["max_output_tokens"],
                                top_p=0.8
                            ),
                            safety_settings=safety_settings
                        )
                        if hasattr(response, 'candidates') and response.candidates:
                            content = response.candidates[0].content.parts[0].text
                        else:
                            content = ' '.join(part.text for part in response.parts)
                    
                    # ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶åé¿å…è¦†ç›–
                    timestamp = datetime.now().strftime("%Y-%m-%d-%H%M%S")
                    
                    # æ¸…ç†å’Œå¤„ç†AIç”Ÿæˆçš„å†…å®¹
                    cleaned_content = self._clean_ai_generated_content(content)
                    
                    # è°ƒè¯•ä¿¡æ¯
                    logging.debug(f"åŸå§‹å†…å®¹é•¿åº¦: {len(content)}")
                    logging.debug(f"æ¸…ç†åå†…å®¹é•¿åº¦: {len(cleaned_content)}")
                    logging.debug(f"åŸå§‹å†…å®¹å‰200å­—ç¬¦: {content[:200]}")
                    logging.debug(f"æ¸…ç†åå†…å®¹å‰200å­—ç¬¦: {cleaned_content[:200] if cleaned_content else 'EMPTY'}")
                    
                    if not cleaned_content.strip():
                        print("âŒ AIç”Ÿæˆçš„å†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆ")
                        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šåŸå§‹å†…å®¹é•¿åº¦ {len(content)}, æ¸…ç†åé•¿åº¦ {len(cleaned_content)}")
                        logging.error(f"AIç”Ÿæˆçš„å†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆ - åŸå§‹é•¿åº¦: {len(content)}, æ¸…ç†åé•¿åº¦: {len(cleaned_content)}")
                        logging.error(f"åŸå§‹å†…å®¹ç¤ºä¾‹: {content[:500] if content else 'NONE'}")
                        return None
                    
                    # æ£€æŸ¥æ˜¯å¦å·²åŒ…å«valid front matter
                    if cleaned_content.startswith('---') and cleaned_content.count('---') >= 2:
                        # AIç”Ÿæˆçš„å†…å®¹å·²åŒ…å«front matterï¼Œç›´æ¥ä½¿ç”¨
                        post_text = cleaned_content
                        print("ğŸ“ ä½¿ç”¨AIç”Ÿæˆçš„å®Œæ•´æ–‡ç« æ ¼å¼")
                    else:
                        # æ‰‹åŠ¨æ·»åŠ front matter
                        from collections import OrderedDict
                        post = OrderedDict()
                        post["title"] = f"AIç”Ÿæˆæµ‹è¯•æ–‡ç«  - {timestamp}"
                        post["date"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S +0000")
                        post["header"] = {
                            "overlay_image": "https://1drv.ms/i/c/b5f6bce7f0f6f9f8/EQl5xJjYnAJOhRfDgJ7HZFABL8y5c7d1e2f3g4h5i6j7k8l9?format=webp&width=1200",
                            "overlay_filter": 0.5
                        }
                        post_text = frontmatter.dumps(frontmatter.Post(cleaned_content, **post))
                        print("ğŸ“ æ·»åŠ äº†æ ‡å‡†front matter")
                    
                    # å†™å…¥æ–‡ä»¶
                    draft_path = Path(f"_drafts/test-article-{timestamp}.md")
                    draft_path.parent.mkdir(parents=True, exist_ok=True)
                    draft_path.write_text(post_text, encoding='utf-8')
                    
                    print(f"âœ… æµ‹è¯•æ–‡ç« å·²ç”Ÿæˆ: {draft_path}")
                    print(f"ğŸ“ æ–‡ç« é•¿åº¦: {len(content)} å­—ç¬¦")
                    logging.info(f"âœ… å·²ç”Ÿæˆæµ‹è¯•æ–‡ç« : {draft_path} (é•¿åº¦: {len(content)} å­—ç¬¦)")
                    
                    # è®°å½•æµ‹è¯•æ–‡ç« ç”Ÿæˆçš„è¯¦ç»†ä¿¡æ¯
                    lines = post_text.count('\n') + 1
                    self.log(f"æµ‹è¯•æ–‡ç« ç”Ÿæˆè¯¦æƒ… - æ–‡ä»¶: {draft_path}, æ€»é•¿åº¦: {len(content)}å­—ç¬¦, è¡Œæ•°: {lines}è¡Œ", level="info", force=True)
                    return draft_path
                    
                except Exception as e:
                    logging.error(f"å¤„ç†å“åº”å†…å®¹æ—¶å‡ºé”™: {str(e)}")
                    logging.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
                    return None
            else:
                print("âŒ Gemini APIè¿”å›ç©ºå“åº”")
                logging.error("Gemini APIè¿”å›ç©ºå“åº”")
                return None
                
        except Exception as e:
            logging.error(f"ç”Ÿæˆæµ‹è¯•æ–‡ç« å¤±è´¥: {str(e)}")
            logging.debug("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            return None
    
    def _has_complete_ending(self, content: str) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦æœ‰å®Œæ•´çš„ç»“å°¾"""
        # æ£€æŸ¥æ˜¯å¦ä»¥å¥å·ã€é—®å·æˆ–æ„Ÿå¹å·ç»“å°¾
        content = content.strip()
        if not content:
            return False
            
        # æ£€æŸ¥æœ€åå‡ è¡Œæ˜¯å¦åŒ…å«æ˜æ˜¾çš„ç»“å°¾æ ‡è¯†
        lines = content.split('\n')
        last_lines = '\n'.join(lines[-5:])  # æ£€æŸ¥æœ€å5è¡Œ
        
        # æ£€æŸ¥ç»“å°¾ç‰¹å¾
        ending_indicators = [
            'ï¼Ÿ', 'ã€‚', 'ï¼',  # ä¸­æ–‡æ ‡ç‚¹
            '?', '.', '!',     # è‹±æ–‡æ ‡ç‚¹
            'æ€è€ƒ', 'æ€»ç»“', 'ç»“è®º', 'å±•æœ›', 'æœªæ¥',
            'é—®é¢˜', 'æŒ‘æˆ˜', 'æœºé‡', 'å‘å±•'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“å°¾æŒ‡ç¤ºè¯
        has_ending_word = any(indicator in last_lines for indicator in ending_indicators)
        
        # æ£€æŸ¥æœ€åä¸€è¡Œæ˜¯å¦çœ‹èµ·æ¥åƒå®Œæ•´çš„å¥å­
        last_line = lines[-1].strip() if lines else ""
        is_complete_sentence = len(last_line) > 10 and any(punct in last_line for punct in ['ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!'])
        
        return has_ending_word and is_complete_sentence
    
    def _clean_ai_generated_content(self, content: str) -> str:
        """æ¸…ç†AIç”Ÿæˆçš„å†…å®¹ï¼Œå»é™¤è§£é‡Šæ€§æ–‡å­—å’Œå¤šä½™çš„æ ¼å¼"""
        if not content:
            return ""
        
        lines = content.split('\n')
        cleaned_lines = []
        start_found = False
        in_yaml_block = False
        in_code_block = False
        yaml_block_start = -1
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # æ£€æµ‹ä»£ç å—
            if stripped.startswith('```'):
                in_code_block = not in_code_block
                # å¦‚æœæ˜¯åŒ…è£…YAMLçš„ä»£ç å—ï¼Œè·³è¿‡
                if 'yaml' in stripped.lower() or 'markdown' in stripped.lower():
                    continue
                # å…¶ä»–ä»£ç å—ä¿ç•™
                if not in_code_block and start_found:
                    cleaned_lines.append(line)
                continue
            
            # åœ¨ä»£ç å—å†…ä¸”æ˜¯YAMLåŒ…è£…ï¼Œç‰¹æ®Šå¤„ç†
            if in_code_block:
                # æ£€æŸ¥æ˜¯å¦æ˜¯åµŒå…¥çš„YAML front matter
                if stripped == '---':
                    if not in_yaml_block:
                        in_yaml_block = True
                        yaml_block_start = i
                    else:
                        in_yaml_block = False
                        # è·³è¿‡æ•´ä¸ªYAMLå—
                    continue
                elif in_yaml_block:
                    continue  # è·³è¿‡YAMLå—å†…å®¹
                elif start_found:
                    cleaned_lines.append(line)  # ä¿ç•™éåµŒå…¥YAMLçš„ä»£ç å—å†…å®¹
                continue
            
            # è·³è¿‡æ˜æ˜¾çš„AIè§£é‡Šæ€§æ–‡å­—
            if not start_found:
                # è·³è¿‡å¸¸è§çš„AIè§£é‡Šæ€§å¼€å¤´
                if (stripped.startswith('å¥½çš„') or 
                    stripped.startswith('éµç…§') or
                    stripped.startswith('æˆ‘å°†') or
                    stripped.startswith('æ ¹æ®') or
                    stripped.startswith('ä»¥ä¸‹æ˜¯') or
                    stripped.startswith('è¿™é‡Œæ˜¯') or
                    stripped.startswith('è¿™æ˜¯ä¸€ç¯‡') or
                    'æŒ‰ç…§æ‚¨çš„è§„èŒƒ' in stripped or
                    'ç”¨äºæµ‹è¯•' in stripped):
                    continue
                # ç©ºè¡Œè·³è¿‡
                elif not stripped:
                    continue
                # æ‰¾åˆ°æ­£å¼å†…å®¹å¼€å§‹
                else:
                    start_found = True
            
            # å·²æ‰¾åˆ°å¼€å§‹ï¼Œä¿ç•™æ­£å¼å†…å®¹
            if start_found:
                cleaned_lines.append(line)
        
        cleaned_content = '\n'.join(cleaned_lines)
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        cleaned_content = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned_content)
        cleaned_content = cleaned_content.strip()
        
        # å¦‚æœæ¸…ç†åå†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œè¿”å›åŸå§‹å†…å®¹
        if not cleaned_content or len(cleaned_content) < 100:
            logging.warning("å†…å®¹æ¸…ç†åä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè¿”å›åŸå§‹å†…å®¹")
            return content.strip()
        
        return cleaned_content

    def process_post_images(self, post_path: Path) -> Dict[str, str]:
        """å¤„ç†æ–‡ç« ä¸­çš„å›¾ç‰‡"""
        return self.image_processor.process_post_images(post_path)
    
    def _download_onedrive_image(self, url: str, temp_dir: Path) -> Optional[str]:
        """ä¸‹è½½OneDriveå›¾ç‰‡
        
        Args:
            url: OneDriveå›¾ç‰‡URL
            temp_dir: ä¸´æ—¶ç›®å½•
            
        Returns:
            æˆåŠŸè¿”å›å›¾ç‰‡æ–‡ä»¶åï¼Œå¤±è´¥è¿”å›None
        """
        try:
            self.log(f"ä¸‹è½½OneDriveå›¾ç‰‡: {url}", level="info")
            
            # æå–OneDrive URLä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦
            unique_id = None
            if 'onedrive.live.com' in url and 'resid=' in url:
                # ä¾‹å¦‚ï¼šhttps://onedrive.live.com/embed?resid=5644DAB129AFDA10%2169891&authkey=%21AFppTKcu8cfS2Eo&width=660
                resid_match = re.search(r'resid=([^&]+)', url)
                if resid_match:
                    resid = resid_match.group(1)
                    # è§£ç URLç¼–ç çš„å­—ç¬¦
                    import urllib.parse
                    resid = urllib.parse.unquote(resid)
                    self.log(f"ä»URLä¸­æå–çš„resid: {resid}", level="debug")
                    
                    # æå–residä¸­çš„æ•°å­—éƒ¨åˆ†ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                    id_match = re.search(r'([0-9]+)$', resid)
                    if id_match:
                        unique_id = id_match.group(1)
                        self.log(f"ä»residä¸­æå–çš„å”¯ä¸€æ ‡è¯†ç¬¦: {unique_id}", level="debug")
            
            # å¦‚æœæ— æ³•ä»URLä¸­æå–å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œåˆ™ä½¿ç”¨URLçš„å“ˆå¸Œå€¼
            if not unique_id:
                import hashlib
                unique_id = hashlib.md5(url.encode()).hexdigest()[:5]
                self.log(f"ä½¿ç”¨URLå“ˆå¸Œå€¼ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦: {unique_id}", level="debug")
            
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            # ç¡®å®šå›¾ç‰‡æ ¼å¼
            content_type = response.headers.get('content-type', '')
            self.log(f"å›¾ç‰‡Content-Type: {content_type}", level="debug")
            extension = self._get_extension_from_content_type(content_type)
            
            if not extension and 'content-disposition' in response.headers:
                # å°è¯•ä»Content-Dispositionå¤´ä¸­æå–æ–‡ä»¶å
                cd = response.headers['content-disposition']
                self.log(f"Content-Disposition: {cd}", level="debug")
                filename_match = re.search(r'filename="?([^";]+)"?', cd)
                if filename_match:
                    orig_filename = filename_match.group(1)
                    _, extension = os.path.splitext(orig_filename)
                    extension = extension.lstrip('.')
                    self.log(f"ä»Content-Dispositionæå–çš„æ‰©å±•å: {extension}", level="debug")
            
            # å¦‚æœä»ç„¶æ— æ³•ç¡®å®šæ‰©å±•åï¼Œåˆ™æ ¹æ®å†…å®¹è¿›è¡Œåˆ¤æ–­
            if not extension:
                import filetype
                img_data = response.content
                kind = filetype.guess(img_data)
                extension = kind.extension if kind else 'jpg'  # é»˜è®¤ä½¿ç”¨jpg
                self.log(f"ä»å†…å®¹åˆ¤æ–­çš„å›¾ç‰‡ç±»å‹: {extension}", level="debug")
            
            # æ„å»ºè¾“å‡ºæ–‡ä»¶å
            output_filename = f"onedrive_{unique_id}.{extension}"
            output_path = temp_dir / output_filename
            
            # ä¿å­˜å›¾ç‰‡
            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            self.log(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {url} -> {output_filename}", level="info")
            return output_filename
        except Exception as e:
            self.log(f"âŒ ä¸‹è½½OneDriveå›¾ç‰‡å¤±è´¥: {str(e)}", level="error")
            self.log("é”™è¯¯è¯¦æƒ…:", level="debug")
            return None

    def _setup_site_url(self):
        """è®¾ç½®ç«™ç‚¹URL"""
        # ä»å¹³å°é…ç½®ä¸­è·å–åŸŸå
        if 'platforms' in self.config and 'github_pages' in self.config['platforms']:
            self.site_url = self.config['platforms']['github_pages'].get('domain', 'arong.eu.org/youxinyanzhe')
        else:
            # é»˜è®¤å€¼
            self.site_url = 'arong.eu.org/youxinyanzhe'
        
        self.log(f"ç«™ç‚¹URL: {self.site_url}", level="debug")
    
    def _is_valid_draft(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ‰æ•ˆçš„è‰ç¨¿æ–‡ä»¶ï¼ˆç”¨äºå‘å¸ƒï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ£€æŸ¥æ˜¯å¦æœ‰ front matter
            if not content.startswith('---'):
                # æ²¡æœ‰Front Matterçš„æ–‡ä»¶ä¸èƒ½ç›´æ¥å‘å¸ƒ
                # ä¸åœ¨è¿™é‡Œè®°å½•æ—¥å¿—ï¼Œé¿å…é‡å¤æç¤º
                return False

            # å°è¯•è§£æ front matter
            try:
                post = frontmatter.loads(content)
                # æ£€æŸ¥å¿…è¦çš„å­—æ®µï¼ˆlayoutä¸æ˜¯å¿…é¡»çš„ï¼Œå‘å¸ƒæ—¶ä¼šè‡ªåŠ¨æ·»åŠ ï¼‰
                required_fields = ['title', 'date']
                for field in required_fields:
                    if field not in post:
                        self.log(f"è‰ç¨¿ç¼ºå°‘å¿…è¦å­—æ®µ: {field}", level="warning")
                        return False
                return True
            except Exception as e:
                self.log(f"è§£æè‰ç¨¿ front matter å¤±è´¥: {str(e)}", level="warning")
                # å°è¯•ä¿®å¤
                fixed_content = self._fix_frontmatter_quotes(content)
                try:
                    post = frontmatter.loads(fixed_content)
                    return True
                except Exception:
                    return False
        except Exception:
            return False
    
    def _get_available_categories(self) -> Dict[str, List[str]]:
        """è·å–å¯ç”¨çš„åˆ†ç±»å’Œæ ‡ç­¾"""
        return self.templates.get('categories', {})
    
    def _suggest_categories(self, content: str) -> List[str]:
        """æ ¹æ®å†…å®¹å»ºè®®åˆ†ç±»"""
        categories = []
        available_cats = self._get_available_categories()
        
        if not available_cats:
            self.log("âŒ æ— æ³•è·å–å¯ç”¨åˆ†ç±»", level="error")
            return []
            
        # å°†å†…å®¹è½¬ä¸ºå°å†™ä»¥è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
        content_lower = content.lower()
        
        # å››å¤§æ ¸å¿ƒåˆ†ç±»å…³é”®è¯æ˜ å°„
        category_keywords = {
            "è®¤çŸ¥å‡çº§": ["æ€ç»´", "è®¤çŸ¥", "æ€è€ƒ", "å­¦ä¹ æ–¹æ³•", "å†³ç­–", "å¿ƒç†å­¦", "åè§", "æˆé•¿", "çŸ¥è¯†", "æ€ç»´æ¨¡å‹", "é˜…è¯»", "æ•™è‚²"],
            "æŠ€æœ¯èµ‹èƒ½": ["æŠ€æœ¯", "å·¥å…·", "è½¯ä»¶", "åº”ç”¨", "è‡ªåŠ¨åŒ–", "æ•ˆç‡", "ç¼–ç¨‹", "å¼€å‘", "äº‘æœåŠ¡", "ai", "äººå·¥æ™ºèƒ½", "æ•™ç¨‹", "æŒ‡å—"],
            "å…¨çƒè§†é‡": ["å…¨çƒ", "å›½é™…", "è¶‹åŠ¿", "æ–‡åŒ–", "è§‚å¯Ÿ", "ä¸–ç•Œ", "è·¨æ–‡åŒ–", "åˆ†æ", "tesla", "é©¬æ–¯å…‹", "ç§‘æŠ€", "åˆ›æ–°", "æœªæ¥"],
            "æŠ•èµ„ç†è´¢": ["æŠ•èµ„", "ç†è´¢", "é‡‘è", "è‚¡ç¥¨", "åŸºé‡‘", "é‡åŒ–", "äº¤æ˜“", "è´¢åŠ¡", "èµ„äº§", "æ”¶ç›Š", "é£é™©", "ç­–ç•¥", "ç¾è‚¡", "qdii"]
        }
        
        # å…ˆå°è¯•ä½¿ç”¨å…³é”®è¯åŒ¹é…
        for main_cat, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    categories.append(main_cat)
                    break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å…³é”®è¯ï¼Œå°è¯•ä½¿ç”¨å­åˆ†ç±»åŒ¹é…
        if not categories:
            for main_cat, sub_cats in available_cats.items():
                for sub_cat in sub_cats:
                    if sub_cat.lower() in content_lower:
                        categories.append(main_cat)
                        break
        
        # å¦‚æœä»ç„¶æ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
        if not categories:
            self.log("âš ï¸ æ— æ³•åŒ¹é…åˆ°åˆé€‚çš„åˆ†ç±»ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»", level="warning")
            return ["æŠ€æœ¯èµ‹èƒ½"]
            
        self.log(f"é€šè¿‡å…³é”®è¯åŒ¹é…æ‰¾åˆ°åˆ†ç±»: {categories}", level="info")
        return list(set(categories))  # å»é‡

    def _analyze_content_categories(self, content: str) -> Tuple[List[str], List[str]]:
        """ä½¿ç”¨ Gemini åˆ†ææ–‡ç« å†…å®¹ï¼Œè¿”å›å»ºè®®çš„åˆ†ç±»å’Œæ ‡ç­¾"""
        # è·å–å¯ç”¨åˆ†ç±»
        available_cats = self._get_available_categories()
        if not available_cats:
            self.log("âŒ æ— æ³•è·å–å¯ç”¨åˆ†ç±»", level="error")
            return [], []
        
        return self.ai_processor.generate_categories_and_tags(content, available_cats)
    
    def _replace_images(self, content: str, images: Dict[str, str], temp_dir_path: Path) -> str:
        """æ›¿æ¢æ–‡ç« ä¸­çš„å›¾ç‰‡é“¾æ¥"""
        return self.image_processor.replace_images_in_content(content, images, temp_dir_path)

    def _is_same_onedrive_image(self, onedrive_url: str, image_name: str) -> bool:
        """åˆ¤æ–­OneDrive URLæ˜¯å¦å¯¹åº”æŒ‡å®šçš„å›¾ç‰‡åç§°
        
        é€šè¿‡æ¯”è¾ƒOneDrive URLä¸­çš„residå‚æ•°å’Œå›¾ç‰‡åç§°ä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦æ¥åˆ¤æ–­
        """
        # å¦‚æœå›¾ç‰‡åç§°ä¸æ˜¯ä»¥onedrive_å¼€å¤´ï¼Œåˆ™æ— æ³•ç¡®å®šå¯¹åº”å…³ç³»
        if not image_name.startswith('onedrive_'):
            self.log(f"å›¾ç‰‡åç§°ä¸æ˜¯ä»¥onedrive_å¼€å¤´: {image_name}", level="debug")
            return False
        
        # ä»å›¾ç‰‡åç§°ä¸­æå–å”¯ä¸€æ ‡è¯†ç¬¦
        # æ ¼å¼ï¼šonedrive_UNIQUEID.extension
        match = re.match(r'onedrive_([^.]+)\.', image_name)
        if not match:
            self.log(f"æ— æ³•ä»å›¾ç‰‡åç§°ä¸­æå–å”¯ä¸€æ ‡è¯†ç¬¦: {image_name}", level="debug")
            return False
        
        image_unique_id = match.group(1)
        self.log(f"æ¯”è¾ƒOneDrive URLå’Œå›¾ç‰‡: URL={onedrive_url}, å›¾ç‰‡åç§°={image_name}, å”¯ä¸€ID={image_unique_id}", level="debug")
        
        # ä»OneDrive URLä¸­æå–residå‚æ•°
        if 'onedrive.live.com' in onedrive_url and 'resid=' in onedrive_url:
            resid_match = re.search(r'resid=([^&]+)', onedrive_url)
            if resid_match:
                resid = resid_match.group(1)
                # è§£ç URLç¼–ç çš„å­—ç¬¦
                import urllib.parse
                resid = urllib.parse.unquote(resid)
                
                self.log(f"ä»OneDrive URLä¸­æå–çš„resid: {resid}", level="debug")
                
                # æ£€æŸ¥residä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡åç§°ä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦
                if image_unique_id in resid:
                    self.log(f"âœ… åŒ¹é…æˆåŠŸ: å”¯ä¸€ID {image_unique_id} åœ¨resid {resid} ä¸­æ‰¾åˆ°", level="debug")
                    return True
                
                # æå–residä¸­çš„æ•°å­—éƒ¨åˆ†
                id_match = re.search(r'([0-9]+)$', resid)
                if id_match:
                    resid_number = id_match.group(1)
                    self.log(f"ä»residä¸­æå–çš„æ•°å­—éƒ¨åˆ†: {resid_number}", level="debug")
                    if resid_number == image_unique_id:
                        self.log(f"âœ… åŒ¹é…æˆåŠŸ: residçš„æ•°å­—éƒ¨åˆ† {resid_number} ä¸å”¯ä¸€ID {image_unique_id} ç›¸åŒ", level="debug")
                        return True
        
        # å¦‚æœæ— æ³•ä»URLä¸­æå–residï¼Œåˆ™ä½¿ç”¨URLçš„å“ˆå¸Œå€¼è¿›è¡Œæ¯”è¾ƒ
        if len(image_unique_id) == 5:  # åŸºäºURLçš„å“ˆå¸Œå€¼é•¿åº¦ä¸º5
            import hashlib
            url_hash = hashlib.md5(onedrive_url.encode()).hexdigest()[:5]
            self.log(f"URLå“ˆå¸Œå€¼: {url_hash}, å”¯ä¸€ID: {image_unique_id}", level="debug")
            if url_hash == image_unique_id:
                self.log(f"âœ… åŒ¹é…æˆåŠŸ: URLå“ˆå¸Œå€¼ {url_hash} ä¸å”¯ä¸€ID {image_unique_id} ç›¸åŒ", level="debug")
                return True
        
        # å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ— æ³•ç¡®å®šå¯¹åº”å…³ç³»ï¼Œåˆ™ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
        result = image_unique_id.lower() in onedrive_url.lower()
        if result:
            self.log(f"âœ… åŒ¹é…æˆåŠŸ: å”¯ä¸€ID {image_unique_id} åœ¨URL {onedrive_url} ä¸­æ‰¾åˆ°", level="debug")
        else:
            self.log(f"âŒ åŒ¹é…å¤±è´¥: å”¯ä¸€ID {image_unique_id} åœ¨URL {onedrive_url} ä¸­æœªæ‰¾åˆ°", level="debug")
        return result

    def _update_header_images(self, post: dict, images: Dict[str, str]) -> dict:
        """æ›´æ–°æ–‡ç« å¤´éƒ¨çš„å›¾ç‰‡URL"""
        if not images:
            self.log("æ²¡æœ‰å›¾ç‰‡éœ€è¦æ›´æ–°å¤´éƒ¨", level="warning")
            return post
        
        if 'header' not in post:
            self.log("æ–‡ç« æ²¡æœ‰headeréƒ¨åˆ†", level="warning")
            return post
        
        updated_count = 0
        for img_field in ['image', 'og_image', 'overlay_image', 'teaser']:
            if img_field in post['header']:
                img_path = post['header'][img_field]
                if not img_path:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯Cloudflare URL
                if img_path.startswith("https://imagedelivery.net"):
                    self.log(f"âš ï¸ å¤´å›¾ {img_field} å·²æ˜¯Cloudflare URLï¼Œè·³è¿‡æ›¿æ¢", level="debug")
                    continue
                
                # å¤„ç†OneDriveé“¾æ¥
                if '1drv.ms' in img_path or 'onedrive.live.com' in img_path:
                    # æŸ¥æ‰¾å¯¹åº”çš„å·²ä¸Šä¼ å›¾ç‰‡
                    found_match = False
                    for img_name, _ in images.items():
                        # å°è¯•åŒ¹é…OneDriveé“¾æ¥å’Œæœ¬åœ°å›¾ç‰‡
                        if self._is_same_onedrive_image(img_path, img_name):
                            # ä½¿ç”¨æœ¬åœ°è·¯å¾„æ›¿ä»£Cloudflare URL
                            local_url = f"/assets/images/posts/{img_name}"
                            
                            post['header'][img_field] = local_url
                            updated_count += 1
                            self.log(f"âœ… æ›´æ–°OneDriveå¤´å›¾: {img_field} = {img_path} -> {local_url}", level="info")
                            found_match = True
                            break
                    
                    if not found_match:
                        self.log(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„OneDriveå¤´å›¾: {img_field} = {img_path}", level="warning")
                # å¤„ç†æœ¬åœ°å›¾ç‰‡
                else:
                    img_name = Path(img_path).name
                    
                    if img_name in images:
                        # ä½¿ç”¨æœ¬åœ°è·¯å¾„æ›¿ä»£Cloudflare URL
                        local_url = f"/assets/images/posts/{img_name}"
                        post['header'][img_field] = local_url
                        updated_count += 1
                        self.log(f"âœ… æ›´æ–°å¤´å›¾: {img_field} = {img_name} -> {local_url}", level="info")
        
        if updated_count > 0:
            self.log(f"æ€»å…±æ›´æ–°äº† {updated_count} å¤„å¤´éƒ¨å›¾ç‰‡", level="info")
        return post

    def _get_extension_from_content_type(self, content_type: str) -> Optional[str]:
        """ä»Content-Typeå¤´ä¸­æå–æ–‡ä»¶æ‰©å±•å
        
        Args:
            content_type: Content-Typeå¤´çš„å€¼
            
        Returns:
            æ–‡ä»¶æ‰©å±•åï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™è¿”å›None
        """
        content_type = content_type.lower()
        if 'image/' not in content_type:
            return None
            
        # å¸¸è§çš„MIMEç±»å‹æ˜ å°„
        mime_to_ext = {
            'image/jpeg': 'jpg',
            'image/jpg': 'jpg',
            'image/png': 'png',
            'image/gif': 'gif',
            'image/webp': 'webp',
            'image/svg+xml': 'svg',
            'image/bmp': 'bmp',
            'image/tiff': 'tiff'
        }
        
        for mime, ext in mime_to_ext.items():
            if mime in content_type:
                return ext
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„MIMEç±»å‹ï¼Œå°è¯•ä»content-typeä¸­æå–å­ç±»å‹
        if '/' in content_type:
            subtype = content_type.split('/')[-1].split(';')[0].strip()
            if subtype and subtype != 'octet-stream':
                return subtype
                
        return None

    # ===================== ç»Ÿä¸€å¤„ç†æ¥å£ =====================
    
    def format_content_file(self, input_file: Path, **kwargs) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„å†…å®¹æ–‡ä»¶æ ¼å¼åŒ–æ¥å£
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            **kwargs: ä¼ é€’ç»™format_draft.pyçš„å‚æ•°
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        from pathlib import Path
        import subprocess
        import sys
        
        result = {
            'success': False,
            'output_file': None,
            'issues': [],
            'error': None
        }
        
        try:
            if not input_file.exists():
                result['error'] = f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}"
                return result
            
            # æ„å»ºformat_draft.pyè°ƒç”¨å‚æ•°
            script_path = Path("scripts/tools/content/format_draft.py")
            if not script_path.exists():
                result['error'] = f"æ ¼å¼åŒ–è„šæœ¬ä¸å­˜åœ¨: {script_path}"
                return result
            
            cmd = [sys.executable, str(script_path), str(input_file)]
            
            # æ·»åŠ å¯é€‰å‚æ•°
            if 'title' in kwargs:
                cmd.extend(['-t', kwargs['title']])
            if 'category' in kwargs:
                cmd.extend(['-c', kwargs['category']])
            if 'tags' in kwargs:
                cmd.extend(['--tags'] + kwargs['tags'])
            if 'output' in kwargs:
                cmd.extend(['-o', str(kwargs['output'])])
            
            # æ‰§è¡Œæ ¼å¼åŒ–
            process_result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                cwd=Path.cwd()
            )
            
            if process_result.returncode == 0:
                result['success'] = True
                
                # è§£æè¾“å‡ºæ‰¾åˆ°ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
                output_lines = process_result.stdout.split('\n')
                for line in output_lines:
                    # å…¼å®¹emojiå‰ç¼€çš„æ ¼å¼åŒ–å®Œæˆæ ‡è®°
                    if 'æ ¼å¼åŒ–å®Œæˆ:' in line:
                        # åˆ†å‰²å¹¶æ¸…ç†è·¯å¾„å­—ç¬¦ä¸²ï¼Œå»é™¤å¯èƒ½çš„emojiç­‰å‰ç¼€
                        output_file_str = line.split('æ ¼å¼åŒ–å®Œæˆ:')[-1].strip()
                        result['output_file'] = Path(output_file_str)
                        break
                
                # å¦‚æœæ ¼å¼åŒ–æˆåŠŸï¼Œè¿›è¡Œè´¨é‡æ£€æŸ¥
                if result['output_file'] and result['output_file'].exists():
                    check_result = self.comprehensive_content_check(
                        result['output_file'], 
                        auto_fix=True
                    )
                    result.update(check_result)
                    
                    self.log(f"ç»Ÿä¸€æ ¼å¼åŒ–å®Œæˆ: {input_file} â†’ {result['output_file']}", level="info")
                else:
                    result['error'] = "æ— æ³•ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„"
                    result['success'] = False
            else:
                result['error'] = process_result.stderr or "æ ¼å¼åŒ–å¤±è´¥"
                
        except Exception as e:
            result['error'] = f"æ ¼å¼åŒ–è¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            self.log(f"æ ¼å¼åŒ–æ–‡ä»¶å¤±è´¥: {input_file}, é”™è¯¯: {str(e)}", level="error")
            
        return result
    
    def process_onedrive_images(self, draft_file: Path, mode: str = "single") -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„OneDriveå›¾ç‰‡å¤„ç†æ¥å£
        
        Args:
            draft_file: è‰ç¨¿æ–‡ä»¶è·¯å¾„
            mode: å¤„ç†æ¨¡å¼ ("single" æˆ– "batch")
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        import subprocess
        import sys
        
        result = {
            'success': False,
            'processed_images': 0,
            'issues': [],
            'error': None
        }
        
        try:
            if not draft_file.exists():
                result['error'] = f"è‰ç¨¿æ–‡ä»¶ä¸å­˜åœ¨: {draft_file}"
                return result
            
            # æ£€æŸ¥è‰ç¨¿ä¸­çš„å›¾ç‰‡é—®é¢˜
            with open(draft_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            image_issues = self.check_image_paths(content)
            if not image_issues:
                result['success'] = True
                result['processed_images'] = 0
                self.log(f"è‰ç¨¿æ— éœ€å›¾ç‰‡å¤„ç†: {draft_file}", level="info")
                return result
            
            # è°ƒç”¨OneDriveå›¾ç‰‡å¤„ç†è„šæœ¬
            script_path = Path("scripts/tools/onedrive_blog_images.py")
            if not script_path.exists():
                result['error'] = f"OneDriveå¤„ç†è„šæœ¬ä¸å­˜åœ¨: {script_path}"
                return result
            
            cmd = [sys.executable, str(script_path), "--draft", str(draft_file)]
            
            process_result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=Path.cwd()
            )
            
            if process_result.returncode == 0:
                result['success'] = True
                result['processed_images'] = len(image_issues)
                
                # é‡æ–°æ£€æŸ¥å¤„ç†åçš„å›¾ç‰‡çŠ¶æ€
                with open(draft_file, 'r', encoding='utf-8') as f:
                    updated_content = f.read()
                remaining_issues = self.check_image_paths(updated_content)
                result['issues'] = remaining_issues
                
                self.log(f"OneDriveå›¾ç‰‡å¤„ç†å®Œæˆ: {draft_file}, å¤„ç† {result['processed_images']} å¼ å›¾ç‰‡", level="info")
            else:
                result['error'] = process_result.stderr or "OneDriveå›¾ç‰‡å¤„ç†å¤±è´¥"
                
        except Exception as e:
            result['error'] = f"OneDriveå›¾ç‰‡å¤„ç†å¼‚å¸¸: {str(e)}"
            self.log(f"OneDriveå›¾ç‰‡å¤„ç†å¤±è´¥: {draft_file}, é”™è¯¯: {str(e)}", level="error")
            
        return result

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='config/pipeline_config.yml', help='Path to config file')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose logging')
    args = parser.parse_args()

    pipeline = ContentPipeline(args.config, args.verbose)
    
    # é€‰æ‹©æ“ä½œ
    print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
    print("1. å¤„ç†ç°æœ‰è‰ç¨¿")
    print("2. é‡æ–°å‘å¸ƒå·²å‘å¸ƒæ–‡ç« ")
    print("3. ç”Ÿæˆæµ‹è¯•æ–‡ç« ")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip()
    
    if choice == "1":
        # å¤„ç†ç°æœ‰è‰ç¨¿
        draft = pipeline.select_draft()
        if not draft:
            return
        elif isinstance(draft, str) and draft.startswith('redirect_to_'):
            # å¤„ç†é‡å®šå‘ - åœ¨ç›´æ¥è°ƒç”¨æ—¶ä¸æ”¯æŒé‡å®šå‘ï¼Œè·³è¿‡
            print("æ­¤æ¨¡å¼ä¸‹ä¸æ”¯æŒé‡å®šå‘ï¼Œè¯·ç›´æ¥é€‰æ‹©è‰ç¨¿æ–‡ä»¶")
            return
    elif choice == "2":
        # é‡æ–°å‘å¸ƒå·²å‘å¸ƒæ–‡ç« 
        post = pipeline.select_published_post()
        if not post:
            return
        draft = pipeline.copy_post_to_draft(post)
        if not draft:
            return
    elif choice == "3":
        # ç”Ÿæˆæµ‹è¯•æ–‡ç« 
        draft = pipeline.generate_test_content()
        if not draft:
            print("ç”Ÿæˆæµ‹è¯•æ–‡ç« å¤±è´¥")
            return
    else:
        print("æ— æ•ˆçš„é€‰æ‹©")
        return
        
    # ç¡®ä¿draftæ˜¯Pathç±»å‹
    if not isinstance(draft, Path):
        print("é”™è¯¯ï¼šæ— æ•ˆçš„è‰ç¨¿ç±»å‹")
        return
        
    # é€‰æ‹©å‘å¸ƒå¹³å°
    platforms = pipeline.select_platforms(draft)
    if not platforms:
        print("æœªé€‰æ‹©ä»»ä½•å‘å¸ƒå¹³å°")
        return
        
    # å¤„ç†å¹¶å‘å¸ƒ
    success = pipeline.process_draft(draft, platforms)
    if success:
        print("âœ… å¤„ç†å®Œæˆ!")
    else:
        print("âš ï¸ å¤„ç†æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main()