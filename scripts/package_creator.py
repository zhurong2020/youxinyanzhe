"""
å†…å®¹æ‰“åŒ…åˆ›å»ºå™¨
ç”¨äºè‡ªåŠ¨ç”ŸæˆPDFå’Œèµ„æ–™åŒ…ZIPæ–‡ä»¶ï¼Œæ”¯æŒå¾®ä¿¡å…¬ä¼—å·å†…å®¹å˜ç°ç³»ç»Ÿ
"""

import os
import re
import zipfile
import tempfile
import requests
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
import json
import frontmatter
from urllib.parse import urlparse
import markdown2
from weasyprint import HTML, CSS
from weasyprint.text.fonts import FontConfiguration


class PackageCreator:
    """å†…å®¹åŒ…åˆ›å»ºå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # é¡¹ç›®è·¯å¾„
        self.project_root = Path(__file__).parent.parent
        self.output_dir = self.project_root / "_output/packages"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # èµ„æ–™æ¸…å•æ¨¡æ¿
        self.resource_list_template = """# ğŸ“¦ èµ„æ–™åŒ…æ¸…å•

## ğŸ“„ æ–‡ç« ä¿¡æ¯
- **æ ‡é¢˜**: {title}
- **å‘å¸ƒæ—¥æœŸ**: {date}
- **ç”Ÿæˆæ—¶é—´**: {generated_at}

## ğŸ“ åŒ…å«æ–‡ä»¶

### 1. å®Œæ•´æ–‡ç« PDF
- `{article_filename}.pdf` - é«˜è´¨é‡PDFç‰ˆæœ¬ï¼Œé€‚åˆä¿å­˜å’Œæ‰“å°

### 2. é«˜æ¸…å›¾ç‰‡èµ„æº
{image_list}

### 3. å‚è€ƒèµ„æ–™
- `èµ„æ–™æ¸…å•.md` - æœ¬æ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰èµ„æºé“¾æ¥
- `é“¾æ¥æ±‡æ€».txt` - æ–‡ç« ä¸­æåˆ°çš„æ‰€æœ‰å¤–éƒ¨é“¾æ¥

## ğŸ”— åœ¨çº¿èµ„æºé“¾æ¥

### å®˜æ–¹ä¿¡æ¯æ¥æº
{official_links}

### æ‰©å±•é˜…è¯»
{additional_links}

## ğŸ’¡ ä½¿ç”¨è¯´æ˜

1. **PDFé˜…è¯»**: æ¨èä½¿ç”¨Adobe Readeræˆ–å…¶ä»–PDFé˜…è¯»å™¨
2. **å›¾ç‰‡æŸ¥çœ‹**: æ‰€æœ‰å›¾ç‰‡å‡ä¸ºé«˜æ¸…ç‰ˆæœ¬ï¼Œå¯ç›´æ¥ä½¿ç”¨
3. **é“¾æ¥è®¿é—®**: éƒ¨åˆ†é“¾æ¥å¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘å·¥å…·
4. **æ›´æ–°è·å–**: å…³æ³¨å¾®ä¿¡å…¬ä¼—å·"æœ‰å¿ƒè¨€è€…"è·å–æœ€æ–°å†…å®¹

## ğŸ“ è”ç³»æ–¹å¼

- **å¾®ä¿¡å…¬ä¼—å·**: æœ‰å¿ƒè¨€è€…
- **åšå®¢**: https://zhurong2020.github.io
- **é‚®ç®±**: é€šè¿‡å…¬ä¼—å·è”ç³»

---

æ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼å¦‚æœè§‰å¾—æœ‰ä»·å€¼ï¼Œæ¬¢è¿åˆ†äº«ç»™æ›´å¤šæœ‹å‹ã€‚

*æ­¤èµ„æ–™åŒ…ç”±è‡ªåŠ¨åŒ–ç³»ç»Ÿç”Ÿæˆï¼Œå¦‚æœ‰é—®é¢˜è¯·é€šè¿‡å¾®ä¿¡å…¬ä¼—å·åé¦ˆã€‚*
"""
    
    def create_package(self, article_path: str, include_images: bool = True, 
                      include_links: bool = True) -> Tuple[bool, Dict]:
        """
        åˆ›å»ºå®Œæ•´çš„å†…å®¹åŒ…
        
        Args:
            article_path: æ–‡ç« æ–‡ä»¶è·¯å¾„
            include_images: æ˜¯å¦åŒ…å«å›¾ç‰‡
            include_links: æ˜¯å¦åŒ…å«é“¾æ¥æ±‡æ€»
            
        Returns:
            (success, result_info)
        """
        try:
            article_file = Path(article_path)
            if not article_file.exists():
                return False, {"error": f"æ–‡ç« æ–‡ä»¶ä¸å­˜åœ¨: {article_path}"}
            
            # è§£ææ–‡ç« 
            with open(article_file, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            article_title = post.metadata.get('title', article_file.stem)
            article_date = str(post.metadata.get('date', ''))
            
            self.logger.info(f"å¼€å§‹åˆ›å»ºå†…å®¹åŒ…: {article_title}")
            
            # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                
                # 1. ç”ŸæˆPDF
                pdf_success, pdf_path = self._create_pdf(post, temp_path, article_title)
                if not pdf_success:
                    return False, {"error": "PDFç”Ÿæˆå¤±è´¥"}
                
                # 2. æ”¶é›†å›¾ç‰‡
                images_info = []
                if include_images:
                    images_info = self._collect_images(post.content, temp_path)
                
                # 3. æå–é“¾æ¥
                links_info = []
                if include_links:
                    links_info = self._extract_links(post.content)
                    self._create_links_file(links_info, temp_path)
                
                # 4. ç”Ÿæˆèµ„æ–™æ¸…å•
                self._create_resource_list(
                    article_title, article_date, images_info, links_info, temp_path
                )
                
                # 5. åˆ›å»ºZIPæ–‡ä»¶
                package_success, package_path = self._create_zip_package(
                    temp_path, article_title, article_date
                )
                
                if package_success:
                    result = {
                        "package_path": str(package_path),
                        "title": article_title,
                        "date": article_date,
                        "files": {
                            "pdf": f"{self._safe_filename(article_title)}.pdf",
                            "images_count": len(images_info),
                            "links_count": len(links_info)
                        },
                        "size_mb": round(package_path.stat().st_size / (1024 * 1024), 2)
                    }
                    
                    self.logger.info(f"âœ… å†…å®¹åŒ…åˆ›å»ºæˆåŠŸ: {package_path}")
                    return True, result
                else:
                    return False, {"error": "ZIPæ‰“åŒ…å¤±è´¥"}
                    
        except Exception as e:
            error_msg = f"åˆ›å»ºå†…å®¹åŒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            self.logger.error(error_msg)
            return False, {"error": error_msg}
    
    def _create_pdf(self, post: frontmatter.Post, temp_path: Path, 
                   title: str) -> Tuple[bool, Optional[Path]]:
        """ç”ŸæˆPDFæ–‡ä»¶"""
        try:
            # å‡†å¤‡HTMLå†…å®¹
            html_content = self._prepare_html_for_pdf(post, title)
            
            # CSSæ ·å¼
            css_content = """
            @page {
                size: A4;
                margin: 2cm;
            }
            
            body {
                font-family: "PingFang SC", "Microsoft YaHei", "Hiragino Sans GB", sans-serif;
                line-height: 1.6;
                color: #333;
                font-size: 14px;
            }
            
            h1 {
                color: #2c3e50;
                border-bottom: 3px solid #3498db;
                padding-bottom: 10px;
                margin-bottom: 30px;
                font-size: 24px;
            }
            
            h2 {
                color: #34495e;
                margin-top: 30px;
                margin-bottom: 15px;
                font-size: 20px;
            }
            
            h3 {
                color: #7f8c8d;
                margin-top: 25px;
                margin-bottom: 12px;
                font-size: 16px;
            }
            
            p {
                margin-bottom: 12px;
                text-align: justify;
            }
            
            ul, ol {
                margin-bottom: 15px;
                padding-left: 25px;
            }
            
            li {
                margin-bottom: 5px;
            }
            
            blockquote {
                border-left: 4px solid #3498db;
                margin: 20px 0;
                padding: 10px 20px;
                background-color: #f8f9fa;
                font-style: italic;
            }
            
            code {
                background-color: #f1f2f6;
                padding: 2px 4px;
                border-radius: 3px;
                font-family: "Consolas", "Monaco", monospace;
            }
            
            pre {
                background-color: #f8f9fa;
                border: 1px solid #e9ecef;
                border-radius: 4px;
                padding: 15px;
                margin: 15px 0;
                overflow-x: auto;
            }
            
            img {
                max-width: 100%;
                height: auto;
                margin: 15px 0;
                border-radius: 5px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            }
            
            .article-meta {
                color: #7f8c8d;
                font-size: 12px;
                margin-bottom: 30px;
                padding: 15px;
                background-color: #f8f9fa;
                border-radius: 5px;
            }
            
            .footer {
                margin-top: 40px;
                padding-top: 20px;
                border-top: 1px solid #e9ecef;
                font-size: 12px;
                color: #7f8c8d;
                text-align: center;
            }
            """
            
            # ç”ŸæˆPDF
            pdf_filename = f"{self._safe_filename(title)}.pdf"
            pdf_path = temp_path / pdf_filename
            
            font_config = FontConfiguration()
            html_doc = HTML(string=html_content)
            css_doc = CSS(string=css_content, font_config=font_config)
            
            html_doc.write_pdf(str(pdf_path), stylesheets=[css_doc], font_config=font_config)
            
            self.logger.info(f"PDFç”ŸæˆæˆåŠŸ: {pdf_filename}")
            return True, pdf_path
            
        except Exception as e:
            self.logger.error(f"PDFç”Ÿæˆå¤±è´¥: {e}")
            return False, None
    
    def _prepare_html_for_pdf(self, post: frontmatter.Post, title: str) -> str:
        """å‡†å¤‡ç”¨äºPDFçš„HTMLå†…å®¹"""
        # æ–‡ç« å…ƒä¿¡æ¯
        date = post.metadata.get('date', '')
        categories = post.metadata.get('categories', [])
        tags = post.metadata.get('tags', [])
        
        # è½¬æ¢Markdownä¸ºHTML
        html_body = markdown2.markdown(
            post.content,
            extras=["fenced-code-blocks", "tables", "strike", "task_list"]
        )
        
        # å¤„ç†å›¾ç‰‡é“¾æ¥ - ç§»é™¤OneDriveé“¾æ¥ï¼Œå› ä¸ºPDFä¸­æ— æ³•æ˜¾ç¤º
        # html_body = re.sub(r'<img[^>]+src="[^"]*1drv\.ms[^"]*"[^>]*>', 
        #                   '<p style="color: #666; font-style: italic;">[å›¾ç‰‡å·²çœç•¥ï¼Œè¯·æŸ¥çœ‹åŸæ–‡]</p>', 
        #                   html_body)
        
        # æ„å»ºå®Œæ•´HTML
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
</head>
<body>
    <h1>{title}</h1>
    
    <div class="article-meta">
        <p><strong>å‘å¸ƒæ—¥æœŸ</strong>: {date}</p>
        {f'<p><strong>åˆ†ç±»</strong>: {", ".join(categories)}</p>' if categories else ''}
        {f'<p><strong>æ ‡ç­¾</strong>: {", ".join(tags)}</p>' if tags else ''}
        <p><strong>PDFç”Ÿæˆæ—¶é—´</strong>: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")}</p>
    </div>
    
    {html_body}
    
    <div class="footer">
        <p>æœ¬PDFç”±"æœ‰å¿ƒè¨€è€…"è‡ªåŠ¨ç”Ÿæˆç³»ç»Ÿåˆ›å»º</p>
        <p>è·å–æ›´å¤šå†…å®¹è¯·å…³æ³¨å¾®ä¿¡å…¬ä¼—å·ï¼šæœ‰å¿ƒè¨€è€…</p>
        <p>åšå®¢åœ°å€ï¼šhttps://zhurong2020.github.io</p>
    </div>
</body>
</html>
        """
        
        return html_content
    
    def _collect_images(self, content: str, temp_path: Path) -> List[Dict]:
        """æ”¶é›†å¹¶ä¸‹è½½æ–‡ç« ä¸­çš„å›¾ç‰‡"""
        images_info = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡é“¾æ¥
        image_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
        matches = re.findall(image_pattern, content)
        
        images_dir = temp_path / "images"
        images_dir.mkdir(exist_ok=True)
        
        for i, (alt_text, image_url) in enumerate(matches, 1):
            try:
                if image_url.startswith(('http://', 'https://')):
                    # ä¸‹è½½ç½‘ç»œå›¾ç‰‡
                    response = requests.get(image_url, timeout=20)
                    if response.status_code == 200:
                        # å°è¯•ä»URLæˆ–headersè·å–æ–‡ä»¶æ‰©å±•å
                        ext = self._get_image_extension(image_url, response.headers)
                        filename = f"image_{i:02d}{ext}"
                        
                        image_path = images_dir / filename
                        with open(image_path, 'wb') as f:
                            f.write(response.content)
                        
                        images_info.append({
                            "filename": filename,
                            "alt_text": alt_text,
                            "original_url": image_url,
                            "local_path": str(image_path),
                            "size_kb": round(len(response.content) / 1024, 2)
                        })
                        
                        self.logger.info(f"å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {filename}")
                    else:
                        self.logger.warning(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {image_url}")
                        
            except Exception as e:
                self.logger.warning(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {image_url} - {e}")
        
        return images_info
    
    def _get_image_extension(self, url: str, headers: Dict) -> str:
        """ä»URLæˆ–headersè·å–å›¾ç‰‡æ‰©å±•å"""
        # å…ˆä»URLè·¯å¾„å°è¯•
        parsed_url = urlparse(url)
        path = parsed_url.path.lower()
        
        for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']:
            if ext in path:
                return ext
        
        # ä»Content-Typeå¤´è·å–
        content_type = headers.get('content-type', '').lower()
        if 'jpeg' in content_type or 'jpg' in content_type:
            return '.jpg'
        elif 'png' in content_type:
            return '.png'
        elif 'gif' in content_type:
            return '.gif'
        elif 'webp' in content_type:
            return '.webp'
        
        # é»˜è®¤ä½¿ç”¨jpg
        return '.jpg'
    
    def _extract_links(self, content: str) -> List[Dict]:
        """æå–æ–‡ç« ä¸­çš„æ‰€æœ‰é“¾æ¥"""
        links_info = []
        
        # Markdowné“¾æ¥æ ¼å¼ [text](url)
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        matches = re.findall(link_pattern, content)
        
        # å»é‡å¹¶åˆ†ç±»
        seen_urls = set()
        for text, url in matches:
            if url not in seen_urls and url.startswith(('http://', 'https://')):
                seen_urls.add(url)
                
                # ç®€å•åˆ†ç±»
                category = "å…¶ä»–"
                domain = urlparse(url).netloc.lower()
                
                if any(official in domain for official in ['tesla.com', 'spacex.com', 'neuralink.com', 'x.com']):
                    category = "å®˜æ–¹ç½‘ç«™"
                elif any(news in domain for news in ['bloomberg.com', 'reuters.com', 'cnbc.com', 'wsj.com']):
                    category = "æ–°é—»åª’ä½“"
                elif any(tech in domain for tech in ['github.com', 'arxiv.org', 'nature.com', 'science.org']):
                    category = "æŠ€æœ¯èµ„æ–™"
                elif any(social in domain for social in ['twitter.com', 'linkedin.com', 'youtube.com']):
                    category = "ç¤¾äº¤åª’ä½“"
                
                links_info.append({
                    "text": text,
                    "url": url,
                    "category": category,
                    "domain": domain
                })
        
        return links_info
    
    def _create_links_file(self, links_info: List[Dict], temp_path: Path) -> None:
        """åˆ›å»ºé“¾æ¥æ±‡æ€»æ–‡ä»¶"""
        if not links_info:
            return
        
        content = "# ğŸ”— é“¾æ¥æ±‡æ€»\n\n"
        
        # æŒ‰åˆ†ç±»ç»„ç»‡é“¾æ¥
        categories = {}
        for link in links_info:
            category = link["category"]
            if category not in categories:
                categories[category] = []
            categories[category].append(link)
        
        for category, links in categories.items():
            content += f"## {category}\n\n"
            for link in links:
                content += f"- [{link['text']}]({link['url']})\n"
            content += "\n"
        
        content += "---\n\n"
        content += f"*å…±è®¡ {len(links_info)} ä¸ªé“¾æ¥ï¼Œç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}*\n"
        
        links_file = temp_path / "é“¾æ¥æ±‡æ€».txt"
        with open(links_file, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _create_resource_list(self, title: str, date: str, images_info: List[Dict], 
                            links_info: List[Dict], temp_path: Path) -> None:
        """åˆ›å»ºèµ„æ–™æ¸…å•æ–‡ä»¶"""
        # ç”Ÿæˆå›¾ç‰‡åˆ—è¡¨
        image_list = ""
        if images_info:
            for img in images_info:
                image_list += f"- `{img['filename']}` - {img['alt_text']} ({img['size_kb']} KB)\n"
        else:
            image_list = "- æ— å›¾ç‰‡èµ„æº\n"
        
        # ç”Ÿæˆå®˜æ–¹é“¾æ¥åˆ—è¡¨
        official_links = ""
        additional_links = ""
        
        for link in links_info:
            link_line = f"- [{link['text']}]({link['url']})\n"
            if link['category'] == "å®˜æ–¹ç½‘ç«™":
                official_links += link_line
            else:
                additional_links += link_line
        
        if not official_links:
            official_links = "- æ— å®˜æ–¹é“¾æ¥\n"
        if not additional_links:
            additional_links = "- æ— æ‰©å±•èµ„æ–™\n"
        
        # ç”Ÿæˆèµ„æ–™æ¸…å•
        content = self.resource_list_template.format(
            title=title,
            date=date,
            generated_at=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
            article_filename=self._safe_filename(title),
            image_list=image_list,
            official_links=official_links,
            additional_links=additional_links
        )
        
        readme_file = temp_path / "èµ„æ–™æ¸…å•.md"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _create_zip_package(self, temp_path: Path, title: str, date: str) -> Tuple[bool, Optional[Path]]:
        """åˆ›å»ºZIPæ–‡ä»¶"""
        try:
            # ç”ŸæˆZIPæ–‡ä»¶å
            safe_title = self._safe_filename(title)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"{safe_title}_{timestamp}_package.zip"
            zip_path = self.output_dir / zip_filename
            
            # åˆ›å»ºZIPæ–‡ä»¶
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # æ·»åŠ æ‰€æœ‰æ–‡ä»¶
                for file_path in temp_path.rglob('*'):
                    if file_path.is_file():
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        arcname = file_path.relative_to(temp_path)
                        zipf.write(file_path, arcname)
            
            self.logger.info(f"ZIPåŒ…åˆ›å»ºæˆåŠŸ: {zip_filename}")
            return True, zip_path
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºZIPåŒ…å¤±è´¥: {e}")
            return False, None
    
    def _safe_filename(self, filename: str) -> str:
        """ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å"""
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨çš„å­—ç¬¦
        safe = re.sub(r'[^\w\s-]', '', filename)
        safe = re.sub(r'[-\s]+', '-', safe).strip('-')
        return safe[:50]  # é™åˆ¶é•¿åº¦
    
    def get_package_info(self, package_path: str) -> Optional[Dict]:
        """è·å–å†…å®¹åŒ…ä¿¡æ¯"""
        try:
            zip_path = Path(package_path)
            if not zip_path.exists():
                return None
            
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                file_list = zipf.namelist()
                
                info = {
                    "path": str(zip_path),
                    "filename": zip_path.name,
                    "size_mb": round(zip_path.stat().st_size / (1024 * 1024), 2),
                    "created_at": datetime.fromtimestamp(zip_path.stat().st_ctime),
                    "files": {
                        "total": len(file_list),
                        "pdf": len([f for f in file_list if f.endswith('.pdf')]),
                        "images": len([f for f in file_list if f.startswith('images/')]),
                        "docs": len([f for f in file_list if f.endswith(('.md', '.txt'))])
                    }
                }
                
                return info
                
        except Exception as e:
            self.logger.error(f"è·å–åŒ…ä¿¡æ¯å¤±è´¥: {e}")
            return None


def create_package_creator() -> PackageCreator:
    """åˆ›å»ºå†…å®¹åŒ…åˆ›å»ºå™¨å®ä¾‹"""
    return PackageCreator()


if __name__ == "__main__":
    # æµ‹è¯•è„šæœ¬
    import sys
    
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python package_creator.py <article_path>")
        sys.exit(1)
    
    article_path = sys.argv[1]
    
    try:
        creator = create_package_creator()
        success, result = creator.create_package(article_path)
        
        if success:
            print(f"âœ… å†…å®¹åŒ…åˆ›å»ºæˆåŠŸ!")
            print(f"æ–‡ä»¶è·¯å¾„: {result['package_path']}")
            print(f"æ–‡ä»¶å¤§å°: {result['size_mb']} MB")
            print(f"åŒ…å«æ–‡ä»¶: PDF + {result['files']['images_count']}å¼ å›¾ç‰‡ + {result['files']['links_count']}ä¸ªé“¾æ¥")
        else:
            print(f"âŒ åˆ›å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")