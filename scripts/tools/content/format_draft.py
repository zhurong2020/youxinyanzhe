#!/usr/bin/env python3
"""
æ‰‹å·¥è‰ç¨¿å¿«é€Ÿæ’ç‰ˆå·¥å…·
ç”¨äºå°†æ‰‹å·¥ç¼–å†™çš„è‰ç¨¿å†…å®¹å¿«é€Ÿæ ¼å¼åŒ–ä¸ºç¬¦åˆé¡¹ç›®è§„èŒƒçš„Jekyllæ–‡ç« 
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
# format_draft.pyåœ¨scripts/tools/content/ï¼Œéœ€è¦å‘ä¸Šå››çº§åˆ°è¾¾é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

class DraftFormatter:
    """è‰ç¨¿æ ¼å¼åŒ–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ ¼å¼åŒ–å™¨"""
        self.project_root = project_root
        self.drafts_dir = self.project_root / "_drafts"
        self.config_dir = self.project_root / "config"
        
        # åˆå§‹åŒ–å†…å®¹è´¨é‡æ£€æŸ¥ç®¡é“
        try:
            from scripts.core.content_pipeline import ContentPipeline
            self.content_pipeline = ContentPipeline()
            self.unified_check_available = True
            print("âœ… ç»Ÿä¸€å†…å®¹è´¨é‡æ£€æŸ¥ç³»ç»Ÿå·²å¯ç”¨")
        except ImportError as e:
            print(f"âš ï¸ ContentPipelineä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ£€æŸ¥ (åŸå› : {e})")
            self.content_pipeline = None
            self.unified_check_available = False
        except Exception as e:
            print(f"âš ï¸ å†…å®¹è´¨é‡æ£€æŸ¥ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.content_pipeline = None
            self.unified_check_available = False
        
        # é»˜è®¤åˆ†ç±»æ˜ å°„
        self.category_mapping = {
            'è®¤çŸ¥': 'cognitive-upgrade',
            'è®¤çŸ¥å‡çº§': 'cognitive-upgrade',
            'æ€ç»´': 'cognitive-upgrade',
            'å­¦ä¹ ': 'cognitive-upgrade',
            
            'æŠ€æœ¯': 'tech-empowerment',
            'å·¥å…·': 'tech-empowerment',
            'æ•ˆç‡': 'tech-empowerment',
            'è‡ªåŠ¨åŒ–': 'tech-empowerment',
            
            'å…¨çƒ': 'global-perspective',
            'å›½é™…': 'global-perspective',
            'æ–‡åŒ–': 'global-perspective',
            'è§†é‡': 'global-perspective',
            
            'æŠ•èµ„': 'investment-finance',
            'ç†è´¢': 'investment-finance',
            'é‡‘è': 'investment-finance',
            'è´¢åŠ¡': 'investment-finance'
        }
        
        # é»˜è®¤æ¨¡æ¿é…ç½®
        self.default_config = {
            "layout": "single",
            "author_profile": True,
            "breadcrumbs": True,
            "comments": True,
            "related": True,
            "share": True,
            "toc": True,
            "toc_icon": "list",
            "toc_label": "æœ¬é¡µå†…å®¹",
            "toc_sticky": True
        }

    def detect_category(self, title: str, content: str) -> str:
        """
        æ™ºèƒ½æ£€æµ‹æ–‡ç« åˆ†ç±»
        
        Args:
            title: æ–‡ç« æ ‡é¢˜
            content: æ–‡ç« å†…å®¹
            
        Returns:
            æ£€æµ‹åˆ°çš„åˆ†ç±»
        """
        text = (title + " " + content).lower()
        
        # åˆ†ç±»å…³é”®è¯æƒé‡
        category_scores = {
            'cognitive-upgrade': 0,
            'tech-empowerment': 0,
            'global-perspective': 0,
            'investment-finance': 0
        }
        
        # è®¤çŸ¥å‡çº§å…³é”®è¯
        cognitive_keywords = ['æ€ç»´', 'å­¦ä¹ ', 'è®¤çŸ¥', 'å¿ƒç†', 'å†³ç­–', 'æ¨¡å‹', 'æ–¹æ³•', 'æˆé•¿', 'æ™ºæ…§']
        for keyword in cognitive_keywords:
            category_scores['cognitive-upgrade'] += text.count(keyword) * 2
        
        # æŠ€æœ¯èµ‹èƒ½å…³é”®è¯
        tech_keywords = ['æŠ€æœ¯', 'å·¥å…·', 'ai', 'è‡ªåŠ¨åŒ–', 'æ•ˆç‡', 'è½¯ä»¶', 'ç³»ç»Ÿ', 'å¹³å°', 'app', 'api']
        for keyword in tech_keywords:
            category_scores['tech-empowerment'] += text.count(keyword) * 2
        
        # å…¨çƒè§†é‡å…³é”®è¯
        global_keywords = ['å…¨çƒ', 'å›½é™…', 'æ–‡åŒ–', 'ç¾å›½', 'ä¸­å›½', 'æ¬§æ´²', 'è¶‹åŠ¿', 'è§‚å¯Ÿ', 'å·®å¼‚', 'è§†é‡']
        for keyword in global_keywords:
            category_scores['global-perspective'] += text.count(keyword) * 2
            
        # æŠ•èµ„ç†è´¢å…³é”®è¯
        finance_keywords = ['æŠ•èµ„', 'ç†è´¢', 'é‡‘è', 'è‚¡ç¥¨', 'åŸºé‡‘', 'æ”¶ç›Š', 'é£é™©', 'è´¢åŠ¡', 'èµ„äº§', 'å¸‚åœº']
        for keyword in finance_keywords:
            category_scores['investment-finance'] += text.count(keyword) * 2
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„åˆ†ç±»
        best_category = max(category_scores.items(), key=lambda x: x[1])[0]
        
        # å¦‚æœæ‰€æœ‰åˆ†ç±»å¾—åˆ†éƒ½å¾ˆä½ï¼Œæ ¹æ®é•¿åº¦è¿”å›é»˜è®¤åˆ†ç±»
        if category_scores[best_category] < 3:
            if len(content) > 2000:
                return 'global-perspective'  # é•¿æ–‡ç« é€šå¸¸æ˜¯å…¨çƒè§†é‡
            else:
                return 'cognitive-upgrade'   # çŸ­æ–‡ç« é€šå¸¸æ˜¯è®¤çŸ¥å‡çº§
        
        return best_category

    def generate_tags(self, title: str, content: str, category: str) -> List[str]:
        """
        æ™ºèƒ½ç”Ÿæˆæ ‡ç­¾
        
        Args:
            title: æ–‡ç« æ ‡é¢˜
            content: æ–‡ç« å†…å®¹  
            category: åˆ†ç±»
            
        Returns:
            ç”Ÿæˆçš„æ ‡ç­¾åˆ—è¡¨
        """
        tags = set()
        text = (title + " " + content).lower()
        
        # åŸºç¡€æ ‡ç­¾æ˜ å°„
        tag_keywords = {
            'å­¦ä¹ ': ['å­¦ä¹ æ–¹æ³•', 'ç»ˆèº«å­¦ä¹ ', 'çŸ¥è¯†ç®¡ç†'],
            'æ€ç»´': ['æ€ç»´æ¨¡å‹', 'æ‰¹åˆ¤æ€ç»´', 'é€»è¾‘æ€ç»´'],
            'ai': ['äººå·¥æ™ºèƒ½', 'AIå·¥å…·', 'æœºå™¨å­¦ä¹ '],
            'å·¥å…·': ['ç”Ÿäº§åŠ›å·¥å…·', 'æ•ˆç‡å·¥å…·', 'è½¯ä»¶æ¨è'],
            'æŠ•èµ„': ['æŠ•èµ„ç­–ç•¥', 'ç†è´¢è§„åˆ’', 'è´¢åŠ¡ç®¡ç†'],
            'ç¾å›½': ['ç¾å›½å¸‚åœº', 'ç¾è‚¡æŠ•èµ„', 'ç¾å›½æ–‡åŒ–'],
            'æŠ€æœ¯': ['æŠ€æœ¯è¶‹åŠ¿', 'ç§‘æŠ€åˆ›æ–°', 'æ•°å­—åŒ–è½¬å‹'],
            'å…¨çƒ': ['å…¨çƒåŒ–', 'å›½é™…è§†é‡', 'è·¨æ–‡åŒ–äº¤æµ']
        }
        
        # æ ¹æ®å…³é”®è¯ç”Ÿæˆæ ‡ç­¾
        for keyword, tag_list in tag_keywords.items():
            if keyword in text:
                tags.update(tag_list)
        
        # æ ¹æ®åˆ†ç±»æ·»åŠ é»˜è®¤æ ‡ç­¾
        category_default_tags = {
            'cognitive-upgrade': ['ä¸ªäººæˆé•¿', 'è®¤çŸ¥æå‡'],
            'tech-empowerment': ['æŠ€æœ¯å·¥å…·', 'æ•ˆç‡æå‡'],
            'global-perspective': ['å…¨çƒè§†é‡', 'å›½é™…è¶‹åŠ¿'],
            'investment-finance': ['æŠ•èµ„ç†è´¢', 'è´¢åŠ¡è§„åˆ’']
        }
        
        tags.update(category_default_tags.get(category, []))
        
        # é™åˆ¶æ ‡ç­¾æ•°é‡ï¼ˆ3-6ä¸ªï¼‰
        return list(tags)[:6] if len(tags) > 6 else list(tags)

    def generate_excerpt(self, content: str, target_length: int = 60) -> str:
        """
        ç”Ÿæˆæ–‡ç« æ‘˜è¦
        
        Args:
            content: æ–‡ç« å†…å®¹
            target_length: ç›®æ ‡é•¿åº¦ï¼ˆé»˜è®¤60å­—ç¬¦ï¼‰
            
        Returns:
            ç”Ÿæˆçš„æ‘˜è¦
        """
        # ç§»é™¤markdownæ ¼å¼å’Œç‰¹æ®Šå­—ç¬¦
        clean_content = re.sub(r'[#*`\[\](){}]', '', content)
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
        
        # å–æ›´å¤šå†…å®¹æ¥å¯»æ‰¾åˆé€‚çš„æˆªæ–­ç‚¹
        search_length = max(150, target_length * 2)
        excerpt = clean_content[:search_length]
        
        # åœ¨å¥å·ã€æ„Ÿå¹å·ã€é—®å·å¤„æˆªæ–­
        min_length = max(30, target_length - 20)  # æœ€å°é•¿åº¦
        max_length = target_length + 20           # æœ€å¤§é•¿åº¦
        
        for punct in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']:
            if punct in excerpt[min_length:max_length]:  # åœ¨åˆç†ä½ç½®å¯»æ‰¾æ ‡ç‚¹
                punct_pos = excerpt.find(punct, min_length)
                if punct_pos != -1:
                    excerpt = excerpt[:punct_pos + 1]
                    break
        
        # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œå¼ºåˆ¶æˆªæ–­
        if len(excerpt) > target_length + 10:
            excerpt = excerpt[:target_length - 3] + "..."
        
        # å¦‚æœå¤ªçŸ­ï¼Œå°è¯•æ·»åŠ æ›´å¤šå†…å®¹
        if len(excerpt) < target_length - 10:
            # å–æ›´å¤šå†…å®¹å¹¶å¼ºåˆ¶æˆªæ–­
            excerpt = clean_content[:target_length - 3] + "..."
        
        return excerpt

    def find_first_image(self, content: str) -> Optional[str]:
        """
        æŸ¥æ‰¾æ–‡ç« å†…å®¹ä¸­çš„ç¬¬ä¸€å¼ å›¾ç‰‡
        
        Args:
            content: æ–‡ç« å†…å®¹
            
        Returns:
            ç¬¬ä¸€å¼ å›¾ç‰‡çš„è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        # æŸ¥æ‰¾markdownæ ¼å¼çš„å›¾ç‰‡
        image_pattern = re.compile(r'!\[(.*?)\]\((.*?)\)')
        
        for match in image_pattern.finditer(content):
            img_path = match.group(2).strip()
            
            # è·³è¿‡ç©ºè·¯å¾„
            if not img_path:
                continue
                
            # è·³è¿‡ç½‘ç»œé“¾æ¥ï¼Œä¿ç•™æœ¬åœ°å›¾ç‰‡è·¯å¾„
            if img_path.startswith(('http://', 'https://')):
                # ä½†å¦‚æœæ˜¯OneDriveé“¾æ¥ï¼Œå¯ä»¥ä½¿ç”¨
                if '1drv.ms' in img_path or 'sharepoint.com' in img_path:
                    return img_path
                continue
                
            return img_path
        
        return None

    def create_front_matter(self, title: str, content: str, 
                           category: Optional[str] = None, 
                           tags: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        åˆ›å»ºfront matter
        
        Args:
            title: æ–‡ç« æ ‡é¢˜
            content: æ–‡ç« å†…å®¹
            category: æŒ‡å®šåˆ†ç±»ï¼ˆå¯é€‰ï¼‰
            tags: æŒ‡å®šæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            front matterå­—å…¸
        """
        # æ£€æµ‹æˆ–ä½¿ç”¨æŒ‡å®šçš„åˆ†ç±»
        detected_category = category if category else self.detect_category(title, content)
        
        # ç”Ÿæˆæˆ–ä½¿ç”¨æŒ‡å®šçš„æ ‡ç­¾
        generated_tags = tags if tags else self.generate_tags(title, content, detected_category)
        
        # ç”Ÿæˆæ‘˜è¦
        excerpt = self.generate_excerpt(content)
        
        # æŸ¥æ‰¾ç¬¬ä¸€å¼ å›¾ç‰‡
        first_image = self.find_first_image(content)
        
        # åˆ›å»ºheaderå­—æ®µ
        if first_image:
            # å¦‚æœæ˜¯OneDriveé“¾æ¥ï¼Œç›´æ¥ä½¿ç”¨
            if '1drv.ms' in first_image or 'sharepoint.com' in first_image:
                header_image = first_image
            else:
                # æœ¬åœ°å›¾ç‰‡ï¼Œè½¬æ¢ä¸ºOneDriveç¤ºä¾‹é“¾æ¥ï¼ˆå®é™…ä½¿ç”¨ä¸­ä¼šè¢«åç»­å¤„ç†æ›¿æ¢ï¼‰
                header_image = "https://1drv.ms/i/c/5644dab129afda10/IQTq4kEOrERvRLHS_4L9uCK_ARjvU4zbducjMUCRTRR8Pdk"
        else:
            # æ²¡æœ‰å›¾ç‰‡æ—¶ä½¿ç”¨é»˜è®¤OneDriveé“¾æ¥
            header_image = "https://1drv.ms/i/c/5644dab129afda10/IQTq4kEOrERvRLHS_4L9uCK_ARjvU4zbducjMUCRTRR8Pdk"
        
        # æ„å»ºfront matter - åªåŒ…å«å¿…éœ€å­—æ®µ
        front_matter = {
            "title": title,
            "date": datetime.now().strftime('%Y-%m-%d'),
            "header": {
                "teaser": header_image  # åªä¿ç•™teaserï¼Œå…¶ä»–headerå­—æ®µåœ¨å‘å¸ƒæ—¶è‡ªåŠ¨æ·»åŠ 
            }
        }

        # æ³¨æ„ï¼šä¸æ·»åŠ é»˜è®¤é…ç½®ï¼Œè¿™äº›ä¼šåœ¨å‘å¸ƒæ—¶è‡ªåŠ¨å¤„ç†
        # ä¸æ·»åŠ categoriesã€tagså’Œexcerptï¼Œè¿™äº›ä¹Ÿä¼šåœ¨å‘å¸ƒæ—¶ç”Ÿæˆ

        return front_matter

    def fix_header_field(self, front_matter: Dict[str, Any], body_content: str) -> bool:
        """
        æ£€æŸ¥å¹¶ä¿®å¤front matterä¸­çš„headerå­—æ®µå’Œå…¶ä»–å¿…éœ€å­—æ®µ
        
        Args:
            front_matter: å‰ç½®æ•°æ®å­—å…¸
            body_content: æ–‡ç« æ­£æ–‡å†…å®¹
            
        Returns:
            æ˜¯å¦è¿›è¡Œäº†ä¿®å¤
        """
        header = front_matter.get('header', {})
        needs_update = False
        
        # æ£€æŸ¥headerå­—æ®µ
        required_header_fields = {
            'overlay_color': '#333',
            'overlay_filter': 0.5,
            'overlay_image': None,  # éœ€è¦ç¡®å®šå›¾ç‰‡
            'teaser': None  # éœ€è¦ç¡®å®šå›¾ç‰‡
        }
        
        # æƒ…å†µ1: æ²¡æœ‰headerå­—æ®µ
        if not header:
            needs_update = True
            print("ğŸ“‹ å‘ç°ç¼ºå¤±headerå­—æ®µ")
        else:
            # æƒ…å†µ2: headerå­—æ®µä¸å®Œæ•´
            missing_fields = []
            for field in required_header_fields:
                if field not in header:
                    missing_fields.append(field)
                    needs_update = True
            
            if missing_fields:
                print(f"ğŸ“‹ å‘ç°ç¼ºå¤±headerå­å­—æ®µ: {', '.join(missing_fields)}")
        
        # æ£€æŸ¥å…¶ä»–å¿…éœ€å­—æ®µ
        other_issues = []
        
        # æ£€æŸ¥tagså­—æ®µ
        if 'tags' not in front_matter or not front_matter.get('tags'):
            title = front_matter.get('title', '')
            if title:
                # ç”Ÿæˆtags
                generated_tags = self.generate_tags(title, body_content, front_matter.get('categories', ['cognitive-upgrade'])[0])
                front_matter['tags'] = generated_tags
                needs_update = True
                other_issues.append("tagså­—æ®µ")
        
        # æ£€æŸ¥excerptå­—æ®µ
        if 'excerpt' not in front_matter or not front_matter.get('excerpt'):
            excerpt = self.generate_excerpt(body_content)
            front_matter['excerpt'] = excerpt
            needs_update = True
            other_issues.append("excerptå­—æ®µ")
        else:
            # æ£€æŸ¥excerpté•¿åº¦
            current_excerpt = front_matter['excerpt']
            if len(current_excerpt) < 50:
                # é‡æ–°ç”Ÿæˆæ›´é•¿çš„excerpt
                excerpt = self.generate_excerpt(body_content, target_length=55)
                front_matter['excerpt'] = excerpt
                needs_update = True
                other_issues.append("excerpté•¿åº¦ä¸è¶³")
        
        if other_issues:
            print(f"ğŸ“‹ å‘ç°å…¶ä»–ç¼ºå¤±å­—æ®µ: {', '.join(other_issues)}")
        
        if not needs_update:
            return False
        
        # ä¿®å¤headerå­—æ®µ
        if needs_update and (not header or any(field not in header for field in required_header_fields)):
            # ç¡®å®šä½¿ç”¨çš„å›¾ç‰‡
            header_image = self.determine_header_image(header, body_content)
            
            # ä¿®å¤headerå­—æ®µ
            if 'header' not in front_matter:
                front_matter['header'] = {}
            
            # è®¾ç½®å¿…éœ€å­—æ®µ
            front_matter['header']['overlay_color'] = header.get('overlay_color', '#333')
            front_matter['header']['overlay_filter'] = header.get('overlay_filter', 0.5)
            front_matter['header']['overlay_image'] = header.get('overlay_image', header_image)
            front_matter['header']['teaser'] = header.get('teaser', header_image)
        
        return True
    
    def determine_header_image(self, existing_header: Dict[str, Any], body_content: str) -> str:
        """
        ç¡®å®šåº”è¯¥ä½¿ç”¨çš„headerå›¾ç‰‡
        
        Args:
            existing_header: ç°æœ‰çš„headerå­—æ®µ
            body_content: æ–‡ç« æ­£æ–‡å†…å®¹
            
        Returns:
            å›¾ç‰‡URL
        """
        # ä¼˜å…ˆçº§1: å¦‚æœå·²æœ‰overlay_imageæˆ–teaserï¼Œä½¿ç”¨ç°æœ‰çš„
        if existing_header.get('overlay_image'):
            print(f"ğŸ–¼ï¸ ä½¿ç”¨ç°æœ‰overlay_image: {existing_header['overlay_image']}")
            return existing_header['overlay_image']
        
        if existing_header.get('teaser'):
            print(f"ğŸ–¼ï¸ ä½¿ç”¨ç°æœ‰teaser: {existing_header['teaser']}")
            return existing_header['teaser']
        
        # ä¼˜å…ˆçº§2: æŸ¥æ‰¾æ­£æ–‡ä¸­çš„ç¬¬ä¸€å¼ å›¾ç‰‡
        first_image = self.find_first_image(body_content)
        if first_image:
            if '1drv.ms' in first_image or 'sharepoint.com' in first_image:
                print(f"ğŸ–¼ï¸ ä½¿ç”¨æ­£æ–‡ç¬¬ä¸€å¼ OneDriveå›¾ç‰‡: {first_image}")
                return first_image
            else:
                print(f"ğŸ–¼ï¸ ä½¿ç”¨æ­£æ–‡ç¬¬ä¸€å¼ å›¾ç‰‡: {first_image}")
                # ç›´æ¥ä½¿ç”¨æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼Œåç»­ç”±OneDriveå¤„ç†å™¨è‡ªåŠ¨å¤„ç†
                return first_image
        
        # ä¼˜å…ˆçº§3: ä½¿ç”¨é»˜è®¤OneDriveé“¾æ¥
        print("ğŸ–¼ï¸ æœªæ‰¾åˆ°å›¾ç‰‡ï¼Œä½¿ç”¨é»˜è®¤OneDriveé“¾æ¥")
        return "https://1drv.ms/i/c/5644dab129afda10/IQTq4kEOrERvRLHS_4L9uCK_ARjvU4zbducjMUCRTRR8Pdk"

    def format_content(self, content: str) -> str:
        """
        æ ¼å¼åŒ–æ–‡ç« å†…å®¹
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            æ ¼å¼åŒ–åçš„å†…å®¹
        """
        lines = content.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line:
                formatted_lines.append('')
                continue
            
            # å¤„ç†æ ‡é¢˜ï¼ˆç¡®ä¿æ ‡é¢˜æ ¼å¼æ­£ç¡®ï¼‰
            if line.startswith('#'):
                # ç¡®ä¿æ ‡é¢˜åæœ‰ç©ºæ ¼
                if not line[1:].startswith(' '):
                    line = line[0] + ' ' + line[1:]
                formatted_lines.append(line)
            
            # å¤„ç†åˆ—è¡¨é¡¹
            elif line.startswith('-') or line.startswith('*'):
                if not line[1:].startswith(' '):
                    line = line[0] + ' ' + line[1:]
                formatted_lines.append(line)
            
            # å¤„ç†ç¼–å·åˆ—è¡¨
            elif re.match(r'^\d+\.', line):
                formatted_lines.append(line)
            
            # æ™®é€šæ®µè½
            else:
                formatted_lines.append(line)
        
        # åœ¨é€‚å½“ä½ç½®æ·»åŠ <!-- more -->æ ‡ç­¾
        content_with_more = self.add_more_tag('\n'.join(formatted_lines))
        
        return content_with_more

    def create_content_structure(self, content: str, title: str) -> str:
        """
        åˆ›å»ºæ ‡å‡†å†…å®¹ç»“æ„ï¼šæ‘˜è¦ + <!-- more --> + èƒŒæ™¯ä»‹ç»(å¯é€‰) + ä¸»ä½“å†…å®¹
        
        Args:
            content: åŸå§‹å†…å®¹
            title: æ–‡ç« æ ‡é¢˜
            
        Returns:
            ç»“æ„åŒ–çš„å†…å®¹
        """
        lines = content.split('\n')
        clean_lines = [line.strip() for line in lines if line.strip()]
        
        if not clean_lines:
            return content
        
        # ç”Ÿæˆå¼€å¤´æ‘˜è¦ (50-60å­—ç¬¦)
        summary = self.generate_opening_summary(content, title)
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦èƒŒæ™¯ä»‹ç»
        needs_background = self.needs_background_introduction(content, title)
        
        # æ„å»ºç»“æ„åŒ–å†…å®¹
        structured_content = [summary, '', '<!-- more -->', '']
        
        # å¦‚æœéœ€è¦èƒŒæ™¯ä»‹ç»ï¼Œæ·»åŠ èƒŒæ™¯ä»‹ç»éƒ¨åˆ†
        if needs_background:
            background = self.generate_background_introduction(content, title)
            structured_content.extend(['## èƒŒæ™¯ä»‹ç»', '', background, ''])
        
        # æ·»åŠ ä¸»ä½“å†…å®¹
        structured_content.extend(['## ä¸»è¦å†…å®¹', ''] + clean_lines)
        
        return '\n'.join(structured_content)

    def format_basic_structure(self, content: str) -> str:
        """
        å¯¹ç»“æ„åŒ–å†…å®¹è¿›è¡ŒåŸºç¡€æ ¼å¼åŒ–
        
        Args:
            content: ç»“æ„åŒ–å†…å®¹
            
        Returns:
            æ ¼å¼åŒ–åçš„å†…å®¹
        """
        lines = content.split('\n')
        formatted_lines = []
        
        for line in lines:
            # ä¿ç•™ç©ºè¡Œå’Œç‰¹æ®Šæ ‡è®°
            if not line.strip() or line.strip() == '<!-- more -->':
                formatted_lines.append(line)
                continue
            
            # å¤„ç†æ ‡é¢˜ï¼ˆç¡®ä¿æ ‡é¢˜æ ¼å¼æ­£ç¡®ï¼‰
            if line.startswith('#'):
                if not line[1:].startswith(' '):
                    line = line[0] + ' ' + line[1:]
                formatted_lines.append(line)
            
            # å¤„ç†åˆ—è¡¨é¡¹
            elif line.startswith('-') or line.startswith('*'):
                if not line[1:].startswith(' '):
                    line = line[0] + ' ' + line[1:]
                formatted_lines.append(line)
            
            # å¤„ç†ç¼–å·åˆ—è¡¨
            elif re.match(r'^\d+\.', line):
                formatted_lines.append(line)
            
            # æ™®é€šæ®µè½
            else:
                formatted_lines.append(line)
        
        return '\n'.join(formatted_lines)

    def generate_opening_summary(self, content: str, title: str) -> str:
        """
        ç”Ÿæˆå¼€å¤´æ‘˜è¦æ®µè½ (50-60å­—ç¬¦)
        
        Args:
            content: æ–‡ç« å†…å®¹
            title: æ–‡ç« æ ‡é¢˜
            
        Returns:
            æ‘˜è¦æ®µè½
        """
        # ç§»é™¤markdownæ ¼å¼
        clean_content = re.sub(r'[#*`\[\](){}]', '', content)
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
        
        # æå–å…³é”®å¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', clean_content)
        key_sentences = [s.strip() for s in sentences[:3] if len(s.strip()) > 10]
        
        if key_sentences:
            # ä»ç¬¬ä¸€å¥å¼€å§‹æ„å»ºæ‘˜è¦
            summary = key_sentences[0]
            
            # ç¡®ä¿é•¿åº¦åœ¨50-60å­—ç¬¦
            if len(summary) > 60:
                summary = summary[:57] + "..."
            elif len(summary) < 50 and len(key_sentences) > 1:
                # å°è¯•æ·»åŠ ç¬¬äºŒå¥çš„éƒ¨åˆ†å†…å®¹
                remaining = 57 - len(summary) - 1  # é¢„ç•™çœç•¥å·ç©ºé—´
                if remaining > 10:
                    addition = key_sentences[1][:remaining]
                    summary = summary + "ï¼Œ" + addition + "..."
        else:
            # å›é€€æ–¹æ¡ˆï¼šåŸºäºæ ‡é¢˜ç”Ÿæˆæ‘˜è¦
            summary = f"æœ¬æ–‡æ¢è®¨{title}ç›¸å…³çš„æ ¸å¿ƒè§‚ç‚¹å’Œå®ç”¨æ–¹æ³•ï¼Œä¸ºè¯»è€…æä¾›æœ‰ä»·å€¼çš„æ€è€ƒå’Œå‚è€ƒã€‚"
        
        return summary

    def needs_background_introduction(self, content: str, title: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦èƒŒæ™¯ä»‹ç»æ®µè½
        
        Args:
            content: æ–‡ç« å†…å®¹
            title: æ–‡ç« æ ‡é¢˜
            
        Returns:
            æ˜¯å¦éœ€è¦èƒŒæ™¯ä»‹ç»
        """
        # æ£€æŸ¥å†…å®¹å¤æ‚æ€§æŒ‡æ ‡
        complexity_indicators = 0
        
        # 1. å†…å®¹é•¿åº¦ (è¶…è¿‡1500å­—ç¬¦è®¤ä¸ºå¤æ‚)
        if len(content) > 1500:
            complexity_indicators += 1
        
        # 2. ä¸“ä¸šæœ¯è¯­å¯†åº¦
        technical_terms = ['api', 'ai', 'ç®—æ³•', 'æ¨¡å‹', 'æ¶æ„', 'ç³»ç»Ÿ', 'å¹³å°', 'æ¡†æ¶', 'æŠ€æœ¯', 'æ–¹æ¡ˆ', 'ç­–ç•¥', 'æœºåˆ¶']
        text_lower = content.lower()
        term_count = sum(1 for term in technical_terms if term in text_lower)
        if term_count >= 3:
            complexity_indicators += 1
        
        # 3. æ•°æ®å’Œæ•°å­—å¯†åº¦
        numbers = re.findall(r'\d+%|\d+\.\d+%|\d+ä¸‡|\d+äº¿|\$\d+', content)
        if len(numbers) >= 3:
            complexity_indicators += 1
        
        # 4. å¤–éƒ¨å¼•ç”¨ (URLã€å¼•ç”¨ç­‰)
        references = re.findall(r'http[s]?://|æ®.*æŠ¥é“|ç ”ç©¶æ˜¾ç¤º|è°ƒæŸ¥è¡¨æ˜', content)
        if len(references) >= 2:
            complexity_indicators += 1
        
        # 5. å¤šçº§æ ‡é¢˜ç»“æ„
        headers = re.findall(r'^#{2,4}\s', content, re.MULTILINE)
        if len(headers) >= 3:
            complexity_indicators += 1
        
        # å¦‚æœå¤æ‚æ€§æŒ‡æ ‡è¾¾åˆ°2ä¸ªæˆ–ä»¥ä¸Šï¼Œéœ€è¦èƒŒæ™¯ä»‹ç»
        return complexity_indicators >= 2

    def generate_background_introduction(self, content: str, title: str) -> str:
        """
        ç”ŸæˆèƒŒæ™¯ä»‹ç»æ®µè½
        
        Args:
            content: æ–‡ç« å†…å®¹
            title: æ–‡ç« æ ‡é¢˜
            
        Returns:
            èƒŒæ™¯ä»‹ç»å†…å®¹
        """
        # æå–å¯èƒ½çš„èƒŒæ™¯ä¿¡æ¯
        background_elements = []
        
        # 1. æ—¶é—´èƒŒæ™¯
        time_patterns = [
            r'(\d{4}å¹´\d{1,2}æœˆ)', r'(è¿‘æœŸ|æœ€è¿‘|ä»Šå¹´)', r'(å»å¹´|ä¸Šä¸ªæœˆ)',
            r'(\d{1,2}æœˆ\d{1,2}æ—¥)', r'(æœ¬å‘¨|ä¸Šå‘¨)'
        ]
        for pattern in time_patterns:
            matches = re.findall(pattern, content)
            if matches:
                background_elements.append(f"æ—¶é—´èƒŒæ™¯ï¼š{matches[0]}")
                break
        
        # 2. äº‹ä»¶èƒŒæ™¯
        event_keywords = ['å‘å¸ƒ', 'å®£å¸ƒ', 'æ¨å‡º', 'æ›´æ–°', 'å‡çº§', 'å˜åŒ–', 'è°ƒæ•´']
        for keyword in event_keywords:
            if keyword in content:
                # æ‰¾åˆ°åŒ…å«å…³é”®è¯çš„å¥å­
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', content)
                for sentence in sentences:
                    if keyword in sentence and len(sentence.strip()) > 20:
                        background_elements.append(f"äº‹ä»¶èƒŒæ™¯ï¼š{sentence.strip()}")
                        break
                break
        
        # 3. æ¦‚å¿µè§£é‡Š (å¦‚æœæ ‡é¢˜åŒ…å«ä¸“ä¸šæœ¯è¯­)
        technical_terms = {
            'AI': 'äººå·¥æ™ºèƒ½æŠ€æœ¯',
            'API': 'åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£',
            'TTS': 'æ–‡æœ¬è½¬è¯­éŸ³æŠ€æœ¯',
            'OAuth': 'å¼€æ”¾æˆæƒåè®®',
            'CDN': 'å†…å®¹åˆ†å‘ç½‘ç»œ'
        }
        for term, explanation in technical_terms.items():
            if term.lower() in title.lower():
                background_elements.append(f"æ¦‚å¿µè¯´æ˜ï¼š{term}æ˜¯æŒ‡{explanation}")
                break
        
        # æ„å»ºèƒŒæ™¯ä»‹ç»
        if background_elements:
            intro = "ä¸ºäº†æ›´å¥½åœ°ç†è§£æœ¬æ–‡å†…å®¹ï¼Œè¿™é‡Œå…ˆæä¾›ä¸€äº›èƒŒæ™¯ä¿¡æ¯ï¼š\n\n"
            intro += "\n".join(f"- {element}" for element in background_elements)
            return intro
        else:
            return f"æœ¬æ–‡å°†è¯¦ç»†åˆ†æ{title}çš„ç›¸å…³å†…å®¹ï¼Œå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ç›¸å…³æ¦‚å¿µå’Œåº”ç”¨åœºæ™¯ã€‚"

    def add_more_tag(self, content: str) -> str:
        """
        ä¿æŒåŸæœ‰çš„moreæ ‡ç­¾æ·»åŠ é€»è¾‘ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
        """
        lines = content.split('\n')
        
        # å¯»æ‰¾ç¬¬ä¸€ä¸ªåˆé€‚çš„æ®µè½ç»“æŸä½ç½®ï¼ˆå¤§çº¦200-400å­—ç¬¦å¤„ï¼‰
        char_count = 0
        for i, line in enumerate(lines):
            char_count += len(line)
            
            # åœ¨200-400å­—ç¬¦ä¹‹é—´å¯»æ‰¾æ®µè½ç»“æŸ
            if 200 <= char_count <= 400 and line.strip() == '':
                lines.insert(i + 1, '<!-- more -->')
                break
            # å¦‚æœè¶…è¿‡400å­—ç¬¦ï¼Œå¼ºåˆ¶æ’å…¥
            elif char_count > 400 and line.strip() == '':
                lines.insert(i + 1, '<!-- more -->')
                break
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚ä½ç½®ï¼Œåœ¨ç¬¬3æ®µåæ’å…¥
            paragraph_count = 0
            for i, line in enumerate(lines):
                if line.strip() != '' and not line.startswith('#'):
                    paragraph_count += 1
                    if paragraph_count == 3 and i + 1 < len(lines):
                        lines.insert(i + 1, '')
                        lines.insert(i + 2, '<!-- more -->')
                        break
        
        return '\n'.join(lines)

    def add_footer(self, content: str, category: str) -> str:
        """
        æ·»åŠ é¡µè„šå†…å®¹
        
        Args:
            content: æ–‡ç« å†…å®¹
            category: æ–‡ç« åˆ†ç±»
            
        Returns:
            æ·»åŠ é¡µè„šçš„å†…å®¹
        """
        footer_templates = {
            'investment-finance': '''
---

{% assign investment_tags = 'QDIIåŸºé‡‘,æŒ‡æ•°æŠ•èµ„,æ ‡æ™®500,çº³æ–¯è¾¾å…‹,ç¾è‚¡æŠ•èµ„,æŠ•èµ„ç†è´¢,è´¢åŠ¡è§„åˆ’,èµ„äº§é…ç½®' | split: ',' %}
{% assign current_tags = page.tags %}
{% assign has_investment = false %}
{% for tag in investment_tags %}
  {% if current_tags contains tag %}
    {% assign has_investment = true %}
    {% break %}
  {% endif %}
{% endfor %}

{% if has_investment %}
> **âš ï¸ æŠ•èµ„é£é™©æç¤º**
> 
> æœ¬æ–‡æ¶‰åŠæŠ•èµ„å†…å®¹ä»…ä¾›æ•™è‚²å’Œä¿¡æ¯ç›®çš„ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚
> 
> - ä»»ä½•æŠ•èµ„å†³ç­–åº”åŸºäºä¸ªäººè´¢åŠ¡çŠ¶å†µå’Œé£é™©æ‰¿å—èƒ½åŠ›
> - è¿‡å¾€è¡¨ç°ä¸ä»£è¡¨æœªæ¥ç»“æœ
> - å»ºè®®åœ¨åšå‡ºæŠ•èµ„å†³ç­–å‰å’¨è¯¢ä¸“ä¸šè´¢åŠ¡é¡¾é—®
> - è¯·è‡ªè¡Œæ‰¿æ‹…æŠ•èµ„é£é™©å’Œè´£ä»»
{% endif %}''',
            
            'tech-empowerment': '''
---

> **ğŸ’¡ å·¥å…·ä½¿ç”¨æç¤º**
> 
> æ–‡ä¸­æåˆ°çš„å·¥å…·å’Œæ–¹æ³•ä»…ä¾›å‚è€ƒï¼Œä½¿ç”¨å‰è¯·ï¼š
> - ç¡®ä¿äº†è§£ç›¸å…³é£é™©å’Œé™åˆ¶
> - éµå®ˆç›¸å…³æœåŠ¡æ¡æ¬¾å’Œæ³•å¾‹æ³•è§„  
> - æ ¹æ®ä¸ªäººéœ€æ±‚é€‰æ‹©åˆé€‚çš„è§£å†³æ–¹æ¡ˆ''',
            
            'global-perspective': '''
---

> **ğŸŒ è§‚ç‚¹å£°æ˜**
> 
> æœ¬æ–‡è§‚ç‚¹åŸºäºå…¬å¼€ä¿¡æ¯å’Œä¸ªäººåˆ†æï¼Œä»…ä¾›è¯»è€…å‚è€ƒå’Œæ€è€ƒã€‚
> ä¸åŒæ–‡åŒ–èƒŒæ™¯å’Œç«‹åœºå¯èƒ½äº§ç”Ÿä¸åŒç†è§£ï¼Œæ¬¢è¿ç†æ€§è®¨è®ºã€‚''',
            
            'cognitive-upgrade': '''
---

> **ğŸ§  å­¦ä¹ å»ºè®®**
> 
> è®¤çŸ¥å‡çº§æ˜¯ä¸ªäººåŒ–çš„è¿‡ç¨‹ï¼Œæ–‡ä¸­æ–¹æ³•ä»…ä¾›å‚è€ƒã€‚
> å»ºè®®ç»“åˆä¸ªäººå®é™…æƒ…å†µï¼Œå¾ªåºæ¸è¿›åœ°å®è·µå’Œæ”¹è¿›ã€‚'''
        }
        
        footer = footer_templates.get(category, '')
        return content + footer

    def process_draft(self, input_file: Path, output_file: Optional[Path] = None,
                     title: Optional[str] = None, category: Optional[str] = None,
                     tags: Optional[List[str]] = None) -> Path:
        """
        å¤„ç†è‰ç¨¿æ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            title: æŒ‡å®šæ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            category: æŒ‡å®šåˆ†ç±»ï¼ˆå¯é€‰ï¼‰
            tags: æŒ‡å®šæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è¯»å–åŸå§‹å†…å®¹
        with open(input_file, 'r', encoding='utf-8') as f:
            raw_content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰front matter
        if raw_content.startswith('---'):
            print("âš ï¸ æ£€æµ‹åˆ°å·²å­˜åœ¨front matterï¼Œæ£€æŸ¥headerå­—æ®µå®Œæ•´æ€§")
            
            # è§£æç°æœ‰çš„front matter
            try:
                # åˆ†ç¦»front matterå’Œå†…å®¹
                parts = raw_content.split('---', 2)
                if len(parts) >= 3:
                    yaml_content = parts[1]
                    body_content = parts[2].strip()
                    
                    import yaml
                    front_matter = yaml.safe_load(yaml_content)
                    
                    # æ£€æŸ¥å¹¶ä¿®å¤headerå­—æ®µ
                    header_updated = self.fix_header_field(front_matter, body_content)
                    
                    if header_updated:
                        # é‡æ–°ç”Ÿæˆæ–‡ä»¶
                        yaml_content = yaml.dump(front_matter, default_flow_style=False, 
                                               allow_unicode=True, sort_keys=False)
                        updated_content = f"---\n{yaml_content}---\n{body_content}"
                        
                        with open(input_file, 'w', encoding='utf-8') as f:
                            f.write(updated_content)
                        
                        print("ğŸ”§ å·²ä¿®å¤headerå­—æ®µ")
                    else:
                        print("âœ… headerå­—æ®µå·²å®Œæ•´")
                        
            except Exception as e:
                print(f"âš ï¸ è§£æfront matterå¤±è´¥: {e}")
                
            print(f"âœ… æ ¼å¼åŒ–å®Œæˆ: {input_file}")
            return input_file
        
        # æå–æ ‡é¢˜ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        if not title:
            # å°è¯•ä»ç¬¬ä¸€è¡Œæå–æ ‡é¢˜
            lines = raw_content.strip().split('\n')
            if lines and lines[0].startswith('#'):
                title = lines[0].lstrip('# ').strip()
                # ç§»é™¤æ ‡é¢˜è¡Œ
                raw_content = '\n'.join(lines[1:]).strip()
            else:
                # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜
                title = input_file.stem.replace('-', ' ').replace('_', ' ').title()
        
        # åˆ›å»ºfront matter
        front_matter = self.create_front_matter(title, raw_content, category, tags)

        # ä¸å†è‡ªåŠ¨åˆ›å»ºç»“æ„åŒ–å†…å®¹ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹
        # åªè¿›è¡ŒåŸºç¡€æ ¼å¼åŒ–ï¼ˆä¿®å¤æ ‡ç‚¹ã€æ®µè½ç­‰ï¼‰
        formatted_content = self.format_basic_structure(raw_content)

        # ä¸è‡ªåŠ¨æ·»åŠ é¡µè„šï¼Œè®©å‘å¸ƒæ—¶å¤„ç†
        final_content = formatted_content
        
        # ç”ŸæˆYAML front matter - ä½¿ç”¨yamlåº“æ¥æ­£ç¡®æ ¼å¼åŒ–
        import yaml
        yaml_content = yaml.dump(front_matter, default_flow_style=False,
                                 allow_unicode=True, sort_keys=False)

        # ç»„åˆæœ€ç»ˆå†…å®¹
        full_content = f"---\n{yaml_content}---\n\n{final_content}"
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if not output_file:
            # é»˜è®¤å°±åœ°æ›´æ–°åŸæ–‡ä»¶
            output_file = input_file
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        print(f"âœ… æ ¼å¼åŒ–å®Œæˆ: {output_file}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ ‡é¢˜: {title}")
        print(f"   å†…å®¹é•¿åº¦: {len(final_content)} å­—ç¬¦")
        
        # æ‰§è¡Œç»Ÿä¸€çš„å†…å®¹è´¨é‡æ£€æŸ¥
        if self.unified_check_available:
            print(f"\nğŸ” æ­£åœ¨è¿›è¡Œå†…å®¹è´¨é‡æ£€æŸ¥...")
            check_results = self.content_pipeline.comprehensive_content_check(
                output_file, auto_fix=True
            )
            
            if check_results['check_passed']:
                print("âœ… å†…å®¹è´¨é‡æ£€æŸ¥é€šè¿‡ï¼")
            else:
                print("âš ï¸ å‘ç°å†…å®¹è´¨é‡é—®é¢˜ï¼š")
                
                # æ˜¾ç¤ºè‡ªåŠ¨ä¿®å¤çš„é—®é¢˜
                if check_results['auto_fixes_applied']:
                    print(f"ğŸ”§ å·²è‡ªåŠ¨ä¿®å¤ï¼š")
                    for fix in check_results['auto_fixes_applied']:
                        print(f"   â€¢ {fix}")
                
                # æ˜¾ç¤ºéœ€è¦æ‰‹åŠ¨å¤„ç†çš„é—®é¢˜
                if check_results['manual_fixes_needed']:
                    print(f"\nğŸ’¡ éœ€è¦æ‰‹åŠ¨å¤„ç†çš„é—®é¢˜ï¼š")
                    for item in check_results['manual_fixes_needed']:
                        print(f"   â€¢ {item['issue']}")
                        for suggestion in item['suggestions']:
                            print(f"     {suggestion}")
                
                print(f"\nğŸ“‹ å»ºè®®ï¼šä½¿ç”¨ '2. å†…å®¹è§„èŒƒåŒ–å¤„ç†' â†’ '5. æŸ¥çœ‹å†…å®¹è´¨é‡æ£€æŸ¥' äº†è§£è¯¦æƒ…")
        else:
            print("\nğŸ’¡ æç¤ºï¼šå®‰è£…å®Œæ•´ä¾èµ–å¯å¯ç”¨é«˜çº§å†…å®¹è´¨é‡æ£€æŸ¥")
        
        return output_file

def main():
    parser = argparse.ArgumentParser(description="æ‰‹å·¥è‰ç¨¿å¿«é€Ÿæ’ç‰ˆå·¥å…·")
    parser.add_argument("input", help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-t", "--title", help="æŒ‡å®šæ–‡ç« æ ‡é¢˜")
    parser.add_argument("-c", "--category", 
                       choices=['cognitive-upgrade', 'tech-empowerment', 'global-perspective', 'investment-finance'],
                       help="æŒ‡å®šæ–‡ç« åˆ†ç±»")
    parser.add_argument("--tags", nargs='+', help="æŒ‡å®šæ ‡ç­¾ï¼ˆå¤šä¸ªæ ‡ç­¾ç”¨ç©ºæ ¼åˆ†éš”ï¼‰")
    parser.add_argument("-v", "--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_file = Path(args.input)
    if not input_file.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = DraftFormatter()
    
    try:
        output_file = args.output
        if output_file:
            output_file = Path(output_file)
        
        # å¤„ç†è‰ç¨¿
        result_file = formatter.process_draft(
            input_file=input_file,
            output_file=output_file,
            title=args.title,
            category=args.category,
            tags=args.tags
        )
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“„ æ ¼å¼åŒ–åçš„æ–‡ä»¶: {result_file}")
        print(f"ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ run.py çš„ã€Œå¤„ç†ç°æœ‰è‰ç¨¿ã€åŠŸèƒ½å‘å¸ƒåˆ°å„å¹³å°")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()