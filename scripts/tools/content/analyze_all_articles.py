#!/usr/bin/env python3
"""
ç»¼åˆæ–‡ç« åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
1. è¯»å–Grideaæœ¬åœ°æ–‡ç« ï¼ˆ81ç¯‡ï¼‰
2. è¯»å–Jekyll _postsæ–‡ç« ï¼ˆ30ç¯‡ï¼‰
3. å¯¹æ¯”å»é‡ï¼Œè¯†åˆ«è¿ç§»çŠ¶æ€
4. ç”Ÿæˆå®Œæ•´çš„æ–‡ç« ç™»è®°è¡¨

ä½¿ç”¨ï¼š
python scripts/tools/content/analyze_all_articles.py
"""

import re
import yaml
from pathlib import Path
from datetime import datetime
from collections import defaultdict


class ArticleAnalyzer:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent.parent
        self.gridea_dir = Path("/mnt/c/onedrive/wuxiami/OneDrive/Documents/Gridea/posts")
        self.jekyll_posts_dir = self.project_root / "_posts"

        self.gridea_articles = []
        self.jekyll_articles = []
        self.title_map = {}  # æ ‡é¢˜æ˜ å°„ï¼Œç”¨äºå»é‡

    def extract_gridea_front_matter(self, file_path):
        """æå–Grideaæ–‡ç« çš„Front Matter"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Grideaä½¿ç”¨ ---...--- æ ¼å¼
            match = re.match(r'^---\s*\n(.*?)\n---', content, re.DOTALL)
            if not match:
                return None, content

            try:
                front_matter = yaml.safe_load(match.group(1))
                body = content[match.end():].strip()
                return front_matter, body
            except:
                return None, content
        except Exception as e:
            print(f"âš ï¸ è¯»å–å¤±è´¥ {file_path.name}: {e}")
            return None, ""

    def scan_gridea_articles(self):
        """æ‰«æGrideaæ–‡ç« """
        print("ğŸ“š æ‰«æGrideaæ–‡ç« ç›®å½•...")

        if not self.gridea_dir.exists():
            print(f"âŒ Grideaç›®å½•ä¸å­˜åœ¨: {self.gridea_dir}")
            return

        for md_file in self.gridea_dir.glob("*.md"):
            if md_file.name == "about.md":
                continue

            front_matter, body = self.extract_gridea_front_matter(md_file)
            if not front_matter:
                continue

            title = front_matter.get('title', 'No Title')
            date = front_matter.get('date', front_matter.get('published', 'Unknown'))
            tags = front_matter.get('tags', [])

            # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
            if isinstance(date, datetime):
                date_str = date.strftime('%Y-%m-%d')
            else:
                date_str = str(date)[:10] if len(str(date)) >= 10 else str(date)

            article_info = {
                'source': 'gridea',
                'filename': md_file.name,
                'title': title,
                'date': date_str,
                'tags': tags if isinstance(tags, list) else [],
                'word_count': len(body),
                'file_path': str(md_file)
            }

            self.gridea_articles.append(article_info)
            self.title_map[title.strip().lower()] = article_info

        print(f"âœ… Grideaæ–‡ç« : {len(self.gridea_articles)} ç¯‡")

    def scan_jekyll_articles(self):
        """æ‰«æJekyllæ–‡ç« """
        print("\nğŸ“š æ‰«æJekyll _postsç›®å½•...")

        for md_file in self.jekyll_posts_dir.glob("*.md"):
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                match = re.match(r'^---\s*\n(.*?)\n---', content, re.DOTALL)
                if not match:
                    continue

                front_matter = yaml.safe_load(match.group(1))
                body = content[match.end():].strip()

                filename = md_file.stem
                date_match = re.match(r'^(\d{4}-\d{2}-\d{2})-(.+)$', filename)

                title = front_matter.get('title', 'No Title')
                date = front_matter.get('date', date_match.group(1) if date_match else 'Unknown')
                categories = front_matter.get('categories', [])

                # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
                if isinstance(date, datetime):
                    date_str = date.strftime('%Y-%m-%d')
                else:
                    date_str = str(date)[:10] if len(str(date)) >= 10 else str(date)

                article_info = {
                    'source': 'jekyll',
                    'filename': md_file.name,
                    'slug': date_match.group(2) if date_match else filename,
                    'title': title,
                    'date': date_str,
                    'categories': categories if isinstance(categories, list) else [],
                    'word_count': len(body),
                    'file_path': str(md_file)
                }

                self.jekyll_articles.append(article_info)

            except Exception as e:
                print(f"âš ï¸ è¯»å–å¤±è´¥ {md_file.name}: {e}")

        print(f"âœ… Jekyllæ–‡ç« : {len(self.jekyll_articles)} ç¯‡")

    def compare_articles(self):
        """å¯¹æ¯”æ–‡ç« ï¼Œè¯†åˆ«è¿ç§»çŠ¶æ€"""
        print("\nğŸ” å¯¹æ¯”Grideaå’ŒJekyllæ–‡ç« ...")

        # åŸºäºæ ‡é¢˜åŒ¹é…
        migrated = []
        not_migrated = []

        jekyll_titles = {a['title'].strip().lower() for a in self.jekyll_articles}

        for gridea_article in self.gridea_articles:
            title_lower = gridea_article['title'].strip().lower()
            if title_lower in jekyll_titles:
                gridea_article['migration_status'] = 'âœ… å·²è¿ç§»'
                migrated.append(gridea_article)
            else:
                gridea_article['migration_status'] = 'âŒ æœªè¿ç§»'
                not_migrated.append(gridea_article)

        return migrated, not_migrated

    def categorize_articles(self, articles):
        """æŒ‰ä¸»é¢˜åˆ†ç±»æ–‡ç« """
        categories = defaultdict(list)

        for article in articles:
            title = article['title']

            # åŸºäºæ ‡é¢˜å…³é”®è¯åˆ†ç±»
            if any(k in title for k in ['æŠ•èµ„', 'ç¾è‚¡', 'å®šæŠ•', 'TQQQ', 'DCA', 'æœŸæƒ', 'é‡åŒ–', 'ETF', 'Moomoo', 'ç½‘æ ¼', 'QDII', 'è‚¡ç¥¨', 'åŸºé‡‘']):
                categories['ğŸ’° æŠ•èµ„ç†è´¢'].append(article)
            elif any(k in title for k in ['ç‰¹æ–¯æ‹‰', 'Tesla', 'é©¬æ–¯å…‹', 'Optimus', 'Robotaxi', 'FSD']):
                categories['ğŸŒ ç‰¹æ–¯æ‹‰ç ”ç©¶'].append(article)
            elif any(k in title for k in ['VPS', 'GitHub', 'Cloudflare', 'è‡ªæ‰˜ç®¡', 'Gridea', 'Jekyll', 'ChatGPT', 'AI', 'Lobe Chat', 'NextChat', 'Pandora', 'LM Studio', 'Kimi']):
                categories['ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½'].append(article)
            elif any(k in title for k in ['ä¿¡æ¯', 'å­¦ä¹ ', 'è¯»ä¹¦', 'æ€ç»´', 'æ„å¿—åŠ›', 'è‡ªæˆ‘å¯¹è¯', 'ç¬”è®°', 'æ•ˆç‡']):
                categories['ğŸ§  è®¤çŸ¥å‡çº§'].append(article)
            elif any(k in title for k in ['è‹±è¯­', 'å·´ä¼¦', 'æ°‘ä¸»å…š', 'å…±å’Œå…š', 'Prove Me Wrong']):
                categories['ğŸ“º è‹±è¯­å­¦ä¹ ä¸è§‚å¯Ÿ'].append(article)
            else:
                categories['ğŸ“ å…¶ä»–'].append(article)

        return dict(categories)

    def generate_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        migrated, not_migrated = self.compare_articles()

        print("\n" + "="*70)
        print("ğŸ“Š ç»¼åˆæ–‡ç« åˆ†ææŠ¥å‘Š")
        print("="*70)

        print(f"\nGrideaæ–‡ç« æ€»æ•°: {len(self.gridea_articles)} ç¯‡")
        print(f"Jekyllæ–‡ç« æ€»æ•°: {len(self.jekyll_articles)} ç¯‡")
        print(f"\nå·²è¿ç§»åˆ°Jekyll: {len(migrated)} ç¯‡ ({len(migrated)/len(self.gridea_articles)*100:.1f}%)")
        print(f"å°šæœªè¿ç§»: {len(not_migrated)} ç¯‡ ({len(not_migrated)/len(self.gridea_articles)*100:.1f}%)")

        # æœªè¿ç§»æ–‡ç« åˆ†ç±»
        if not_migrated:
            print("\nâš ï¸ æœªè¿ç§»æ–‡ç« æŒ‰ä¸»é¢˜åˆ†ç±»ï¼š")
            categorized = self.categorize_articles(not_migrated)

            for category, articles in sorted(categorized.items()):
                print(f"\n{category} ({len(articles)}ç¯‡):")
                for article in sorted(articles, key=lambda x: x.get('date', ''), reverse=True)[:5]:
                    print(f"  - {article['date']} | {article['title']}")
                if len(articles) > 5:
                    print(f"  ... è¿˜æœ‰ {len(articles) - 5} ç¯‡")

        print("\n" + "="*70)

        return migrated, not_migrated

    def generate_markdown_registry(self):
        """ç”Ÿæˆå®Œæ•´çš„Markdownç™»è®°è¡¨"""
        migrated, not_migrated = self.compare_articles()

        output = []
        output.append("# ğŸ“š å®Œæ•´æ–‡ç« ç™»è®°è¡¨ï¼ˆGridea + Jekyllï¼‰\n")
        output.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        output.append(f"**Grideaæ–‡ç« **: {len(self.gridea_articles)} ç¯‡")
        output.append(f"**Jekyllæ–‡ç« **: {len(self.jekyll_articles)} ç¯‡")
        output.append(f"**å·²è¿ç§»**: {len(migrated)} ç¯‡")
        output.append(f"**æœªè¿ç§»**: {len(not_migrated)} ç¯‡\n")

        output.append("---\n")

        # å·²è¿ç§»æ–‡ç« 
        output.append("## âœ… å·²è¿ç§»åˆ°Jekyllçš„æ–‡ç«  ({} ç¯‡)\n".format(len(migrated)))
        categorized_migrated = self.categorize_articles(migrated)

        for category, articles in sorted(categorized_migrated.items()):
            output.append(f"### {category} ({len(articles)}ç¯‡)\n")
            output.append("| å‘å¸ƒæ—¥æœŸ | æ–‡ç« æ ‡é¢˜ | Grideaæ–‡ä»¶ | å­—æ•° |")
            output.append("|---------|---------|-----------|------|")

            for article in sorted(articles, key=lambda x: x.get('date', ''), reverse=True):
                date = article.get('date', 'Unknown')
                title = article['title']
                filename = f"`{article['filename']}`"
                word_count = f"{article['word_count']:,}"

                output.append(f"| {date} | {title} | {filename} | {word_count} |")

            output.append("")

        # æœªè¿ç§»æ–‡ç« 
        if not_migrated:
            output.append("---\n")
            output.append("## âŒ å°šæœªè¿ç§»çš„Grideaæ–‡ç«  ({} ç¯‡)\n".format(len(not_migrated)))
            categorized_not_migrated = self.categorize_articles(not_migrated)

            for category, articles in sorted(categorized_not_migrated.items()):
                output.append(f"### {category} ({len(articles)}ç¯‡)\n")
                output.append("| å‘å¸ƒæ—¥æœŸ | æ–‡ç« æ ‡é¢˜ | æ–‡ä»¶å | å­—æ•° | å»ºè®® |")
                output.append("|---------|---------|--------|------|------|")

                for article in sorted(articles, key=lambda x: x.get('date', ''), reverse=True):
                    date = article.get('date', 'Unknown')
                    title = article['title']
                    filename = f"`{article['filename']}`"
                    word_count = f"{article['word_count']:,}"

                    # åŸºäºå­—æ•°å’Œæ—¥æœŸç»™å‡ºå»ºè®®
                    if article['word_count'] > 3000 and date.startswith('2024') or date.startswith('2025'):
                        suggestion = "ğŸ”¥ æ¨èè¿ç§»"
                    elif article['word_count'] > 1000:
                        suggestion = "ğŸ“ å¯è€ƒè™‘"
                    else:
                        suggestion = "ğŸ“¦ å¯å½’æ¡£"

                    output.append(f"| {date} | {title} | {filename} | {word_count} | {suggestion} |")

                output.append("")

        return "\n".join(output)

    def run(self):
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        self.scan_gridea_articles()
        self.scan_jekyll_articles()
        self.generate_report()

        # ç”ŸæˆMarkdownç™»è®°è¡¨
        markdown = self.generate_markdown_registry()

        output_file = self.project_root / "_drafts" / "todos" / "COMPLETE-ARTICLES-REGISTRY.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown)

        print(f"\nğŸ“„ å®Œæ•´ç™»è®°è¡¨å·²ä¿å­˜åˆ°: {output_file}\n")


def main():
    analyzer = ArticleAnalyzer()
    analyzer.run()


if __name__ == "__main__":
    main()
