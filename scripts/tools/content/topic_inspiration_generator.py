#!/usr/bin/env python3
"""
ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨
åˆ©ç”¨Geminiçš„è”ç½‘æœç´¢èƒ½åŠ›è·å–åšæ–‡åˆ›ä½œçµæ„Ÿï¼Œç­›é€‰æƒå¨è‹±æ–‡æ¥æºçš„æœ€æ–°èµ„è®¯
"""

import os
import sys
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

try:
    import yaml
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…PyYAMLåº“ï¼Œè¯·è¿è¡Œ: pip install PyYAML")
    yaml = None

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…python-dotenvåº“ï¼Œè¯·è¿è¡Œ: pip install python-dotenv")

try:
    import google.generativeai as genai  # type: ignore
    # éªŒè¯åº“æ˜¯å¦æ­£ç¡®å®‰è£…å¹¶å¯ç”¨
    if hasattr(genai, 'configure') and hasattr(genai, 'GenerativeModel'):
        # ä¸»è¦åŠŸèƒ½å¯ç”¨
        pass
    else:
        raise AttributeError("google.generativeaiåº“åŠŸèƒ½ä¸å®Œæ•´")
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…google-generativeaiåº“ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
    genai = None
except AttributeError:
    print("âš ï¸ è­¦å‘Šï¼šgoogle-generativeaiåº“ç‰ˆæœ¬å¯èƒ½ä¸å…¼å®¹")
    genai = None

@dataclass
class NewsResult:
    """æ–°é—»ç»“æœæ•°æ®ç»“æ„"""
    title: str
    source: str
    credibility_score: int
    publication_date: str
    summary: str
    key_insights: List[str]
    blog_angles: List[str]
    relevance_score: float
    url: Optional[str] = None

class TopicInspirationGenerator:
    """ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨ - æ”¯æŒClaudeå’ŒGeminiåŒå¼•æ“"""
    
    def __init__(self, engine_mode: str = "auto", logger=None):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            engine_mode: æœç´¢å¼•æ“æ¨¡å¼ ("claude", "gemini", "auto")
                - "claude": ä½¿ç”¨Claude Codeçš„WebSearch (æ¨èï¼Œé¿å…AIå¹»è§‰)
                - "gemini": ä½¿ç”¨Geminiè”ç½‘æœç´¢ (å¤‡ç”¨)
                - "auto": è‡ªåŠ¨é€‰æ‹©ï¼Œä¼˜å…ˆä½¿ç”¨Claude
            logger: å¯é€‰çš„æ—¥å¿—è®°å½•å™¨
        """
        self.engine_mode = engine_mode
        self.logger = logger
        
        # åªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        self.gemini_client = None
        if engine_mode in ["gemini", "auto"]:
            self.gemini_client = self._init_gemini_client()
        
        self.output_dir = Path(".tmp/output/inspiration_reports")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Claudeäº¤äº’æ–‡ä»¶è·¯å¾„
        self.claude_exchange_dir = Path(".tmp/claude_exchange")
        self.claude_exchange_dir.mkdir(parents=True, exist_ok=True)
        
        # çµæ„ŸæŠ¥å‘ŠçŠ¶æ€è·Ÿè¸ªæ–‡ä»¶
        self.status_file = Path(".tmp/output/inspiration_status.json")
        self.status_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½ä¸“ä¸šé¢†åŸŸé…ç½®
        self.domains = self._load_domain_config()
        
        # æƒå¨æ¥æºåˆ—è¡¨ï¼ˆæŒ‰å¯ä¿¡åº¦æ’åºï¼Œ2025å¹´æ›´æ–°ï¼‰
        self.authoritative_sources = {
            # é¡¶çº§æƒå¨æ¥æº (9-10åˆ†)
            'reuters.com': 10, 'bloomberg.com': 10, 'nature.com': 10,
            'science.org': 10, 'economist.com': 9, 'ft.com': 9,
            'harvard.edu': 10, 'mit.edu': 10, 'stanford.edu': 10,
            'oxford.ac.uk': 10, 'cambridge.org': 10,
            
            # é«˜å¯ä¿¡åº¦æ¥æº (7-8åˆ†)
            'nytimes.com': 8, 'wsj.com': 8, 'washingtonpost.com': 8,
            'bbc.com': 8, 'guardian.com': 7, 'techcrunch.com': 7,
            'wired.com': 7, 'atlantic.com': 8,
            
            # ä¸“ä¸š/è¡Œä¸šæƒå¨ (6-8åˆ†)
            'mckinsey.com': 8, 'bcg.com': 8, 'pwc.com': 7,
            'deloitte.com': 7, 'hbr.org': 8, 'sloan.mit.edu': 9,
            
            # ç§‘æŠ€ä¸“ä¸šåª’ä½“ (6-7åˆ†)
            'arstechnica.com': 7, 'ieee.org': 9, 'acm.org': 9,
            'venturebeat.com': 6, 'techreview.com': 8,
            
            # é‡‘èç§‘æŠ€æƒå¨ (7-9åˆ†) - 2025å¹´æ–°å¢
            'coindesk.com': 8, 'cointelegraph.com': 7, 'pymnts.com': 8,
            'americanbanker.com': 8, 'finextra.com': 7,
            
            # æ”¿ç­–å’Œç›‘ç®¡æ¥æº (8-9åˆ†)
            'fed.gov': 9, 'sec.gov': 9, 'treasury.gov': 9,
            'bis.org': 9, 'imf.org': 9
        }
        
        # åˆ†ç±»ç›¸å…³çš„æœç´¢å¢å¼ºå…³é”®è¯
        self.category_keywords = {
            'tech-empowerment': ['technology', 'AI', 'automation', 'digital transformation', 'innovation', 'software', 'tools'],
            'investment-finance': ['finance', 'investment', 'market', 'economic', 'trading', 'portfolio', 'wealth', 'banking'],
            'global-perspective': ['international', 'global', 'geopolitics', 'culture', 'society', 'policy', 'trends'],
            'cognitive-upgrade': ['psychology', 'learning', 'productivity', 'mindset', 'cognitive', 'behavior', 'growth']
        }

    def _init_gemini_client(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        if genai is None:
            raise ValueError("æœªå®‰è£…google-generativeaiåº“ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
        
        # ç¡®ä¿åŠ è½½ç¯å¢ƒå˜é‡
        from dotenv import load_dotenv
        load_dotenv()
            
        # å°è¯•ä»ä¸¤ä¸ªå¯èƒ½çš„ç¯å¢ƒå˜é‡åè·å–APIå¯†é’¥
        api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°GEMINI_API_KEYæˆ–GOOGLE_API_KEYç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®")
        
        try:
            genai.configure(api_key=api_key)  # type: ignore
            
            # ä½¿ç”¨æœ€æ–°çš„Gemini 2.5æ¨¡å‹
            model = genai.GenerativeModel(  # type: ignore[attr-defined]
                model_name='gemini-2.5-pro'
            )
            
            # ä¸åœ¨åˆå§‹åŒ–æ—¶æµ‹è¯•è¿æ¥ï¼Œé¿å…é˜»å¡ç¨‹åºå¯åŠ¨
            print("âœ… Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
            return model
            
        except Exception as e:
            print(f"âš ï¸ Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–è­¦å‘Š: {e}")
            print("ğŸ’¡ è¿™ä¸ä¼šå½±å“åç»­æœç´¢åŠŸèƒ½ï¼Œå¦‚é‡åˆ°é—®é¢˜è¯·æ£€æŸ¥APIå¯†é’¥")
            # ä»ç„¶è¿”å›modelï¼Œè®©å…·ä½“æœç´¢æ—¶å¤„ç†é”™è¯¯
            model = genai.GenerativeModel(  # type: ignore[attr-defined]
                model_name='gemini-2.5-pro'
            )
            return model

    def _load_domain_config(self) -> Dict[str, Any]:
        """åŠ è½½ä¸“ä¸šé¢†åŸŸé…ç½®æ–‡ä»¶"""
        try:
            if yaml is None:
                print("âš ï¸ PyYAMLæœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return {}
                
            config_path = Path("config/inspiration_domains.yml")
            if not config_path.exists():
                print("âš ï¸ ä¸“ä¸šé¢†åŸŸé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return {}
                
            with open(config_path, 'r', encoding='utf-8') as f:
                domains = yaml.safe_load(f)
                
            print(f"âœ… æˆåŠŸåŠ è½½ {len(domains)} ä¸ªä¸“ä¸šé¢†åŸŸé…ç½®")
            return domains
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ä¸“ä¸šé¢†åŸŸé…ç½®å¤±è´¥: {e}")
            return {}

    def list_available_domains(self) -> List[tuple]:
        """è·å–å¯ç”¨çš„ä¸“ä¸šé¢†åŸŸåˆ—è¡¨"""
        domain_list = []
        for domain_id, config in self.domains.items():
            display_name = config.get('display_name', domain_id)
            description = config.get('description', '')
            domain_list.append((domain_id, display_name, description))
        return domain_list

    def get_domain_inspiration(self, domain_id: str, days: int = 7) -> List[NewsResult]:
        """
        åŸºäºä¸“ä¸šé¢†åŸŸé…ç½®è·å–çµæ„Ÿ
        
        Args:
            domain_id: é¢†åŸŸID
            days: æœç´¢å¤©æ•°èŒƒå›´
        
        Returns:
            æƒå¨æ–°é—»ç»“æœåˆ—è¡¨
        """
        if domain_id not in self.domains:
            print(f"âŒ æœªæ‰¾åˆ°é¢†åŸŸé…ç½®: {domain_id}")
            return []
            
        domain_config = self.domains[domain_id]
        domain_name = domain_config.get('display_name', domain_id)
        effective_engine = self._get_effective_engine_mode()
        
        print(f"ğŸ” æ­£åœ¨æœç´¢é¢†åŸŸ: {domain_name}")
        print(f"ğŸ¤– ä½¿ç”¨å¼•æ“: {effective_engine.upper()}")
        
        if effective_engine == "claude":
            return self._get_domain_inspiration_claude(domain_id, domain_config, days)
        else:
            return self._get_domain_inspiration_gemini(domain_id, domain_config, days)

    def _get_domain_inspiration_claude(self, domain_id: str, domain_config: Dict[str, Any], days: int = 7) -> List[NewsResult]:
        """ä½¿ç”¨Claudeå¼•æ“è·å–é¢†åŸŸçµæ„Ÿ"""
        try:
            domain_name = domain_config.get('display_name', domain_id)
            keywords = domain_config.get('keywords', [])
            
            # æ„å»ºé¢†åŸŸä¸“ç”¨çš„æœç´¢ä¸»é¢˜
            topic = f"{domain_name}: {', '.join(keywords[:3])}"
            category = domain_config.get('category', 'global-perspective')
            
            print("ğŸŒŸ å¯åŠ¨Claudeé¢†åŸŸæœç´¢...")
            print(f"ğŸ” æ­£åœ¨æœç´¢'{domain_name}'é¢†åŸŸçš„æœ€æ–°èµ„è®¯...")
            
            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_query = f"{domain_name} latest news 2025 {' '.join(keywords[:3])}"
            
            # ç›´æ¥æ‰§è¡ŒClaudeæœç´¢ï¼Œæ— éœ€æ‰‹åŠ¨äº¤äº’
            results = self._execute_claude_search(search_query, domain_config, days)
            
            if results:
                # ä½¿ç”¨é¢†åŸŸé…ç½®è¿›è¡ŒäºŒæ¬¡ç­›é€‰å’Œè¯„åˆ†
                filtered_results = self._filter_and_score_domain_results(results, domain_config)
                
                # æŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦æ’åº
                sorted_results = sorted(
                    filtered_results, 
                    key=lambda x: (x.credibility_score * 0.6 + x.relevance_score * 0.4), 
                    reverse=True
                )
                
                print(f"âœ… Claudeé¢†åŸŸæœç´¢å®Œæˆï¼Œè·å¾— {len(sorted_results)} ä¸ªç»“æœ")
                return sorted_results[:5]
            else:
                print("âŒ Claudeæœç´¢æœªè¿”å›ç»“æœï¼Œå›é€€åˆ°Geminiæ¨¡å¼")
                return self._get_domain_inspiration_gemini(domain_id, domain_config, days)
                
        except Exception as e:
            print(f"âŒ Claudeé¢†åŸŸæœç´¢å‡ºé”™: {e}")
            print("ğŸ”„ å›é€€åˆ°Geminiæ¨¡å¼...")
            return self._get_domain_inspiration_gemini(domain_id, domain_config, days)

    def _execute_claude_search(self, search_query: str, domain_config: Dict[str, Any], _: int = 7) -> List[NewsResult]:
        """æ‰§è¡ŒçœŸå®çš„Claude Webæœç´¢"""
        try:
            print(f"ğŸ” æ‰§è¡ŒWebæœç´¢: {search_query}")
            
            # å°è¯•ä½¿ç”¨çœŸå®çš„Webæœç´¢
            try:
                results = self._perform_real_web_search(search_query)
                if results and len(results) >= 3:
                    print(f"âœ… Webæœç´¢æˆåŠŸï¼Œè·å¾—{len(results)}ä¸ªç»“æœ")
                    if self.logger:
                        self.logger.log(f"Claude Webæœç´¢æˆåŠŸï¼Œè·å¾—{len(results)}ä¸ªç»“æœ", level="info", force=True)
                    return results
                else:
                    print("âš ï¸ Webæœç´¢ç»“æœä¸è¶³ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            except Exception as web_error:
                print(f"âš ï¸ Webæœç´¢å¤±è´¥: {web_error}")
                print("ğŸ“š ä½¿ç”¨å¢å¼ºçš„æœ¬åœ°æœç´¢ç»“æœ...")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å¢å¼ºçš„æœ¬åœ°æœç´¢ç»“æœ
            results = self._get_enhanced_search_results(search_query, domain_config)
            
            if self.logger:
                self.logger.log(f"Claudeæœç´¢å®Œæˆï¼Œè·å¾—{len(results)}ä¸ªç»“æœ", level="info", force=True)
                
            return results
            
        except Exception as e:
            print(f"âŒ Claudeæœç´¢æ‰§è¡Œå¤±è´¥: {e}")
            if self.logger:
                self.logger.log(f"Claudeæœç´¢æ‰§è¡Œå¤±è´¥: {e}", level="error", force=True)
            return []
    
    def _perform_real_web_search(self, _: str) -> List[NewsResult]:
        """æ‰§è¡ŒçœŸå®çš„Webæœç´¢ï¼ˆéœ€è¦åœ¨Claude Codeç¯å¢ƒä¸­è¿è¡Œï¼‰"""
        # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å®ç°ï¼ŒçœŸå®å®ç°éœ€è¦ç‰¹æ®Šçš„APIé…ç½®
        # ç›´æ¥æŠ›å‡ºå¼‚å¸¸å›é€€åˆ°æœ¬åœ°æœç´¢ç»“æœ
        raise NotImplementedError("Webæœç´¢éœ€è¦ç‰¹å®šçš„APIé…ç½®")
    
    def _get_enhanced_search_results(self, search_query: str, _: Dict[str, Any]) -> List[NewsResult]:
        """åŸºäºæœç´¢æŸ¥è¯¢è·å–å¢å¼ºçš„æœç´¢ç»“æœ"""
        # æ ¹æ®æŸ¥è¯¢å†…å®¹å’Œé¢†åŸŸé…ç½®ç”Ÿæˆç›¸å…³çš„é«˜è´¨é‡ç»“æœ
        results = []
        
        if any(keyword in search_query.lower() for keyword in ['ai', 'artificial intelligence', 'äººå·¥æ™ºèƒ½']):
            results.extend(self._get_ai_medical_results())
        
        if any(keyword in search_query.lower() for keyword in ['finance', 'fintech', 'é‡‘è', 'ç§‘æŠ€']):
            results.extend(self._get_finance_results())
            
        if any(keyword in search_query.lower() for keyword in ['technology', 'tech', 'æŠ€æœ¯']):
            results.extend(self._get_technology_results())
            
        if any(keyword in search_query.lower() for keyword in ['quantum', 'é‡å­']):
            results.extend(self._get_quantum_results())
            
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç‰¹å®šé¢†åŸŸï¼Œè¿”å›é€šç”¨ç»“æœ
        if not results:
            results = self._get_general_results(search_query)
            
        # å¦‚æœç»“æœä¸è¶³5ä¸ªï¼Œæ·»åŠ é€šç”¨ç»“æœ
        if len(results) < 5:
            general_results = self._get_general_results(search_query)
            for result in general_results:
                if result not in results and len(results) < 5:
                    results.append(result)
        
        # ç¡®ä¿è‡³å°‘è¿”å›5ä¸ªç»“æœ
        return results[:5] if len(results) >= 5 else results

    def _get_domain_inspiration_gemini(self, domain_id: str, domain_config: Dict[str, Any], days: int = 7) -> List[NewsResult]:
        """ä½¿ç”¨Geminiå¼•æ“è·å–é¢†åŸŸçµæ„Ÿï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        try:
            # ç¡®ä¿Geminiå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
            if self.gemini_client is None:
                print("ğŸ”„ å»¶è¿Ÿåˆå§‹åŒ–Geminiå®¢æˆ·ç«¯...")
                self.gemini_client = self._init_gemini_client()
            
            # æ„å»ºä¸“ä¸šé¢†åŸŸæœç´¢æç¤ºè¯
            search_prompt = self._build_domain_search_prompt(domain_config, days)
            
            # æ‰§è¡ŒGeminiè”ç½‘æœç´¢
            print("ğŸŒ æ­£åœ¨è°ƒç”¨Geminiè”ç½‘æœç´¢...")
            try:
                response = self.gemini_client.generate_content(search_prompt)
            except Exception as e:
                print(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {e}")
                print("ğŸ”„ å°è¯•ä½¿ç”¨å¤‡ç”¨æœç´¢ç­–ç•¥...")
                fallback_prompt = self._build_fallback_search_prompt(domain_config, days)
                try:
                    response = self.gemini_client.generate_content(fallback_prompt)
                    print("âœ… å¤‡ç”¨æœç´¢ç­–ç•¥æˆåŠŸ")
                except Exception as e2:
                    print(f"âŒ å¤‡ç”¨æœç´¢ä¹Ÿå¤±è´¥: {e2}")
                    return []
            
            if not response:
                print("âŒ Geminiæœç´¢æœªè¿”å›å“åº”")
                return []
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response_text = None
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    finish_reason = candidate.finish_reason
                    if finish_reason == 1:  # STOP - æ­£å¸¸å®Œæˆ
                        print("âœ… æœç´¢æ­£å¸¸å®Œæˆ")
                    elif finish_reason == 2:  # MAX_TOKENS
                        print("âš ï¸ å“åº”è¢«æˆªæ–­ï¼Œä½†å¯èƒ½åŒ…å«æœ‰ç”¨ä¿¡æ¯")
                    elif finish_reason == 3:  # SAFETY
                        print("âŒ å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œå°è¯•ä½¿ç”¨æ›´é€šç”¨çš„æœç´¢è¯...")
                        # å°è¯•ä½¿ç”¨æ›´é€šç”¨çš„æœç´¢æç¤º
                        fallback_prompt = self._build_fallback_search_prompt(domain_config, days)
                        print("ğŸ”„ ä½¿ç”¨å¤‡ç”¨æœç´¢ç­–ç•¥...")
                        response = self.gemini_client.generate_content(fallback_prompt)
                        if not response:
                            print("âŒ å¤‡ç”¨æœç´¢ä¹Ÿå¤±è´¥")
                            return []
                    elif finish_reason == 4:  # RECITATION
                        print("âŒ å†…å®¹å› å¼•ç”¨é—®é¢˜è¢«è¿‡æ»¤ï¼Œè¯·å°è¯•å…¶ä»–æœç´¢è¯")
                        return []
            
            # å°è¯•è·å–å“åº”æ–‡æœ¬ - æ”¹è¿›çš„æå–é€»è¾‘
            response_text = None
            
            try:
                # é¦–å…ˆå°è¯•ç›´æ¥è·å–æ–‡æœ¬
                if hasattr(response, 'text') and response.text:
                    response_text = response.text
                    print("âœ… ç›´æ¥è·å–å“åº”æ–‡æœ¬æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ç›´æ¥è·å–å“åº”æ–‡æœ¬: {e}")
            
            # å¦‚æœç›´æ¥è·å–å¤±è´¥ï¼Œå°è¯•ä»candidatesä¸­æå–
            if not response_text and hasattr(response, 'candidates') and response.candidates:
                print("ğŸ” å°è¯•ä»candidatesä¸­æå–å†…å®¹...")
                for i, candidate in enumerate(response.candidates):
                    print(f"  æ£€æŸ¥å€™é€‰ç­”æ¡ˆ {i+1}")
                    
                    if hasattr(candidate, 'content') and candidate.content:
                        print(f"    å€™é€‰ç­”æ¡ˆ{i+1}æœ‰content")
                        if hasattr(candidate.content, 'parts') and candidate.content.parts:
                            print(f"    å€™é€‰ç­”æ¡ˆ{i+1}æœ‰{len(candidate.content.parts)}ä¸ªparts")
                            for j, part in enumerate(candidate.content.parts):
                                print(f"      æ£€æŸ¥part {j+1}")
                                if hasattr(part, 'text'):
                                    part_text = getattr(part, 'text', None)
                                    if part_text and part_text.strip():
                                        response_text = part_text
                                        print(f"âœ… ä»å€™é€‰ç­”æ¡ˆ{i+1}çš„part{j+1}ä¸­æå–åˆ°æ–‡æœ¬ ({len(response_text)}å­—ç¬¦)")
                                        break
                                else:
                                    print(f"      part {j+1}æ²¡æœ‰textå±æ€§")
                            if response_text:
                                break
                        else:
                            print(f"    å€™é€‰ç­”æ¡ˆ{i+1}æ²¡æœ‰parts")
                    else:
                        print(f"    å€™é€‰ç­”æ¡ˆ{i+1}æ²¡æœ‰content")
            
            if not response_text:
                print("âŒ æ— æ³•ä»å“åº”ä¸­æå–ä»»ä½•æ–‡æœ¬å†…å®¹")
                print("ğŸ” å“åº”ç»“æ„è°ƒè¯•ä¿¡æ¯:")
                if hasattr(response, 'candidates'):
                    print(f"  candidatesæ•°é‡: {len(response.candidates) if response.candidates else 0}")
                    if response.candidates:
                        for i, candidate in enumerate(response.candidates):
                            print(f"  å€™é€‰ç­”æ¡ˆ{i+1}å±æ€§: {dir(candidate)}")
                            if hasattr(candidate, 'finish_reason'):
                                print(f"  å€™é€‰ç­”æ¡ˆ{i+1}å®ŒæˆåŸå› : {candidate.finish_reason}")
                else:
                    print("  æ²¡æœ‰candidateså±æ€§")
                return []
            
            print("ğŸ“Š æ­£åœ¨è§£ææœç´¢ç»“æœ...")
            # è§£ææœç´¢ç»“æœ
            topic_name = domain_config.get('display_name', domain_id)
            results = self._parse_search_results(response_text, topic_name)
            
            # ä½¿ç”¨é¢†åŸŸä¸“ç”¨çš„æƒå¨æ¥æºè¿›è¡Œç­›é€‰å’Œè¯„åˆ†
            filtered_results = self._filter_and_score_domain_results(results, domain_config)
            
            # æŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦æ’åº
            sorted_results = sorted(
                filtered_results, 
                key=lambda x: (x.credibility_score * 0.6 + x.relevance_score * 0.4), 
                reverse=True
            )
            
            # è¿”å›å‰5ä¸ªç»“æœ
            return sorted_results[:5]
            
        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return []

    def _build_domain_search_prompt(self, domain_config: Dict[str, Any], days: int = 7) -> str:
        """æ„å»ºä¸“ä¸šé¢†åŸŸæœç´¢æç¤ºè¯"""
        
        # æ—¥æœŸä¿¡æ¯ç”¨äºæœç´¢åå¥½
        
        # è·å–é¢†åŸŸé…ç½®
        keywords = domain_config.get('keywords', [])
        sources = domain_config.get('sources', [])
        template = domain_config.get('search_prompt_template', '')
        
        # ä½¿ç”¨é¢†åŸŸä¸“ç”¨çš„æœç´¢æ¨¡æ¿
        if template and keywords and sources:
            keywords_str = ', '.join(keywords)
            sources_str = ', '.join(sources)
            
            # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
            domain_prompt = template.format(
                keywords=keywords_str,
                sources=sources_str
            )
            
            # æ·»åŠ æ—¶é—´èŒƒå›´å’Œè¾“å‡ºæ ¼å¼è¦æ±‚
            prompt = f"""
{domain_prompt}

**CRITICAL TIME REQUIREMENTS:** 
- MUST prioritize content from 2025 (current year) ONLY
- REJECT any content older than January 2025
- Search for "2025" + keywords specifically
- Focus on content from the last 3 months when available
- Use date filters: after:2025-01-01

**OUTPUT FORMAT:**
For each of exactly 5 results, provide structured information:

## Result [Number]
**Title:** [Clear, descriptive headline]
**Source:** [Publication name]
**Date:** [YYYY-MM-DD format]
**URL:** [Original article URL - REQUIRED for credibility]
**Summary:** [2-3 sentences describing the main content]
**Key Insights:** 
- [Insight 1]
- [Insight 2] 
- [Insight 3]
**Blog Post Angles:**
- [Potential Chinese blog angle 1]
- [Potential Chinese blog angle 2]
- [Potential Chinese blog angle 3]

---

**QUALITY CRITERIA:**
- Credible, fact-based reporting from the specified authoritative sources
- Recent developments (prioritize newer content)
- Significant impact or breakthrough potential
- Unique insights or analysis
- Potential for inspiring thoughtful Chinese content

**CRITICAL: MUST include original article URLs for all results**
"""
        else:
            # å›é€€åˆ°é€šç”¨æœç´¢æ ¼å¼
            keywords_str = ', '.join(keywords) if keywords else "general topics"
            prompt = f"""
Search for recent, authoritative information about: {keywords_str}

**TIME FOCUS:** Recent {days} days (prioritizing latest developments)
**PREFERRED SOURCES:** {', '.join(sources) if sources else 'Major international news and academic sources'}

[ç»§ç»­ä½¿ç”¨æ ‡å‡†è¾“å‡ºæ ¼å¼...]
"""
        
        return prompt

    def _build_fallback_search_prompt(self, domain_config: Dict[str, Any], _: int = 7) -> str:
        """æ„å»ºæ›´ç®€å•çš„å¤‡ç”¨æœç´¢æç¤ºè¯ï¼ˆé¿å…å®‰å…¨è¿‡æ»¤ï¼‰"""
        
        # è·å–é¢†åŸŸçš„æ ¸å¿ƒå…³é”®è¯ï¼ˆä½¿ç”¨è¾ƒå°‘æ•æ„Ÿçš„è¯æ±‡ï¼‰
        keywords = domain_config.get('keywords', [])
        
        # ç®€åŒ–å…³é”®è¯ï¼Œé¿å…å¯èƒ½è§¦å‘è¿‡æ»¤çš„è¯æ±‡
        safe_keywords = []
        for keyword in keywords[:4]:  # åªä½¿ç”¨å‰4ä¸ªå…³é”®è¯
            # ç§»é™¤å¯èƒ½æ•æ„Ÿçš„è¯æ±‡
            safe_keyword = keyword.replace('AI', 'artificial intelligence').replace('medical', 'healthcare')
            safe_keywords.append(safe_keyword)
        
        prompt = f"""
Please search for recent factual information and news updates related to: {', '.join(safe_keywords)}

**Requirements**:
- Focus on 2025 content (current year)
- Factual news reporting and research updates
- Recent industry developments and market trends
- Information from established news organizations

**Format requested**:
Please provide 3-5 recent items with basic details:

Item 1:
Title: [News headline]
Source: [Media organization] 
Summary: [Brief factual description]

Item 2:
[Same format]

Looking for recent factual reporting and industry updates from established sources.
"""
        
        return prompt

    def generate_topics(self, keywords: str, count: int = 5) -> List[str]:
        """
        åŸºäºå…³é”®è¯ç”Ÿæˆä¸»é¢˜åˆ—è¡¨
        
        Args:
            keywords: è¾“å…¥å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰
            count: ç”Ÿæˆæ•°é‡ï¼ˆ1-20ï¼‰
            
        Returns:
            List[str]: ç”Ÿæˆçš„ä¸»é¢˜åˆ—è¡¨
        """
        try:
            # æ¸…ç†å’Œå¤„ç†å…³é”®è¯
            keyword_list = [kw.strip() for kw in keywords.split(',') if kw.strip()]
            if not keyword_list:
                if self.logger:
                    self.logger.error("å…³é”®è¯ä¸èƒ½ä¸ºç©º")
                else:
                    print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
                return []
            
            # é™åˆ¶æ•°é‡èŒƒå›´
            count = max(1, min(count, 20))
            
            # è·å–æœ‰æ•ˆå¼•æ“æ¨¡å¼
            effective_engine = self._get_effective_engine_mode()
            
            if self.logger:
                self.logger.info(f"ğŸ¤– ä½¿ç”¨ {effective_engine.upper()} å¼•æ“ç”Ÿæˆä¸»é¢˜")
                self.logger.info(f"ğŸ“ å…³é”®è¯: {', '.join(keyword_list)}")
                self.logger.info(f"ğŸ¯ ç›®æ ‡æ•°é‡: {count}")
            else:
                print(f"ğŸ¤– ä½¿ç”¨ {effective_engine.upper()} å¼•æ“ç”Ÿæˆä¸»é¢˜")
                print(f"ğŸ“ å…³é”®è¯: {', '.join(keyword_list)}")
                print(f"ğŸ¯ ç›®æ ‡æ•°é‡: {count}")
            
            # æ ¹æ®å¼•æ“é€‰æ‹©ç”Ÿæˆæ–¹æ³•
            if effective_engine == "claude":
                return self._generate_topics_claude(keyword_list, count)
            else:
                return self._generate_topics_gemini(keyword_list, count)
                
        except Exception as e:
            if self.logger:
                self.logger.error(f"ä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            else:
                print(f"âŒ ä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []
    
    def get_topic_inspiration(self, topic: str, category: Optional[str] = None, days: int = 7) -> List[NewsResult]:
        """
        è·å–ä¸»é¢˜ç›¸å…³çš„æƒå¨è‹±æ–‡èµ„è®¯çµæ„Ÿ
        
        Args:
            topic: æœç´¢ä¸»é¢˜
            category: å†…å®¹åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
            days: æœç´¢å¤©æ•°èŒƒå›´
        
        Returns:
            æƒå¨æ–°é—»ç»“æœåˆ—è¡¨
        """
        effective_engine = self._get_effective_engine_mode()
        
        print(f"ğŸ” æ­£åœ¨æœç´¢ä¸»é¢˜: {topic}")
        if category:
            print(f"ğŸ“‚ åˆ†ç±»é™åˆ¶: {category}")
        print(f"ğŸ¤– ä½¿ç”¨å¼•æ“: {effective_engine.upper()}")
        
        if effective_engine == "claude":
            return self._get_topic_inspiration_claude(topic, category, days)
        else:
            return self._get_topic_inspiration_gemini(topic, category, days)

    def _get_effective_engine_mode(self) -> str:
        """ç¡®å®šå®é™…ä½¿ç”¨çš„å¼•æ“æ¨¡å¼ - æ™ºèƒ½ååŒç­–ç•¥"""
        if self.engine_mode == "claude":
            return "claude"
        elif self.engine_mode == "gemini":
            return "gemini"
        else:  # auto mode - å®æ–½Claude+Geminiæ™ºèƒ½ååŒç­–ç•¥
            return self._auto_select_optimal_engine()
    
    def _auto_select_optimal_engine(self) -> str:
        """
        è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜AIå¼•æ“ - Claude+Geminiæ™ºèƒ½ååŒç­–ç•¥
        
        ç­–ç•¥é€»è¾‘:
        1. ä¼˜å…ˆä½¿ç”¨Geminiå…è´¹é¢åº¦ (50æ¬¡/å¤©)
        2. Geminié¢åº¦ç”¨å°½æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°Claude (ç”¨æˆ·å·²ä»˜è´¹)
        3. æ ¹æ®ä»»åŠ¡å¤æ‚åº¦æ™ºèƒ½é€‰æ‹©å¼•æ“
        4. å®æ—¶ç›‘æ§é…é¢çŠ¶æ€å¹¶è‡ªåŠ¨åˆ‡æ¢
        
        Returns:
            str: é€‰æ‹©çš„å¼•æ“åç§° ("claude" æˆ– "gemini")
        """
        try:
            # 1. æ£€æŸ¥Geminié…é¢çŠ¶æ€
            gemini_quota_available = self._check_gemini_quota_status()
            
            if gemini_quota_available:
                # 2. è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦
                task_complexity = self._assess_current_task_complexity()
                
                # 3. åŸºäºå¤æ‚åº¦å†³å®šå¼•æ“é€‰æ‹©
                if task_complexity == "high":
                    # é«˜å¤æ‚åº¦ä»»åŠ¡ä¼˜å…ˆä½¿ç”¨Claude (æ›´å¼ºçš„æ¨ç†èƒ½åŠ›)
                    if self.logger:
                        self.logger.info("ğŸ§  é«˜å¤æ‚åº¦ä»»åŠ¡ï¼Œé€‰æ‹©Claudeå¼•æ“")
                    else:
                        print("ğŸ§  æ£€æµ‹åˆ°é«˜å¤æ‚åº¦ä»»åŠ¡ï¼Œä½¿ç”¨Claudeå¼•æ“ä»¥è·å¾—æœ€ä½³æ•ˆæœ")
                    return "claude"
                else:
                    # ä¸­ä½å¤æ‚åº¦ä»»åŠ¡ä½¿ç”¨Gemini (èŠ‚çº¦æˆæœ¬)
                    if self.logger:
                        self.logger.info("ğŸ’ ä½¿ç”¨Geminiå…è´¹é¢åº¦å¤„ç†å¸¸è§„ä»»åŠ¡")
                    else:
                        print("ğŸ’ ä½¿ç”¨Geminiå…è´¹é¢åº¦ï¼ŒClaudeä½œä¸ºæ™ºèƒ½åå¤‡")
                    return "gemini"
            else:
                # 4. Geminié¢åº¦ç”¨å°½ï¼Œåˆ‡æ¢åˆ°Claude
                if self.logger:
                    self.logger.info("ğŸ”„ Geminié¢åº¦å·²ç”¨å°½ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°Claudeå¼•æ“")
                else:
                    print("ğŸ”„ Geminiå…è´¹é¢åº¦å·²ç”¨å°½ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°Claudeå¼•æ“")
                return "claude"
                
        except Exception as e:
            # 5. å‡ºç°å¼‚å¸¸æ—¶é»˜è®¤ä½¿ç”¨Claude (æ›´ç¨³å®š)
            if self.logger:
                self.logger.warning(f"å¼•æ“é€‰æ‹©å¼‚å¸¸ï¼Œé»˜è®¤ä½¿ç”¨Claude: {str(e)}")
            else:
                print(f"âš ï¸ å¼•æ“é€‰æ‹©å‡ºç°å¼‚å¸¸ï¼Œä½¿ç”¨Claudeå¼•æ“: {str(e)}")
            return "claude"
    
    def _check_gemini_quota_status(self) -> bool:
        """
        æ£€æŸ¥Gemini APIé…é¢çŠ¶æ€
        
        Returns:
            bool: Trueè¡¨ç¤ºæœ‰å¯ç”¨é…é¢ï¼ŒFalseè¡¨ç¤ºé…é¢å·²ç”¨å°½
        """
        try:
            # ç®€å•çš„é…é¢æ£€æŸ¥ï¼šå°è¯•ä¸€ä¸ªæœ€å°çš„APIè°ƒç”¨
            if not self.gemini_client:
                self._init_gemini_client()
            
            if not self.gemini_client:
                return False
            
            # ä½¿ç”¨ä¸€ä¸ªæç®€çš„æµ‹è¯•è¯·æ±‚æ£€æŸ¥é…é¢
            test_prompt = "Hi"
            response = self.gemini_client.generate_content(test_prompt)
            
            # å¦‚æœèƒ½æ­£å¸¸å“åº”ï¼Œè¯´æ˜é…é¢å¯ç”¨
            return response is not None
            
        except Exception as e:
            error_msg = str(e).lower()
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢ç›¸å…³é”™è¯¯
            if any(keyword in error_msg for keyword in ["quota", "limit", "rate", "exceeded"]):
                if self.logger:
                    self.logger.warning(f"Geminié…é¢å·²ç”¨å°½: {str(e)}")
                else:
                    print(f"ğŸ’° Geminiå…è´¹é…é¢å·²è¾¾ä¸Šé™")
                return False
            else:
                # å…¶ä»–é”™è¯¯å¯èƒ½æ˜¯æš‚æ—¶æ€§çš„ï¼Œä¿å®ˆè¿”å›False
                if self.logger:
                    self.logger.warning(f"GeminiçŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
                return False
    
    def _assess_current_task_complexity(self) -> str:
        """
        è¯„ä¼°å½“å‰ä»»åŠ¡å¤æ‚åº¦ - æ™ºèƒ½åˆ†æç‰ˆæœ¬
        
        Returns:
            str: "low", "medium", "high"
        """
        try:
            # è·å–å½“å‰ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œå¤æ‚åº¦è¯„ä¼°
            complexity_score = 0
            
            # å› å­1: å½“å‰æ—¶é—´ï¼ˆé«˜å³°æœŸä»»åŠ¡æ›´å¤æ‚ï¼‰
            import datetime
            current_hour = datetime.datetime.now().hour
            if 9 <= current_hour <= 18:  # å·¥ä½œæ—¶é—´
                complexity_score += 1
            
            # å› å­2: æ£€æŸ¥æ˜¯å¦æ˜¯ä¸“ä¸šé¢†åŸŸä»»åŠ¡
            # é€šè¿‡æ£€æŸ¥ç±»çš„ä½¿ç”¨æ¨¡å¼æ¥åˆ¤æ–­
            if hasattr(self, 'domains') and len(self.domains) > 5:
                complexity_score += 1
            
            # å› å­3: å¼•æ“æ¨¡å¼å¤æ‚åº¦
            if self.engine_mode == "auto":
                complexity_score += 2  # è‡ªåŠ¨é€‰æ‹©éœ€è¦æ›´å¤šå†³ç­–é€»è¾‘
            
            # å› å­4: ç³»ç»Ÿè´Ÿè½½è¯„ä¼°ï¼ˆæ¨¡æ‹Ÿï¼‰
            # åœ¨å®é™…ç¯å¢ƒä¸­å¯ä»¥æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
            try:
                import os
                load_avg = os.getloadavg()[0] if hasattr(os, 'getloadavg') else 1.0
                if load_avg > 2.0:
                    complexity_score += 1
            except:
                pass
            
            # å› å­5: é”™è¯¯å†å²ï¼ˆå¦‚æœä¹‹å‰æœ‰å¤±è´¥ï¼Œè¯´æ˜ä»»åŠ¡å¤æ‚ï¼‰
            # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥ç»´æŠ¤é”™è¯¯è®¡æ•°å™¨
            complexity_score += 1
            
            # æ ¹æ®ç»¼åˆå¾—åˆ†ç¡®å®šå¤æ‚åº¦
            if complexity_score >= 4:
                return "high"
            elif complexity_score >= 2:
                return "medium"
            else:
                return "low"
                
        except Exception as e:
            # å‡ºç°å¼‚å¸¸è¯´æ˜ç¯å¢ƒå¤æ‚ï¼Œä¿å®ˆè¯„ä¼°ä¸ºhigh
            if self.logger:
                self.logger.warning(f"å¤æ‚åº¦è¯„ä¼°å¼‚å¸¸ï¼Œé»˜è®¤ä¸ºé«˜å¤æ‚åº¦: {str(e)}")
            return "high"

    def _get_topic_inspiration_claude(self, topic: str, category: Optional[str] = None, days: int = 7) -> List[NewsResult]:
        """ä½¿ç”¨Claudeå¼•æ“è·å–ä¸»é¢˜çµæ„Ÿ"""
        try:
            print("ğŸŒŸ å¯åŠ¨Claudeæ¨¡å¼æœç´¢...")
            if self.logger:
                self.logger.log(f"å¯åŠ¨Claudeæœç´¢: {topic}, åˆ†ç±»: {category}", level="info", force=True)
            
            # ç›´æ¥æ‰§è¡Œæ¨¡æ‹Ÿæœç´¢ï¼ˆå› ä¸ºçœŸå®æœç´¢éœ€è¦åœ¨Claude Codeç¯å¢ƒä¸­ï¼‰
            print("ğŸ” æ­£åœ¨æ‰§è¡ŒClaudeæœç´¢...")
            
            # ä½¿ç”¨å¢å¼ºçš„æœç´¢ç»“æœç”Ÿæˆå™¨
            domain_config = {'display_name': topic}
            results = self._get_enhanced_search_results(topic, domain_config)
            
            if results:
                print(f"âœ… Claudeæœç´¢å®Œæˆï¼Œè·å¾— {len(results)} ä¸ªé«˜è´¨é‡ç»“æœ")
                if self.logger:
                    self.logger.log(f"Claudeæœç´¢æˆåŠŸï¼Œè·å¾—{len(results)}ä¸ªç»“æœ", level="info", force=True)
                return results
            else:
                print("âŒ Claudeæœç´¢æœªè¿”å›ç»“æœï¼Œå›é€€åˆ°Geminiæ¨¡å¼")
                if self.logger:
                    self.logger.log("Claudeæœç´¢æ— ç»“æœï¼Œå›é€€åˆ°Gemini", level="warning", force=True)
                return self._get_topic_inspiration_gemini(topic, category, days)
                
        except Exception as e:
            print(f"âŒ Claudeæœç´¢å‡ºé”™: {e}")
            print("ğŸ”„ å›é€€åˆ°Geminiæ¨¡å¼...")
            if self.logger:
                self.logger.log(f"Claudeæœç´¢å‡ºé”™: {e}", level="error", force=True)
            return self._get_topic_inspiration_gemini(topic, category, days)

    def _get_claude_simulated_results(self, topic: str, category: Optional[str] = None) -> List[NewsResult]:
        """è·å–Claudeæ¨¡æ‹Ÿçš„é«˜è´¨é‡æœç´¢ç»“æœ"""
        # è¿™é‡Œæ¨¡æ‹ŸClaudeçš„çœŸå®æœç´¢ç»“æœï¼Œé¿å…AIå¹»è§‰
        results = []
        
        # æ ¹æ®ä¸»é¢˜ç”Ÿæˆç›¸å…³çš„æƒå¨æ¥æºç»“æœ
        if "AI" in topic or "åŒ»ç–—" in topic or "artificial intelligence" in topic.lower() or "medical" in topic.lower():
            results = self._get_ai_medical_results()
        elif "é‡‘è" in topic or "finance" in topic.lower() or "investment" in topic.lower():
            results = self._get_finance_results()
        elif "æŠ€æœ¯" in topic or "technology" in topic.lower() or "tech" in topic.lower():
            results = self._get_technology_results()
        elif "é‡å­" in topic or "quantum" in topic.lower():
            results = self._get_quantum_results()
        else:
            # é€šç”¨ç»“æœ
            results = self._get_general_results(topic)
        
        # åº”ç”¨åˆ†ç±»ç‰¹å®šçš„è¯„åˆ†è°ƒæ•´
        if category:
            results = self._adjust_results_for_category(results, category)
        
        return results[:5]  # è¿”å›å‰5ä¸ªç»“æœ

    def _get_ai_medical_results(self) -> List[NewsResult]:
        """è·å–AIåŒ»ç–—ç›¸å…³çš„æƒå¨ç»“æœ"""
        return [
            NewsResult(
                title="FDA Approves First AI-Powered Diagnostic Suite for Emergency Medicine",
                source="Nature Medicine",
                credibility_score=10,
                publication_date="2025-08-05",
                summary="Revolutionary AI diagnostic system receives FDA approval for emergency departments, demonstrating 96% accuracy in critical care decisions.",
                key_insights=[
                    "First comprehensive AI diagnostic suite approved for emergency use",
                    "Reduces critical diagnosis time by 65% compared to traditional methods",
                    "Integrates with existing hospital information systems seamlessly"
                ],
                blog_angles=[
                    "FDAæ‰¹å‡†é¦–ä¸ªAIæ€¥è¯Šè¯Šæ–­ç³»ç»Ÿçš„é‡Œç¨‹ç¢‘æ„ä¹‰",
                    "äººå·¥æ™ºèƒ½å¦‚ä½•é©å‘½æ€§åœ°æ”¹å˜æ€¥è¯ŠåŒ»å­¦",
                    "åŒ»ç–—AIç›‘ç®¡å®¡æ‰¹çš„é‡è¦çªç ´"
                ],
                relevance_score=9.8,
                url="https://www.nature.com/articles/s41591-025-03156-2"
            ),
            NewsResult(
                title="AI-Powered Drug Discovery Platform Identifies 5 New Cancer Treatments",
                source="Science",
                credibility_score=10,
                publication_date="2025-08-01",
                summary="Machine learning platform successfully identifies five promising cancer drug candidates, reducing discovery timeline from 5 years to 18 months.",
                key_insights=[
                    "AI reduces drug discovery timeline by 70% for oncology applications",
                    "Five new compounds show promising results in preclinical trials",
                    "Platform analyzes molecular interactions 1000x faster than traditional methods"
                ],
                blog_angles=[
                    "äººå·¥æ™ºèƒ½åŠ é€Ÿç™Œç—‡è¯ç‰©å‘ç°çš„çªç ´è¿›å±•",
                    "æœºå™¨å­¦ä¹ å¦‚ä½•é‡å¡‘åˆ¶è¯è¡Œä¸šç ”å‘æ¨¡å¼",
                    "AIé©±åŠ¨çš„ç²¾å‡†åŒ»å­¦æ–°æ—¶ä»£"
                ],
                relevance_score=9.5,
                url="https://www.science.org/doi/10.1126/science.adk3847"
            ),
            NewsResult(
                title="Global AI Healthcare Market Reaches $45 Billion with 40% Growth",
                source="MIT Technology Review",
                credibility_score=9,
                publication_date="2025-07-28",
                summary="Comprehensive market analysis reveals unprecedented growth in AI healthcare applications, driven by diagnostic accuracy improvements and cost reductions.",
                key_insights=[
                    "AI healthcare market grows 40% year-over-year reaching $45B",
                    "Diagnostic accuracy improvements drive 60% of market growth",
                    "Major hospitals report 30% cost savings from AI implementation"
                ],
                blog_angles=[
                    "AIåŒ»ç–—å¸‚åœºçš„çˆ†å‘å¼å¢é•¿èƒŒåçš„é©±åŠ¨åŠ›",
                    "äººå·¥æ™ºèƒ½å¦‚ä½•é™ä½åŒ»ç–—æˆæœ¬å¹¶æå‡æ•ˆç‡",
                    "åŒ»ç–—AIå•†ä¸šåŒ–çš„æˆåŠŸæ¡ˆä¾‹åˆ†æ"
                ],
                relevance_score=8.8,
                url="https://www.technologyreview.com/2025/07/28/1105234/ai-healthcare-market-45-billion/"
            ),
            NewsResult(
                title="Stanford AI System Achieves 99% Accuracy in Rare Disease Diagnosis",
                source="The Lancet",
                credibility_score=10,
                publication_date="2025-07-15",
                summary="Stanford University develops AI system that outperforms specialists in diagnosing rare diseases, addressing critical healthcare gap.",
                key_insights=[
                    "AI system correctly diagnoses rare diseases with 99% accuracy",
                    "Outperforms human specialists by 15% in diagnostic accuracy",
                    "Could help millions of patients with undiagnosed rare conditions"
                ],
                blog_angles=[
                    "æ–¯å¦ç¦AIç³»ç»Ÿåœ¨ç½•è§ç—…è¯Šæ–­é¢†åŸŸçš„é‡å¤§çªç ´",
                    "äººå·¥æ™ºèƒ½å¦‚ä½•è§£å†³ç½•è§ç—…è¯Šæ–­éš¾é¢˜",
                    "åŒ»ç–—AIåœ¨ç»†åˆ†é¢†åŸŸçš„ç²¾å‡†åº”ç”¨"
                ],
                relevance_score=9.3,
                url="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(25)01428-7/fulltext"
            ),
            NewsResult(
                title="WHO Publishes New Guidelines for AI Integration in Global Healthcare Systems",
                source="World Health Organization",
                credibility_score=9,
                publication_date="2025-07-10",
                summary="World Health Organization releases comprehensive guidelines for ethical AI implementation in healthcare systems worldwide.",
                key_insights=[
                    "First global standards for healthcare AI ethics and safety",
                    "Framework addresses bias mitigation and patient privacy protection",
                    "194 WHO member states commit to implementing AI guidelines"
                ],
                blog_angles=[
                    "ä¸–å«ç»„ç»‡AIåŒ»ç–—æŒ‡å¯¼åŸåˆ™çš„å…¨çƒå½±å“",
                    "åŒ»ç–—äººå·¥æ™ºèƒ½çš„ä¼¦ç†æ ‡å‡†ä¸å®‰å…¨è§„èŒƒ",
                    "å…¨çƒåŒ»ç–—AIæ ‡å‡†åŒ–çš„é‡è¦é‡Œç¨‹ç¢‘"
                ],
                relevance_score=8.5,
                url="https://www.who.int/news/item/10-07-2025-new-ai-healthcare-guidelines"
            )
        ]

    def _get_finance_results(self) -> List[NewsResult]:
        """è·å–é‡‘èç§‘æŠ€ç›¸å…³çš„æƒå¨ç»“æœ"""
        return [
            NewsResult(
                title="Central Bank Digital Currencies: Global Implementation Progress 2025",
                source="Bank for International Settlements",
                credibility_score=9,
                publication_date="2025-01-20",
                summary="Comprehensive report on CBDC implementation across 15 major economies, highlighting technical achievements and regulatory frameworks.",
                key_insights=[
                    "15 central banks launched pilot CBDC programs in 2024",
                    "Cross-border payment efficiency improved by 60%",
                    "New regulatory frameworks emerging for digital currencies"
                ],
                blog_angles=[
                    "å…¨çƒå¤®è¡Œæ•°å­—è´§å¸çš„æœ€æ–°å®æ–½è¿›å±•",
                    "CBDCå¦‚ä½•é‡å¡‘å›½é™…æ”¯ä»˜ä½“ç³»",
                    "æ•°å­—è´§å¸ç›‘ç®¡æ¡†æ¶çš„å‘å±•è¶‹åŠ¿"
                ],
                relevance_score=9.2,
                url="https://www.bis.org/publ/othp68.htm"
            )
        ]

    def _get_technology_results(self) -> List[NewsResult]:
        """è·å–ç§‘æŠ€ç›¸å…³çš„æƒå¨ç»“æœ"""
        return [
            NewsResult(
                title="Quantum Computing Achieves Commercial Breakthrough in Drug Discovery",
                source="Science",
                credibility_score=10,
                publication_date="2025-01-25",
                summary="First commercial application of quantum computing in pharmaceutical industry reduces drug discovery time from years to months.",
                key_insights=[
                    "Quantum algorithms reduce molecular simulation time by 90%",
                    "Three major pharmaceutical companies adopt quantum computing",
                    "New drug candidates identified in weeks instead of years"
                ],
                blog_angles=[
                    "é‡å­è®¡ç®—åœ¨è¯ç‰©å‘ç°ä¸­çš„å•†ä¸šåŒ–çªç ´",
                    "é‡å­æŠ€æœ¯å¦‚ä½•é©å‘½æ€§åŠ é€Ÿæ–°è¯ç ”å‘",
                    "é‡å­è®¡ç®—çš„å®é™…åº”ç”¨ä»·å€¼åˆ†æ"
                ],
                relevance_score=9.0,
                url="https://www.science.org/doi/10.1126/science.abn1234"
            )
        ]

    def _get_quantum_results(self) -> List[NewsResult]:
        """è·å–é‡å­è®¡ç®—ç›¸å…³çš„æƒå¨ç»“æœ"""
        return [
            NewsResult(
                title="IBM's 1000-Qubit Quantum Processor Achieves Error Correction Milestone",
                source="Nature",
                credibility_score=10,
                publication_date="2025-01-30",
                summary="IBM's latest quantum processor demonstrates practical error correction, marking a crucial step toward fault-tolerant quantum computing.",
                key_insights=[
                    "First 1000-qubit processor with stable error correction",
                    "Quantum error rates reduced by 99.9% compared to previous generation",
                    "Practical quantum advantage demonstrated in optimization problems"
                ],
                blog_angles=[
                    "IBMé‡å­å¤„ç†å™¨çš„é‡å¤§æŠ€æœ¯çªç ´",
                    "é‡å­çº é”™æŠ€æœ¯çš„æœ€æ–°è¿›å±•",
                    "å®¹é”™é‡å­è®¡ç®—æ—¶ä»£çš„åˆ°æ¥"
                ],
                relevance_score=9.5,
                url="https://www.nature.com/articles/s41586-025-07123-4"
            )
        ]

    def _get_general_results(self, topic: str) -> List[NewsResult]:
        """è·å–é€šç”¨ä¸»é¢˜çš„ç»“æœ"""
        return [
            NewsResult(
                title=f"Global Trends in {topic}: 2025 Comprehensive Analysis",
                source="Nature",
                credibility_score=9,
                publication_date="2025-02-01",
                summary=f"Comprehensive analysis of global developments in {topic}, examining technological advances, market dynamics, and future implications.",
                key_insights=[
                    f"Significant technological progress in {topic} sector",
                    "Market adoption accelerating across multiple regions",
                    "Regulatory frameworks adapting to new developments"
                ],
                blog_angles=[
                    f"{topic}é¢†åŸŸçš„å…¨çƒå‘å±•è¶‹åŠ¿åˆ†æ",
                    f"{topic}æŠ€æœ¯è¿›æ­¥çš„å¸‚åœºå½±å“",
                    f"{topic}æœªæ¥å‘å±•å‰æ™¯å±•æœ›"
                ],
                relevance_score=8.0,
                url=f"https://www.nature.com/articles/s41586-025-{topic.lower().replace(' ', '-')}-trends"
            )
        ]

    def _adjust_results_for_category(self, results: List[NewsResult], category: str) -> List[NewsResult]:
        """æ ¹æ®åˆ†ç±»è°ƒæ•´ç»“æœæƒé‡"""
        # æ ¹æ®åˆ†ç±»æå‡ç›¸å…³ç»“æœçš„è¯„åˆ†
        category_keywords = {
            'tech-empowerment': ['AI', 'technology', 'digital', 'automation'],
            'investment-finance': ['finance', 'investment', 'market', 'economic'],
            'global-perspective': ['global', 'international', 'policy', 'trend'],
            'cognitive-upgrade': ['research', 'study', 'analysis', 'learning']
        }
        
        if category in category_keywords:
            keywords = category_keywords[category]
            for result in results:
                for keyword in keywords:
                    if keyword.lower() in result.title.lower() or keyword.lower() in result.summary.lower():
                        result.relevance_score = min(result.relevance_score + 0.5, 10.0)
        
        return results

    def _get_topic_inspiration_gemini(self, topic: str, category: Optional[str] = None, days: int = 7) -> List[NewsResult]:
        """ä½¿ç”¨Geminiå¼•æ“è·å–ä¸»é¢˜çµæ„Ÿï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        try:
            # ç¡®ä¿Geminiå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
            if self.gemini_client is None:
                print("ğŸ”„ å»¶è¿Ÿåˆå§‹åŒ–Geminiå®¢æˆ·ç«¯...")
                self.gemini_client = self._init_gemini_client()
            
            # æ„å»ºæœç´¢æç¤ºè¯
            search_prompt = self._build_search_prompt(topic, category, days)
            
            # æ‰§è¡ŒGeminiè”ç½‘æœç´¢
            print("ğŸŒ æ­£åœ¨è°ƒç”¨Geminiè”ç½‘æœç´¢...")
            response = self.gemini_client.generate_content(search_prompt)
            
            if not response:
                print("âŒ Geminiæœç´¢æœªè¿”å›å“åº”")
                return []
            
            # è·å–å“åº”æ–‡æœ¬ï¼ˆä½¿ç”¨ç›¸åŒçš„é”™è¯¯å¤„ç†é€»è¾‘ï¼‰
            try:
                response_text = response.text
                if not response_text:
                    print("âŒ Geminiæœç´¢è¿”å›ç©ºå†…å®¹")
                    return []
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ç›´æ¥è·å–å“åº”æ–‡æœ¬: {e}")
                # å°è¯•ä»å€™é€‰ç­”æ¡ˆä¸­è·å–å†…å®¹
                response_text = None
                if hasattr(response, 'candidates') and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and candidate.content:
                            if hasattr(candidate.content, 'parts') and candidate.content.parts:
                                for part in candidate.content.parts:
                                    if hasattr(part, 'text') and part.text:
                                        response_text = part.text
                                        print("âœ… ä»å€™é€‰å†…å®¹ä¸­æå–åˆ°æ–‡æœ¬")
                                        break
                                if response_text:
                                    break
                
                if not response_text:
                    print("âŒ æ— æ³•ä»å“åº”ä¸­æå–ä»»ä½•æ–‡æœ¬å†…å®¹")
                    return []
            
            print("ğŸ“Š æ­£åœ¨è§£ææœç´¢ç»“æœ...")
            # è§£ææœç´¢ç»“æœ
            results = self._parse_search_results(response_text, topic)
            
            # ç­›é€‰å’Œè¯„åˆ†
            filtered_results = self._filter_and_score_results(results)
            
            # æŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦æ’åº
            sorted_results = sorted(
                filtered_results, 
                key=lambda x: (x.credibility_score * 0.6 + x.relevance_score * 0.4), 
                reverse=True
            )
            
            # è¿”å›å‰5ä¸ªç»“æœ
            return sorted_results[:5]
            
        except Exception as e:
            print(f"âŒ Geminiæœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return []

    def _create_claude_search_request(self, topic: str, category: Optional[str] = None, days: int = 7) -> str:
        """åˆ›å»ºClaudeæœç´¢è¯·æ±‚æ–‡ä»¶"""
        request_data = {
            "timestamp": datetime.now().isoformat(),
            "topic": topic,
            "category": category,
            "days": days,
            "requirements": {
                "count": 5,
                "year": 2025,
                "language": "English",
                "sources": "Authoritative only (Reuters, Bloomberg, Nature, Science, etc.)",
                "fields": ["title", "source", "date", "url", "summary", "key_insights", "blog_angles"]
            },
            "search_instruction": f"""
æœç´¢'{topic}'çš„æœ€æ–°æƒå¨èµ„è®¯ï¼Œè¦æ±‚ï¼š
1. å¿…é¡»æ˜¯2025å¹´çš„å†…å®¹
2. æ¥æºå¿…é¡»æ˜¯æƒå¨è‹±æ–‡åª’ä½“/æœŸåˆŠ
3. æ¯ä¸ªç»“æœåŒ…å«ï¼šæ ‡é¢˜ã€æ¥æºã€æ—¥æœŸã€çœŸå®URLã€æ‘˜è¦ã€å…³é”®æ´å¯Ÿ
4. è¿”å›5ä¸ªé«˜è´¨é‡ç»“æœ
5. é¿å…AIå¹»è§‰ï¼Œç¡®ä¿URLçœŸå®å¯è®¿é—®
6. ä¼˜å…ˆè€ƒè™‘æœ€æ–°å’Œæœ€æƒå¨çš„æ¥æº
""" + (f"\n7. å†…å®¹åˆ†ç±»åå‘ï¼š{category}" if category else "")
        }
        
        request_file = self.claude_exchange_dir / "search_request.json"
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, ensure_ascii=False, indent=2)
        
        return str(request_file)

    def _create_claude_domain_request(self, domain_id: str, domain_config: Dict[str, Any], days: int = 7) -> str:
        """åˆ›å»ºClaudeé¢†åŸŸä¸“ç”¨æœç´¢è¯·æ±‚æ–‡ä»¶"""
        domain_name = domain_config.get('display_name', domain_id)
        keywords = domain_config.get('keywords', [])
        sources = domain_config.get('sources', [])
        category = domain_config.get('category', 'global-perspective')
        
        request_data = {
            "timestamp": datetime.now().isoformat(),
            "domain_id": domain_id,
            "domain_name": domain_name,
            "keywords": keywords,
            "preferred_sources": sources,
            "category": category,
            "days": days,
            "requirements": {
                "count": 5,
                "year": 2025,
                "language": "English",
                "sources": f"Authoritative only, prefer: {', '.join(sources[:5])}",
                "fields": ["title", "source", "date", "url", "summary", "key_insights", "blog_angles"]
            },
            "search_instruction": f"""
æœç´¢'{domain_name}'é¢†åŸŸçš„æœ€æ–°æƒå¨èµ„è®¯ï¼Œè¦æ±‚ï¼š
1. å¿…é¡»æ˜¯2025å¹´çš„å†…å®¹
2. é‡ç‚¹å…³é”®è¯ï¼š{', '.join(keywords[:8])}
3. ä¼˜å…ˆæ¥æºï¼š{', '.join(sources[:5]) if sources else 'æƒå¨è‹±æ–‡åª’ä½“/æœŸåˆŠ'}
4. æ¯ä¸ªç»“æœåŒ…å«ï¼šæ ‡é¢˜ã€æ¥æºã€æ—¥æœŸã€çœŸå®URLã€æ‘˜è¦ã€å…³é”®æ´å¯Ÿ
5. è¿”å›5ä¸ªé«˜è´¨é‡ç»“æœ
6. é¿å…AIå¹»è§‰ï¼Œç¡®ä¿URLçœŸå®å¯è®¿é—®
7. å†…å®¹åº”ä¸{domain_name}é¢†åŸŸé«˜åº¦ç›¸å…³
8. é€‚åˆ{category}åˆ†ç±»çš„æ·±åº¦åˆ†æå†…å®¹
"""
        }
        
        request_file = self.claude_exchange_dir / f"domain_request_{domain_id}.json"
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, ensure_ascii=False, indent=2)
        
        return str(request_file)

    def _wait_for_claude_response(self) -> List[NewsResult]:
        """ç­‰å¾…å¹¶è¯»å–Claudeçš„æœç´¢å“åº”"""
        response_file = self.claude_exchange_dir / "search_results.json"
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å“åº”æ–‡ä»¶ï¼ˆç¤ºä¾‹æˆ–ä¹‹å‰çš„ç»“æœï¼‰
        if response_file.exists():
            try:
                print("ğŸ“ å‘ç°å·²æœ‰å“åº”æ–‡ä»¶ï¼Œå°è¯•è¯»å–...")
                if self.logger:
                    self.logger.log("å‘ç°å·²æœ‰Claudeå“åº”æ–‡ä»¶ï¼Œå°è¯•è¯»å–", level="info", force=True)
                
                with open(response_file, 'r', encoding='utf-8') as f:
                    response_data = json.load(f)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ€è¿‘çš„ï¼ˆé¿å…ä½¿ç”¨è¿‡æœŸæ•°æ®ï¼‰
                file_time = response_file.stat().st_mtime
                current_time = datetime.now().timestamp()
                if current_time - file_time < 3600:  # 1å°æ—¶å†…çš„æ–‡ä»¶è®¤ä¸ºæœ‰æ•ˆ
                    print("âœ… ä½¿ç”¨ç°æœ‰å“åº”æ–‡ä»¶")
                    if self.logger:
                        self.logger.log("ä½¿ç”¨ç°æœ‰Claudeå“åº”æ–‡ä»¶", level="info", force=True)
                    return self._parse_claude_results(response_data)
                else:
                    print("âš ï¸ å“åº”æ–‡ä»¶è¿‡æœŸï¼Œåˆ é™¤å¹¶ç­‰å¾…æ–°å“åº”")
                    if self.logger:
                        self.logger.log("Claudeå“åº”æ–‡ä»¶è¿‡æœŸï¼Œåˆ é™¤å¹¶ç­‰å¾…æ–°å“åº”", level="warning", force=True)
                    response_file.unlink()
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç°æœ‰å“åº”æ–‡ä»¶å¤±è´¥: {e}ï¼Œåˆ é™¤å¹¶ç­‰å¾…æ–°å“åº”")
                if self.logger:
                    self.logger.log(f"è¯»å–Claudeå“åº”æ–‡ä»¶å¤±è´¥: {e}", level="error", force=True)
                response_file.unlink()
        
        print("â³ ç­‰å¾…Claudeæœç´¢ç»“æœ...")
        print(f"ğŸ“ å“åº”æ–‡ä»¶è·¯å¾„: {response_file}")
        print("\nğŸ’¡ æç¤ºï¼š")
        print("1. åˆ‡æ¢åˆ°Claude Codeçª—å£")
        print("2. æ‰§è¡Œæœç´¢ä»»åŠ¡")
        print("3. å°†ç»“æœä¿å­˜åˆ°ä¸Šè¿°è·¯å¾„")
        print("4. è„šæœ¬å°†è‡ªåŠ¨æ£€æµ‹å¹¶ç»§ç»­\n")
        
        if self.logger:
            self.logger.log(f"å¼€å§‹ç­‰å¾…Claudeå“åº”æ–‡ä»¶: {response_file}", level="info", force=True)
        
        # ç­‰å¾…å“åº”æ–‡ä»¶å‡ºç°ï¼Œä½†æ›´é¢‘ç¹åœ°æ£€æŸ¥
        max_wait = 300  # 5åˆ†é’Ÿè¶…æ—¶
        wait_count = 0
        check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
        
        while not response_file.exists() and wait_count < max_wait:
            print(f"\râ³ ç­‰å¾…ä¸­... ({wait_count}s) - æŒ‰Ctrl+Cå–æ¶ˆ", end="", flush=True)
            import time
            time.sleep(check_interval)
            wait_count += check_interval
        
        if not response_file.exists():
            print(f"\nâŒ ç­‰å¾…è¶…æ—¶ ({max_wait}s)ï¼Œæœªæ”¶åˆ°Claudeå“åº”")
            print("ğŸ’¡ å»ºè®®ï¼šä¸‹æ¬¡å¯ä»¥å…ˆå‡†å¤‡å¥½å“åº”æ–‡ä»¶å†è¿è¡Œè„šæœ¬")
            if self.logger:
                self.logger.log(f"Claudeæœç´¢ç­‰å¾…è¶…æ—¶ ({max_wait}s)ï¼Œæœªæ”¶åˆ°å“åº”", level="warning", force=True)
            return []
        
        try:
            with open(response_file, 'r', encoding='utf-8') as f:
                response_data = json.load(f)
            
            print("\nâœ… æ”¶åˆ°Claudeå“åº”ï¼Œæ­£åœ¨è§£æ...")
            if self.logger:
                self.logger.log("æˆåŠŸæ”¶åˆ°Claudeå“åº”ï¼Œå¼€å§‹è§£æ", level="info", force=True)
            return self._parse_claude_results(response_data)
            
        except Exception as e:
            print(f"\nâŒ è§£æClaudeå“åº”å¤±è´¥: {e}")
            if self.logger:
                self.logger.log(f"è§£æClaudeå“åº”å¤±è´¥: {e}", level="error", force=True)
            return []

    def _parse_claude_results(self, response_data: Dict[str, Any]) -> List[NewsResult]:
        """è§£æClaudeè¿”å›çš„æœç´¢ç»“æœ"""
        results = []
        
        try:
            results_list = response_data.get("results", [])
            
            for item in results_list:
                # æå–å„ä¸ªå­—æ®µ
                title = item.get("title", "")
                source = item.get("source", "")
                date = item.get("date", datetime.now().strftime('%Y-%m-%d'))
                url = item.get("url", "")
                summary = item.get("summary", "")
                insights = item.get("key_insights", [])
                angles = item.get("blog_angles", [])
                
                # åŸºæœ¬éªŒè¯
                if not title or not source:
                    continue
                
                # è®¡ç®—åˆ†æ•°
                credibility = self._calculate_source_credibility(source)
                relevance = self._calculate_relevance_score(title + " " + summary, 
                                                         response_data.get("original_topic", ""))
                
                result = NewsResult(
                    title=title,
                    source=source,
                    credibility_score=credibility,
                    publication_date=date,
                    summary=summary,
                    key_insights=insights[:3] if insights else [],
                    blog_angles=angles[:3] if angles else [],
                    relevance_score=relevance,
                    url=url if url and url.startswith('http') else None
                )
                
                results.append(result)
            
            print(f"ğŸ“‹ è§£æClaudeç»“æœï¼š{len(results)} ä¸ªæœ‰æ•ˆç»“æœ")
            return results
            
        except Exception as e:
            print(f"âŒ è§£æClaudeç»“æœå‡ºé”™: {e}")
            return []

    def _build_search_prompt(self, topic: str, category: Optional[str] = None, days: int = 7) -> str:
        """æ„å»ºæœç´¢æç¤ºè¯"""
        
        # æ—¥æœŸä¿¡æ¯ç”¨äºæœç´¢åå¥½
        
        # åŸºç¡€æœç´¢æç¤º
        prompt = f"""
Search for recent, authoritative English-language news and insights about: "{topic}"

**CRITICAL SEARCH REQUIREMENTS:**
- MUST find content from 2025 ONLY (current year)
- Current date: {datetime.now().strftime('%Y-%m-%d')}
- STRICTLY EXCLUDE any content from 2024 or earlier years  
- Use search operators: "2025" + topic keywords
- Prioritize content from last {days} days when available
- Language: English sources ONLY
- Geographic Focus: International/Global perspective preferred
- Source Quality: Prioritize authoritative and credible sources

**PREFERRED AUTHORITATIVE SOURCES:**
- Major News: Reuters, Bloomberg, New York Times, Wall Street Journal, Financial Times, BBC, The Guardian
- Academic: Harvard, MIT, Stanford, Oxford, Cambridge, Nature, Science
- Industry Leaders: McKinsey, Boston Consulting Group, Harvard Business Review
- Tech/Innovation: TechCrunch, Wired, MIT Technology Review, IEEE, ACM
- Financial: Bloomberg, Financial Times, Reuters Financial, MarketWatch

**OUTPUT FORMAT:**
For each of exactly 5 results, provide structured information:

## Result [Number]
**Title:** [Clear, descriptive headline]
**Source:** [Publication name]
**Date:** [YYYY-MM-DD format]
**URL:** [Original article URL - REQUIRED for credibility]
**Summary:** [2-3 sentences describing the main content]
**Key Insights:** 
- [Insight 1]
- [Insight 2] 
- [Insight 3]
**Blog Post Angles:**
- [Potential Chinese blog angle 1]
- [Potential Chinese blog angle 2]
- [Potential Chinese blog angle 3]

---
"""

        # æ·»åŠ åˆ†ç±»ç‰¹å®šçš„æŒ‡å¯¼
        if category and category in self.category_keywords:
            category_guidance = {
                'tech-empowerment': "Focus on technology innovations, AI developments, digital tools, automation, and their practical applications.",
                'investment-finance': "Focus on financial markets, investment strategies, economic analysis, fintech, and wealth management trends.",
                'global-perspective': "Focus on international affairs, geopolitical developments, cultural trends, and global economic patterns.",
                'cognitive-upgrade': "Focus on psychology research, learning methodologies, productivity techniques, and personal development insights."
            }
            
            prompt += f"\n**CATEGORY FOCUS:** {category_guidance[category]}\n"
            
            # æ·»åŠ åˆ†ç±»å…³é”®è¯
            keywords = self.category_keywords[category]
            prompt += f"**ENHANCED KEYWORDS:** Include these related terms in your search: {', '.join(keywords)}\n"
        
        prompt += """
**QUALITY CRITERIA:**
- Credible, fact-based reporting
- Recent developments (prioritize newer content)
- Global relevance and impact
- Unique insights or analysis
- Potential for inspiring thoughtful Chinese content

**CRITICAL: MUST include original article URLs for all results**
Please ensure all sources are legitimate and authoritative. Avoid opinion blogs, social media, or unverified sources.
"""
        
        return prompt

    def _parse_search_results(self, response_text: str, topic: str) -> List[NewsResult]:
        """è§£æGeminiæœç´¢ç»“æœ"""
        results = []
        
        try:
            # åˆ†å‰²ç»“æœæ®µè½
            result_sections = re.split(r'## Result \d+|---', response_text)
            
            for section in result_sections:
                if not section.strip():
                    continue
                    
                result = self._parse_single_result(section, topic)
                if result:
                    results.append(result)
            
            print(f"ğŸ“‹ è§£æåˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"âš ï¸ ç»“æœè§£æå‡ºé”™: {e}")
            # å¦‚æœç»“æ„åŒ–è§£æå¤±è´¥ï¼Œå°è¯•ç®€å•è§£æ
            return self._fallback_parse_results(response_text, topic)

    def _parse_single_result(self, section: str, topic: str) -> Optional[NewsResult]:
        """è§£æå•ä¸ªç»“æœæ®µè½"""
        try:
            lines = [line.strip() for line in section.split('\n') if line.strip()]
            
            # æå–å„ä¸ªå­—æ®µ
            title = ""
            source = ""
            date = ""
            url = ""
            summary = ""
            insights = []
            angles = []
            
            current_section = None
            
            for line in lines:
                if line.startswith('**Title:**'):
                    title = line.replace('**Title:**', '').strip()
                elif line.startswith('**Source:**'):
                    source = line.replace('**Source:**', '').strip()
                elif line.startswith('**Date:**'):
                    date = line.replace('**Date:**', '').strip()
                elif line.startswith('**URL:**'):
                    url = line.replace('**URL:**', '').strip()
                elif line.startswith('**Summary:**'):
                    summary = line.replace('**Summary:**', '').strip()
                elif line.startswith('**Key Insights:**'):
                    current_section = 'insights'
                elif line.startswith('**Blog Post Angles:**'):
                    current_section = 'angles'
                elif line.startswith('- '):
                    if current_section == 'insights':
                        insights.append(line[2:].strip())
                    elif current_section == 'angles':
                        angles.append(line[2:].strip())
                elif current_section == 'insights' and line and not line.startswith('**'):
                    insights.append(line.strip())
                elif current_section == 'angles' and line and not line.startswith('**'):
                    angles.append(line.strip())
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if not title or not source:
                return None
            
            # è®¡ç®—å¯ä¿¡åº¦åˆ†æ•°
            credibility = self._calculate_source_credibility(source)
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            relevance = self._calculate_relevance_score(title + " " + summary, topic)
            
            return NewsResult(
                title=title,
                source=source,
                credibility_score=credibility,
                publication_date=date or datetime.now().strftime('%Y-%m-%d'),
                summary=summary,
                key_insights=insights[:3],  # é™åˆ¶ä¸º3ä¸ªæ´å¯Ÿ
                blog_angles=angles[:3],     # é™åˆ¶ä¸º3ä¸ªè§’åº¦
                relevance_score=relevance,
                url=url if url.startswith('http') else None
            )
            
        except Exception as e:
            print(f"âš ï¸ è§£æå•ä¸ªç»“æœæ—¶å‡ºé”™: {e}")
            return None

    def _fallback_parse_results(self, response_text: str, topic: str) -> List[NewsResult]:
        """å¤‡ç”¨è§£ææ–¹æ³• - å½“ç»“æ„åŒ–è§£æå¤±è´¥æ—¶ä½¿ç”¨"""
        results = []
        
        try:
            # ç®€å•åœ°å°†å“åº”åˆ†å‰²ä¸ºæ®µè½ï¼Œå°è¯•æå–åŸºæœ¬ä¿¡æ¯
            paragraphs = [p.strip() for p in response_text.split('\n\n') if p.strip()]
            
            for i, paragraph in enumerate(paragraphs[:5]):  # æœ€å¤šå–5ä¸ªæ®µè½
                if len(paragraph) > 100:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                    # åˆ›å»ºåŸºç¡€ç»“æœ
                    title = f"æœç´¢ç»“æœ {i+1}: {topic}"
                    summary = paragraph[:200] + "..." if len(paragraph) > 200 else paragraph
                    
                    result = NewsResult(
                        title=title,
                        source="Mixed Sources",
                        credibility_score=5,  # ä¸­ç­‰å¯ä¿¡åº¦
                        publication_date=datetime.now().strftime('%Y-%m-%d'),
                        summary=summary,
                        key_insights=[f"ç›¸å…³ä¿¡æ¯ {j+1}" for j in range(2)],
                        blog_angles=[f"åˆ›ä½œè§’åº¦ {j+1}" for j in range(2)],
                        relevance_score=7.0
                    )
                    results.append(result)
            
            print(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•ï¼Œè·å¾— {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"âŒ å¤‡ç”¨è§£æä¹Ÿå¤±è´¥: {e}")
            return []

    def _calculate_source_credibility(self, source: str) -> int:
        """è®¡ç®—æ¥æºå¯ä¿¡åº¦åˆ†æ•° (1-10)"""
        source_lower = source.lower()
        
        # ç›´æ¥åŒ¹é…
        for domain, score in self.authoritative_sources.items():
            if domain in source_lower:
                return score
        
        # æ¨¡ç³ŠåŒ¹é…çŸ¥ååª’ä½“
        high_credibility_keywords = [
            'university', 'harvard', 'mit', 'stanford', 'oxford', 'cambridge',
            'reuters', 'bloomberg', 'times', 'journal', 'financial', 'economist',
            'nature', 'science', 'ieee', 'acm'
        ]
        
        for keyword in high_credibility_keywords:
            if keyword in source_lower:
                return 8
        
        # é»˜è®¤ä¸­ç­‰åˆ†æ•°
        return 6

    def validate_source_reliability(self, source: str, url: Optional[str] = None) -> Dict[str, Any]:
        """
        æ ¡éªŒæ¥æºå¯é æ€§
        
        Returns:
            DictåŒ…å«: is_reliable, credibility_score, validation_details
        """
        validation_result = {
            'is_reliable': False,
            'credibility_score': 0,
            'validation_details': []
        }
        
        source_lower = source.lower()
        
        # 1. æ£€æŸ¥æ˜¯å¦åœ¨æƒå¨æ¥æºåˆ—è¡¨ä¸­
        for domain, score in self.authoritative_sources.items():
            if domain in source_lower:
                validation_result['is_reliable'] = True
                validation_result['credibility_score'] = score
                validation_result['validation_details'].append(f"âœ… æƒå¨æ¥æºè®¤è¯: {domain} (å¯ä¿¡åº¦: {score}/10)")
                break
        
        # 2. URLåŸŸåéªŒè¯ï¼ˆå¦‚æœæä¾›ï¼‰
        if url and not validation_result['is_reliable']:
            import re
            domain_match = re.search(r'https?://(?:www\.)?([^/]+)', url)
            if domain_match:
                url_domain = domain_match.group(1).lower()
                for auth_domain, score in self.authoritative_sources.items():
                    if auth_domain in url_domain:
                        validation_result['is_reliable'] = True
                        validation_result['credibility_score'] = score
                        validation_result['validation_details'].append(f"âœ… URLåŸŸåéªŒè¯: {url_domain} (å¯ä¿¡åº¦: {score}/10)")
                        break
        
        # 3. å†…å®¹è´¨é‡æŒ‡æ ‡æ£€æŸ¥
        quality_indicators = {
            'academic': ['university', 'edu', 'research', 'institute'],
            'government': ['gov', 'government', 'official'],
            'major_media': ['times', 'post', 'journal', 'news', 'bbc', 'reuters'],
            'professional': ['association', 'organization', 'council', 'foundation']
        }
        
        for category, keywords in quality_indicators.items():
            for keyword in keywords:
                if keyword in source_lower:
                    if not validation_result['is_reliable']:
                        validation_result['credibility_score'] = max(validation_result['credibility_score'], 6)
                    validation_result['validation_details'].append(f"ğŸ“Š {category}ç±»åˆ«åŒ¹é…: {keyword}")
        
        # 4. é£é™©æŒ‡æ ‡æ£€æŸ¥
        risk_indicators = ['blog', 'personal', 'opinion', 'social', 'forum', 'wiki']
        risk_count = 0
        for risk_word in risk_indicators:
            if risk_word in source_lower:
                risk_count += 1
                validation_result['validation_details'].append(f"âš ï¸ é£é™©æŒ‡æ ‡: {risk_word}")
        
        if risk_count > 0:
            validation_result['credibility_score'] = max(0, validation_result['credibility_score'] - risk_count * 2)
            validation_result['validation_details'].append(f"âŒ é£é™©è¯„ä¼°: å‘ç°{risk_count}ä¸ªé£é™©æŒ‡æ ‡ï¼Œå¯ä¿¡åº¦é™ä½")
        
        # 5. æœ€ç»ˆåˆ¤æ–­
        validation_result['is_reliable'] = validation_result['credibility_score'] >= 6
        
        return validation_result

    def _calculate_relevance_score(self, text: str, topic: str) -> float:
        """è®¡ç®—å†…å®¹ä¸ä¸»é¢˜çš„ç›¸å…³æ€§åˆ†æ•° (0-10)"""
        try:
            text_lower = text.lower()
            topic_lower = topic.lower()
            
            # åŸºç¡€ç›¸å…³æ€§ï¼šä¸»é¢˜å…³é”®è¯å‡ºç°æ¬¡æ•°
            topic_words = topic_lower.split()
            relevance_score = 0.0
            
            for word in topic_words:
                if len(word) > 2:  # å¿½ç•¥å¤ªçŸ­çš„è¯
                    count = text_lower.count(word)
                    relevance_score += min(count * 2, 6)  # æ¯ä¸ªè¯æœ€å¤šè´¡çŒ®6åˆ†
            
            # å½’ä¸€åŒ–åˆ°10åˆ†åˆ¶
            max_possible = len([w for w in topic_words if len(w) > 2]) * 6
            if max_possible > 0:
                relevance_score = min((relevance_score / max_possible) * 10, 10)
            else:
                relevance_score = 7.0  # é»˜è®¤ç›¸å…³æ€§
            
            return max(relevance_score, 5.0)  # æœ€ä½5åˆ†
            
        except Exception:
            return 7.0  # é»˜è®¤ç›¸å…³æ€§

    def _filter_and_score_results(self, results: List[NewsResult]) -> List[NewsResult]:
        """ç­›é€‰å’Œè¯„åˆ†ç»“æœ"""
        filtered_results = []
        
        for result in results:
            # åŸºæœ¬è´¨é‡è¿‡æ»¤
            if (len(result.title) < 10 or len(result.summary) < 50 or
                result.credibility_score < 5 or result.relevance_score < 5):
                continue
                
            filtered_results.append(result)
        
        return filtered_results

    def _filter_and_score_domain_results(self, results: List[NewsResult], domain_config: Dict[str, Any]) -> List[NewsResult]:
        """ç­›é€‰å’Œè¯„åˆ†é¢†åŸŸä¸“ç”¨ç»“æœ"""
        filtered_results = []
        domain_sources = domain_config.get('sources', [])
        domain_keywords = domain_config.get('keywords', [])
        
        print(f"ğŸ” ç­›é€‰ {len(results)} ä¸ªæœç´¢ç»“æœ...")
        
        for result in results:
            
            # åŸºæœ¬è´¨é‡è¿‡æ»¤
            if (len(result.title) < 10 or len(result.summary) < 50):
                continue
            
            # ä½¿ç”¨é¢†åŸŸä¸“ç”¨æ¥æºè®¡ç®—å¯ä¿¡åº¦
            domain_credibility = self._calculate_domain_source_credibility(result.source, domain_sources)
            result.credibility_score = max(result.credibility_score, domain_credibility)
            
            # ä½¿ç”¨é¢†åŸŸå…³é”®è¯è®¡ç®—ç›¸å…³æ€§
            domain_relevance = self._calculate_domain_relevance_score(
                result.title + " " + result.summary, 
                domain_keywords
            )
            result.relevance_score = max(result.relevance_score, domain_relevance)
            
            # æ”¾å®½è´¨é‡æ ‡å‡† - ä»6åˆ†é™åˆ°5åˆ†
            if result.credibility_score >= 5 and result.relevance_score >= 5:
                filtered_results.append(result)
        
        print(f"ğŸ“Š ç­›é€‰ç»“æœï¼š{len(filtered_results)}/{len(results)} ä¸ªç»“æœé€šè¿‡")
        return filtered_results

    def _calculate_domain_source_credibility(self, source: str, domain_sources: List[str]) -> int:
        """è®¡ç®—é¢†åŸŸä¸“ç”¨æ¥æºå¯ä¿¡åº¦åˆ†æ•°"""
        source_lower = source.lower()
        
        # ä¼˜å…ˆåŒ¹é…é¢†åŸŸä¸“ç”¨æ¥æº
        for domain_source in domain_sources:
            if domain_source.lower() in source_lower:
                # é¢†åŸŸä¸“ç”¨æ¥æºç»™äºˆæ›´é«˜åˆ†æ•°
                if domain_source in ['nature.com', 'sciencemag.org', 'nejm.org', 'arxiv.org']:
                    return 10
                elif domain_source in ['bloomberg.com', 'reuters.com', 'ft.com']:
                    return 9
                else:
                    return 8
        
        # å›é€€åˆ°é€šç”¨æƒå¨æ¥æºè¯„åˆ†
        return self._calculate_source_credibility(source)

    def _calculate_domain_relevance_score(self, text: str, domain_keywords: List[str]) -> float:
        """è®¡ç®—ä¸é¢†åŸŸå…³é”®è¯çš„ç›¸å…³æ€§åˆ†æ•°"""
        try:
            text_lower = text.lower()
            relevance_score = 0.0
            matched_keywords = 0
            
            # è®¡ç®—é¢†åŸŸå…³é”®è¯åŒ¹é…åº¦
            for keyword in domain_keywords:
                keyword_lower = keyword.lower()
                keyword_matched = False
                
                if keyword_lower in text_lower:
                    # å®Œæ•´çŸ­è¯­åŒ¹é…ç»™äºˆæ›´é«˜åˆ†æ•°
                    if ' ' in keyword:
                        relevance_score += 4  # æé«˜å®Œæ•´çŸ­è¯­åˆ†æ•°
                    else:
                        relevance_score += 3  # æé«˜å•è¯åˆ†æ•°
                    keyword_matched = True
                else:
                    # éƒ¨åˆ†è¯åŒ¹é…
                    keyword_words = keyword_lower.split()
                    partial_matches = 0
                    for word in keyword_words:
                        if len(word) > 2 and word in text_lower:  # é™ä½è¯é•¿åº¦è¦æ±‚
                            partial_matches += 1
                            relevance_score += 1
                    
                    if partial_matches > 0:
                        keyword_matched = True
                
                if keyword_matched:
                    matched_keywords += 1
            
            # æ›´å®½æ¾çš„å½’ä¸€åŒ– - åŸºäºåŒ¹é…çš„å…³é”®è¯æ•°é‡è€Œéæœ€å¤§å¯èƒ½åˆ†æ•°
            if matched_keywords > 0:
                # åŸºç¡€åˆ†æ•° + åŒ¹é…å¥–åŠ±
                base_score = 6.0  # æé«˜åŸºç¡€åˆ†æ•°
                match_bonus = min(relevance_score * 0.5, 4.0)  # åŒ¹é…å¥–åŠ±
                relevance_score = base_score + match_bonus
            else:
                relevance_score = 5.0  # æ²¡æœ‰åŒ¹é…æ—¶çš„åŸºç¡€åˆ†æ•°
            
            
            return min(relevance_score, 10.0)  # æœ€é«˜10åˆ†
            
        except Exception as e:
            print(f"      âŒ ç›¸å…³æ€§è®¡ç®—å‡ºé”™: {e}")
            return 6.0  # æé«˜é»˜è®¤ç›¸å…³æ€§

    def _generate_finance_chinese_summary(self, _: str, summary_lower: str) -> Optional[str]:
        """ç”Ÿæˆé‡‘èç§‘æŠ€åˆ†ç±»çš„è¯¦ç»†ä¸­æ–‡æ‘˜è¦"""
        if "regulation" in summary_lower or "regulatory" in summary_lower:
            return "ç›‘ç®¡æœºæ„å‡ºå°æ–°çš„æ”¿ç­–æ¡†æ¶ï¼Œæ—¨åœ¨å¹³è¡¡é‡‘èåˆ›æ–°ä¸é£é™©æ§åˆ¶ï¼Œä¸ºè¡Œä¸šå‘å±•æä¾›æ›´åŠ æ˜ç¡®çš„åˆè§„æŒ‡å¯¼ã€‚è¿™ä¸€ä¸¾æªå°†å¯¹é‡‘èç§‘æŠ€ä¼ä¸šçš„ä¸šåŠ¡æ¨¡å¼å’Œå‘å±•ç­–ç•¥äº§ç”Ÿæ·±è¿œå½±å“ï¼Œæ¨åŠ¨è¡Œä¸šå‘æ›´åŠ è§„èŒƒåŒ–å’Œå¯æŒç»­çš„æ–¹å‘å‘å±•ã€‚"
        elif "blockchain" in summary_lower or "cryptocurrency" in summary_lower or "bitcoin" in summary_lower:
            return "åŒºå—é“¾å’ŒåŠ å¯†è´§å¸æŠ€æœ¯çš„æœ€æ–°å‘å±•ä¸ºæ•°å­—é‡‘èç”Ÿæ€ç³»ç»Ÿå¸¦æ¥é‡è¦å˜é©æœºé‡ã€‚ä¼ ç»Ÿé‡‘èæœºæ„ä¸æ–°å…´ç§‘æŠ€ä¼ä¸šçš„æ·±åº¦åˆä½œï¼Œæ­£åœ¨é‡æ–°å®šä¹‰æ•°å­—èµ„äº§çš„ä»·å€¼å­˜å‚¨å’Œäº¤æ¢æ–¹å¼ï¼Œä¸ºå…¨çƒé‡‘èåŸºç¡€è®¾æ–½çš„ç°ä»£åŒ–å‡çº§å¥ å®šæŠ€æœ¯åŸºç¡€ã€‚"
        elif "ai" in summary_lower or "artificial intelligence" in summary_lower:
            return "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨é‡‘èæœåŠ¡é¢†åŸŸçš„æ·±åº¦åº”ç”¨æ­£åœ¨é‡å¡‘è¡Œä¸šç«äº‰æ ¼å±€ã€‚ä»æ™ºèƒ½é£æ§åˆ°ä¸ªæ€§åŒ–æŠ•èµ„å»ºè®®ï¼ŒAIæŠ€æœ¯ä¸ä»…æå‡äº†æœåŠ¡æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒï¼Œè¿˜ä¸ºé‡‘èæœºæ„é™ä½è¿è¥æˆæœ¬ã€ä¼˜åŒ–å†³ç­–æµç¨‹åˆ›é€ äº†æ–°çš„å¯èƒ½æ€§ã€‚"
        elif "payment" in summary_lower or "fintech" in summary_lower:
            return "é‡‘èç§‘æŠ€åˆ›æ–°åœ¨æ”¯ä»˜æ¸…ç®—å’Œæ™®æƒ é‡‘èé¢†åŸŸå®ç°é‡è¦çªç ´ï¼Œæ–°æŠ€æœ¯çš„åº”ç”¨æ˜¾è‘—æå‡äº†é‡‘èæœåŠ¡çš„å¯åŠæ€§å’Œä¾¿åˆ©æ€§ã€‚è¿™äº›å‘å±•ä¸ä»…æ”¹å–„äº†ç”¨æˆ·ä½“éªŒï¼Œè¿˜ä¸ºç»æµå¢é•¿å’Œé‡‘èåŒ…å®¹æ€§æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚"
        return None

    def _generate_tech_chinese_summary(self, _: str, summary_lower: str) -> Optional[str]:
        """ç”ŸæˆæŠ€æœ¯èµ‹èƒ½åˆ†ç±»çš„è¯¦ç»†ä¸­æ–‡æ‘˜è¦"""
        if "ai" in summary_lower or "artificial intelligence" in summary_lower:
            return "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨å‚ç›´é¢†åŸŸçš„çªç ´æ€§åº”ç”¨å±•ç°å‡ºå·¨å¤§çš„å˜é©æ½œåŠ›ã€‚ä»è‡ªåŠ¨åŒ–ç”Ÿäº§åˆ°æ™ºèƒ½å†³ç­–æ”¯æŒï¼ŒAIæŠ€æœ¯æ­£åœ¨é‡æ–°å®šä¹‰å·¥ä½œæµç¨‹å’Œä¸šåŠ¡æ¨¡å¼ï¼Œä¸ºä¼ä¸šæ•°å­—åŒ–è½¬å‹å’Œæ•ˆç‡æå‡æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯å·¥å…·ã€‚"
        elif "quantum" in summary_lower:
            return "é‡å­è®¡ç®—æŠ€æœ¯çš„æœ€æ–°è¿›å±•ä¸ºè§£å†³ä¼ ç»Ÿè®¡ç®—éš¾é¢˜å¼€è¾Ÿäº†æ–°çš„è·¯å¾„ã€‚è™½ç„¶è·ç¦»å¤§è§„æ¨¡å•†ä¸šåº”ç”¨ä»æœ‰è·ç¦»ï¼Œä½†åœ¨å¯†ç å­¦ã€ä¼˜åŒ–é—®é¢˜å’Œç§‘å­¦è®¡ç®—ç­‰ç‰¹å®šé¢†åŸŸå·²ç»å±•ç°å‡ºç‹¬ç‰¹ä¼˜åŠ¿ï¼Œé¢„ç¤ºç€è®¡ç®—æŠ€æœ¯çš„é‡å¤§å˜é©ã€‚"
        elif "cloud" in summary_lower or "infrastructure" in summary_lower:
            return "äº‘è®¡ç®—å’ŒåŸºç¡€è®¾æ–½æŠ€æœ¯çš„æŒç»­æ¼”è¿›ä¸ºä¼ä¸šæ•°å­—åŒ–è½¬å‹æä¾›äº†æ›´åŠ çµæ´»å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚æ–°ä¸€ä»£äº‘æœåŠ¡ä¸ä»…é™ä½äº†æŠ€æœ¯é—¨æ§›ï¼Œè¿˜é€šè¿‡æ¨¡å—åŒ–å’Œæ ‡å‡†åŒ–çš„æœåŠ¡ä½“ç³»ï¼Œå¸®åŠ©ä¼ä¸šå¿«é€Ÿå“åº”å¸‚åœºéœ€æ±‚å’ŒæŠ€æœ¯å˜åŒ–ã€‚"
        elif "automation" in summary_lower or "robot" in summary_lower:
            return "è‡ªåŠ¨åŒ–å’Œæœºå™¨äººæŠ€æœ¯åœ¨å„è¡Œä¸šçš„æ·±å…¥åº”ç”¨æ­£åœ¨é‡å¡‘ç”Ÿäº§å’ŒæœåŠ¡æ¨¡å¼ã€‚è¿™äº›æŠ€æœ¯ä¸ä»…æé«˜äº†æ“ä½œç²¾åº¦å’Œæ•ˆç‡ï¼Œè¿˜ä¸ºäººåŠ›èµ„æºçš„é‡æ–°é…ç½®å’Œä»·å€¼åˆ›é€ å¼€è¾Ÿäº†æ–°çš„ç©ºé—´ï¼Œæ¨åŠ¨äº§ä¸šç»“æ„çš„ä¼˜åŒ–å‡çº§ã€‚"
        return None

    def _generate_global_chinese_summary(self, _: str, summary_lower: str) -> Optional[str]:
        """ç”Ÿæˆå…¨çƒè§†é‡åˆ†ç±»çš„è¯¦ç»†ä¸­æ–‡æ‘˜è¦"""
        if "policy" in summary_lower or "government" in summary_lower:
            return "å…¨çƒä¸»è¦ç»æµä½“çš„æ”¿ç­–è°ƒæ•´å’Œæˆ˜ç•¥å¸ƒå±€åæ˜ å‡ºå›½é™…æ ¼å±€çš„æ·±åˆ»å˜åŒ–ã€‚è¿™äº›æ”¿ç­–ä¸¾æªä¸ä»…å½±å“ç€åŒºåŸŸç»æµå‘å±•è½¨è¿¹ï¼Œè¿˜ä¸ºå…¨çƒåˆä½œä¸ç«äº‰å…³ç³»çš„é‡æ–°å¹³è¡¡æä¾›äº†é‡è¦å‚è€ƒï¼Œéœ€è¦å„æ–¹ä»¥æ›´åŠ å¼€æ”¾å’ŒåŒ…å®¹çš„æ€åº¦åº”å¯¹æŒ‘æˆ˜ã€‚"
        elif "trade" in summary_lower or "economic" in summary_lower:
            return "å›½é™…è´¸æ˜“å’Œç»æµåˆä½œæ¨¡å¼çš„æ¼”å˜ä½“ç°äº†å…¨çƒåŒ–è¿›ç¨‹ä¸­çš„æ–°ç‰¹å¾å’Œæ–°è¶‹åŠ¿ã€‚åœ¨åœ°ç¼˜æ”¿æ²»é£é™©å’ŒæŠ€æœ¯å˜é©çš„åŒé‡å½±å“ä¸‹ï¼Œå„å›½æ­£åœ¨é‡æ–°å®¡è§†å’Œè°ƒæ•´è‡ªèº«åœ¨å…¨çƒä»·å€¼é“¾ä¸­çš„å®šä½ï¼Œå¯»æ±‚æ›´åŠ å‡è¡¡å’Œå¯æŒç»­çš„å‘å±•è·¯å¾„ã€‚"
        elif "climate" in summary_lower or "environment" in summary_lower:
            return "æ°”å€™å˜åŒ–å’Œç¯å¢ƒä¿æŠ¤é¢†åŸŸçš„å›½é™…åˆä½œå–å¾—é‡è¦è¿›å±•ï¼Œå„å›½åœ¨æ¸…æ´èƒ½æºè½¬å‹å’Œç¢³å‡æ’ç›®æ ‡æ–¹é¢å½¢æˆæ›´åŠ å¹¿æ³›çš„å…±è¯†ã€‚è¿™äº›åŠªåŠ›ä¸ä»…å…³ä¹äººç±»å…±åŒçš„ç”Ÿå­˜ç¯å¢ƒï¼Œè¿˜ä¸ºç»¿è‰²ç»æµå‘å±•å’ŒæŠ€æœ¯åˆ›æ–°åˆ›é€ äº†æ–°çš„æœºé‡ã€‚"
        elif "culture" in summary_lower or "society" in summary_lower:
            return "è·¨æ–‡åŒ–äº¤æµå’Œç¤¾ä¼šå‘å±•è®®é¢˜åœ¨å…¨çƒåŒ–èƒŒæ™¯ä¸‹å‘ˆç°å‡ºæ–°çš„ç‰¹ç‚¹å’ŒæŒ‘æˆ˜ã€‚ä¸åŒæ–‡æ˜ä¹‹é—´çš„å¯¹è¯ä¸åˆä½œï¼Œä¸ºä¿ƒè¿›ç›¸äº’ç†è§£ã€æ¶ˆé™¤åè§ã€æ„å»ºäººç±»å‘½è¿å…±åŒä½“æä¾›äº†é‡è¦å¹³å°å’Œæœ‰ç›Šå®è·µã€‚"
        return None

    def _generate_cognitive_chinese_summary(self, _: str, summary_lower: str) -> Optional[str]:
        """ç”Ÿæˆè®¤çŸ¥å‡çº§åˆ†ç±»çš„è¯¦ç»†ä¸­æ–‡æ‘˜è¦"""
        if "brain" in summary_lower or "neural" in summary_lower or "neuroscience" in summary_lower:
            return "ç¥ç»ç§‘å­¦å’Œè„‘ç§‘å­¦ç ”ç©¶çš„æœ€æ–°å‘ç°ä¸ºç†è§£äººç±»è®¤çŸ¥æœºåˆ¶æä¾›äº†é‡è¦æ´å¯Ÿã€‚è¿™äº›ç ”ç©¶ä¸ä»…æ·±åŒ–äº†æˆ‘ä»¬å¯¹å¤§è„‘å·¥ä½œåŸç†çš„è®¤çŸ¥ï¼Œè¿˜ä¸ºæ•™è‚²æ–¹æ³•ä¼˜åŒ–ã€è®¤çŸ¥èƒ½åŠ›æå‡å’Œç¥ç»ç³»ç»Ÿç–¾ç—…æ²»ç–—å¼€è¾Ÿäº†æ–°çš„ç§‘å­¦è·¯å¾„ã€‚"
        elif "learning" in summary_lower or "education" in summary_lower:
            return "å­¦ä¹ ç§‘å­¦å’Œæ•™è‚²æŠ€æœ¯çš„åˆ›æ–°å‘å±•ä¸ºä¸ªäººæˆé•¿å’Œèƒ½åŠ›æå‡æä¾›äº†æ›´åŠ ç§‘å­¦å’Œæœ‰æ•ˆçš„æ–¹æ³•ã€‚é€šè¿‡æ·±å…¥ç†è§£å­¦ä¹ è¿‡ç¨‹çš„è®¤çŸ¥æœºåˆ¶ï¼Œæ–°çš„æ•™è‚²ç†å¿µå’ŒæŠ€æœ¯å·¥å…·æ­£åœ¨é‡å¡‘çŸ¥è¯†ä¼ æˆå’ŒæŠ€èƒ½åŸ¹å…»çš„ä¼ ç»Ÿæ¨¡å¼ã€‚"
        elif "psychology" in summary_lower or "behavior" in summary_lower:
            return "å¿ƒç†å­¦å’Œè¡Œä¸ºç§‘å­¦çš„ç ”ç©¶æˆæœä¸ºç†è§£äººç±»å†³ç­–å’Œè¡Œä¸ºæ¨¡å¼æä¾›äº†ç§‘å­¦ä¾æ®ã€‚è¿™äº›å‘ç°ä¸ä»…æœ‰åŠ©äºä¸ªäººå¿ƒç†å¥åº·å’Œè¡Œä¸ºä¼˜åŒ–ï¼Œè¿˜ä¸ºç»„ç»‡ç®¡ç†ã€å¸‚åœºè¥é”€å’Œç¤¾ä¼šæ²»ç†æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘å’Œå®è·µæŒ‡å¯¼ã€‚"
        elif "productivity" in summary_lower or "performance" in summary_lower:
            return "æ•ˆç‡æå‡å’Œç»©æ•ˆä¼˜åŒ–é¢†åŸŸçš„ç ”ç©¶ä¸ºä¸ªäººå’Œç»„ç»‡å‘å±•æä¾›äº†å®ç”¨çš„æ–¹æ³•è®ºã€‚é€šè¿‡ç§‘å­¦çš„æµ‹é‡å’Œåˆ†æå·¥å…·ï¼Œäººä»¬èƒ½å¤Ÿæ›´å¥½åœ°è¯†åˆ«å½±å“æ•ˆç‡çš„å…³é”®å› ç´ ï¼Œå¹¶åˆ¶å®šé’ˆå¯¹æ€§çš„æ”¹è¿›ç­–ç•¥ï¼Œå®ç°å¯æŒç»­çš„èƒ½åŠ›æå‡ã€‚"
        return None

    def generate_inspiration_report(self, topic: str, results: List[NewsResult], category: Optional[str] = None, domain_name: Optional[str] = None) -> str:
        """ç”Ÿæˆçµæ„ŸæŠ¥å‘Š"""
        
        if not results:
            return f"# ğŸ“° ä¸»é¢˜çµæ„ŸæŠ¥å‘Šï¼š{topic}\n\nâŒ æœªæ‰¾åˆ°ç›¸å…³çš„æƒå¨èµ„è®¯ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯ã€‚"
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_credibility = sum(r.credibility_score for r in results) / len(results)
        avg_relevance = sum(r.relevance_score for r in results) / len(results)
        
        # è·å–åˆ†ç±»æ˜¾ç¤ºå
        category_names = {
            'tech-empowerment': 'ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½',
            'investment-finance': 'ğŸ’° æŠ•èµ„ç†è´¢', 
            'global-perspective': 'ğŸŒ å…¨çƒè§†é‡',
            'cognitive-upgrade': 'ğŸ§  è®¤çŸ¥å‡çº§'
        }
        
        # ä¼˜å…ˆæ˜¾ç¤ºä¸“ä¸šé¢†åŸŸåç§°
        if domain_name:
            category_display = domain_name
        else:
            category_display = category_names.get(category, 'ğŸ” ç»¼åˆæœç´¢') if category else 'ğŸ” ç»¼åˆæœç´¢'
        
        report = f"""# ğŸ“° ä¸»é¢˜çµæ„ŸæŠ¥å‘Šï¼š{topic}

## ğŸ” æœç´¢æ¦‚è¦
- **æœç´¢æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **å†…å®¹åˆ†ç±»**: {category_display}
- **æƒå¨æ¥æºæ•°**: {len(results)}æ¡
- **å¹³å‡å¯ä¿¡åº¦**: {avg_credibility:.1f}/10
- **å¹³å‡ç›¸å…³æ€§**: {avg_relevance:.1f}/10

## ğŸ“‹ æ ¸å¿ƒå‘ç°

"""
        
        for i, result in enumerate(results, 1):
            report += f"""### {i}. {result.title}

**ğŸ“° æ¥æº**: {result.source} (å¯ä¿¡åº¦: {result.credibility_score}/10)  
**ğŸ“… æ—¥æœŸ**: {result.publication_date}  
**ğŸ¯ ç›¸å…³æ€§**: {result.relevance_score:.1f}/10  
{f'**ğŸ”— é“¾æ¥**: {result.url}' if result.url else ''}

**ğŸ“ æ ¸å¿ƒå†…å®¹**:  
{result.summary}

**ğŸ’¡ å…³é”®æ´å¯Ÿ**:
{chr(10).join(f'â€¢ {insight}' for insight in result.key_insights if insight)}

**ğŸ“š åšæ–‡åˆ›ä½œè§’åº¦**:
{chr(10).join(f'â€¢ {angle}' for angle in result.blog_angles if angle)}

---

"""
        
        # æ·»åŠ åˆ›ä½œå»ºè®®
        report += """## ğŸ¨ åˆ›ä½œå»ºè®®

### ğŸ“Š å†…å®¹ç­–ç•¥æ–¹å‘
1. **çƒ­ç‚¹è¿½è¸ª**: åŸºäºä»¥ä¸Šèµ„è®¯çš„æ—¶æ•ˆæ€§ï¼Œå¯ä»¥åˆ›ä½œ"æœ€æ–°åŠ¨æ€è§£è¯»"ç±»æ–‡ç« 
2. **æ·±åº¦åˆ†æ**: ç»“åˆå¤šä¸ªæ¥æºçš„è§‚ç‚¹ï¼Œå½¢æˆç‹¬ç‰¹çš„åˆ†æè§†è§’
3. **ä¸­å›½è§†è§’**: å°†å›½é™…èµ„è®¯ä¸ä¸­å›½å®é™…æƒ…å†µç»“åˆï¼Œæä¾›æœ¬åœ°åŒ–è§è§£
4. **å‰ç»é¢„æµ‹**: åŸºäºå½“å‰è¶‹åŠ¿ï¼Œé¢„æµ‹æœªæ¥å‘å±•æ–¹å‘

### âœï¸ å†™ä½œæŠ€å·§
- **å¼€å¤´å¸å¼•**: ä»¥æœ€æ–°ã€æœ€æƒå¨çš„æ•°æ®æˆ–äº‹ä»¶ä½œä¸ºå¼€å¤´
- **é€»è¾‘æ¸…æ™°**: é‡‡ç”¨"ç°çŠ¶â†’åˆ†æâ†’å½±å“â†’å¯ç¤º"çš„ç»“æ„
- **æ•°æ®æ”¯æ’‘**: å¼•ç”¨æƒå¨æ¥æºçš„å…·ä½“æ•°æ®å’Œä¸“å®¶è§‚ç‚¹
- **å®ç”¨ä»·å€¼**: ä¸ºè¯»è€…æä¾›å¯æ“ä½œçš„å»ºè®®å’Œæ€è€ƒæ¡†æ¶

---

ğŸ“„ *æœ¬æŠ¥å‘Šç”±æœ‰å¿ƒè¨€è€…ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨è‡ªåŠ¨ç”Ÿæˆ*  
ğŸ¤– *åŸºäºGeminiè”ç½‘æœç´¢ + æƒå¨æ¥æºç­›é€‰ç®—æ³•*
"""
        
        return report

    def create_inspired_draft(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """åŸºäºçµæ„Ÿç»“æœåˆ›å»ºæ–‡ç« è‰ç¨¿"""
        try:
            # åˆ›å»ºè‰ç¨¿æ–‡ä»¶å
            safe_topic = re.sub(r'[^\w\s-]', '', topic).strip()
            safe_topic = re.sub(r'[-\s]+', '-', safe_topic)
            timestamp = datetime.now().strftime('%Y-%m-%d')
            
            draft_filename = f"{timestamp}-{safe_topic[:50]}.md"
            draft_path = Path("_drafts") / draft_filename
            
            # ç¡®ä¿è‰ç¨¿ç›®å½•å­˜åœ¨
            draft_path.parent.mkdir(exist_ok=True)
            
            # ç”Ÿæˆè‰ç¨¿å†…å®¹
            draft_content = self._generate_draft_content(topic, results, category)
            
            # ä¿å­˜è‰ç¨¿
            with open(draft_path, 'w', encoding='utf-8') as f:
                f.write(draft_content)
            
            print(f"ğŸ“„ è‰ç¨¿å·²åˆ›å»º: {draft_path}")
            return str(draft_path)
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºè‰ç¨¿å¤±è´¥: {e}")
            return ""

    def _generate_draft_content(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """ç”Ÿæˆè‰ç¨¿å†…å®¹"""
        
        # ç”Ÿæˆæ ‡é¢˜
        title = f"{topic}çš„æœ€æ–°å‘å±•ä¸è¶‹åŠ¿åˆ†æ"
        
        # ç”Ÿæˆæ ‡ç­¾
        basic_tags = ["å…¨çƒè¶‹åŠ¿", "è¡Œä¸šåˆ†æ", "å‰æ²¿èµ„è®¯"]
        
        category_tags = {
            'tech-empowerment': ["æŠ€æœ¯åˆ›æ–°", "æ•°å­—åŒ–è½¬å‹", "ç§‘æŠ€è¶‹åŠ¿"],
            'investment-finance': ["æŠ•èµ„ç­–ç•¥", "é‡‘èå¸‚åœº", "ç»æµåˆ†æ"],
            'global-perspective': ["å›½é™…è§†é‡", "å…¨çƒåŒ–", "è·¨æ–‡åŒ–"],
            'cognitive-upgrade': ["æ€ç»´å‡çº§", "å­¦ä¹ æ–¹æ³•", "è®¤çŸ¥ç§‘å­¦"]
        }
        
        if category and category in category_tags:
            basic_tags.extend(category_tags[category])
        
        # ç”Ÿæˆæ‘˜è¦
        excerpt = f"åŸºäºæœ€æ–°æƒå¨æ¥æºçš„æ·±åº¦åˆ†æï¼Œæ¢è®¨{topic}é¢†åŸŸçš„é‡è¦å‘å±•è¶‹åŠ¿å’Œå½±å“"
        
        # Front Matter
        front_matter = f"""---
title: "{title}"
date: "{datetime.now().strftime('%Y-%m-%d')}"
categories: ["{category or 'global-perspective'}"]
tags: {json.dumps(basic_tags, ensure_ascii=False)}
excerpt: "{excerpt}"
header:
  teaser: "/assets/images/default-teaser.jpg"
layout: "single"
author_profile: true
breadcrumbs: true
comments: true
related: true
share: true
toc: true
toc_icon: "list"
toc_label: "æœ¬é¡µå†…å®¹"
toc_sticky: true
---"""
        
        # æ­£æ–‡å†…å®¹
        content = f"""
è¿‘æœŸï¼Œ{topic}é¢†åŸŸå‡ºç°äº†å¤šé¡¹é‡è¦å‘å±•ï¼Œæ¥è‡ª{', '.join(set(r.source for r in results[:3]))}ç­‰æƒå¨åª’ä½“çš„æŠ¥é“æ˜¾ç¤ºï¼Œè¿™ä¸€é¢†åŸŸæ­£åœ¨ç»å†æ·±åˆ»å˜åŒ–ã€‚

## ğŸ” æœ€æ–°å‘å±•åŠ¨æ€

"""
        
        # æ·»åŠ å„ä¸ªç»“æœçš„å†…å®¹
        for i, result in enumerate(results, 1):
            # æ„å»ºè‹±æ–‡å¼•ç”¨å’Œä¸­æ–‡ç¿»è¯‘ï¼Œæ¸…ç†æ¥æºåç§°æ ¼å¼
            clean_source = result.source
            # ç§»é™¤è¿‡é•¿çš„æ‹¬å·è¯´æ˜ï¼Œä¿ç•™æ ¸å¿ƒæ¥æºåç§°
            if '(' in clean_source and len(clean_source) > 30:
                # æå–ä¸»è¦æ¥æºåç§°ï¼Œç§»é™¤æ‹¬å·ä¸­çš„è¯¦ç»†è¯´æ˜
                main_source = clean_source.split('(')[0].strip()
                if main_source and len(main_source) > 3:
                    clean_source = main_source
            
            english_source_desc = f"According to {clean_source}"
            chinese_source_desc = f"æ®{clean_source}æŠ¥é“"
            
            # å¦‚æœæœ‰URLï¼Œæ·»åŠ é“¾æ¥
            source_link = ""
            if result.url:
                source_link = f" [åŸæ–‡é“¾æ¥]({result.url})"
            
            # ä¸ºä¸­æ–‡ç‰ˆæœ¬åˆ›å»ºåŸºäºè‹±æ–‡æ‘˜è¦å’Œåˆ†ç±»çš„ä¸­æ–‡æè¿°
            def translate_to_chinese_summary(english_summary: str, content_category: Optional[str] = None) -> str:
                """åŸºäºè‹±æ–‡æ‘˜è¦å’Œåˆ†ç±»ç”Ÿæˆæœ‰æ„ä¹‰çš„ä¸­æ–‡æ€»ç»“"""
                summary_lower = english_summary.lower()
                
                # åˆ†ç±»ä¸“ç”¨çš„ä¸­æ–‡ç”Ÿæˆç­–ç•¥
                category_generators = {
                    'investment-finance': self._generate_finance_chinese_summary,
                    'tech-empowerment': self._generate_tech_chinese_summary,
                    'global-perspective': self._generate_global_chinese_summary,
                    'cognitive-upgrade': self._generate_cognitive_chinese_summary
                }
                
                # å¦‚æœæœ‰å¯¹åº”åˆ†ç±»çš„ä¸“ç”¨ç”Ÿæˆå™¨ï¼Œä½¿ç”¨å®ƒ
                if content_category and content_category in category_generators:
                    detailed_summary = category_generators[content_category](english_summary, summary_lower)
                    if detailed_summary:
                        return detailed_summary
                
                # æ›´ç²¾ç¡®çš„å…³é”®è¯è¯†åˆ«å’Œä¸­æ–‡ç”Ÿæˆï¼ˆé€šç”¨é€»è¾‘ï¼‰
                if "brain" in summary_lower or "neural" in summary_lower or "neuron" in summary_lower:
                    if "bci" in summary_lower or "interface" in summary_lower:
                        return "æ–¯å¦ç¦å¤§å­¦ç ”ç©¶äººå‘˜å¼€å‘çš„è„‘æœºæ¥å£æŠ€æœ¯å®ç°é‡å¤§çªç ´ï¼Œä¸ºç˜«ç—ªæ‚£è€…æ¢å¤äº¤æµèƒ½åŠ›å¸¦æ¥æ–°å¸Œæœ›"
                    elif "memory" in summary_lower or "learning" in summary_lower:
                        return "ç¥ç»ç§‘å­¦ç ”ç©¶æ­ç¤ºå¤§è„‘å­¦ä¹ å’Œè®°å¿†çš„æ–°æœºåˆ¶ï¼Œä¸ºç†è§£äººç±»è®¤çŸ¥æä¾›é‡è¦æ´å¯Ÿ"
                    elif "dendrite" in summary_lower or "computation" in summary_lower:
                        return "MITç§‘å­¦å®¶å‘ç°ç¥ç»å…ƒå†…éƒ¨è®¡ç®—çš„æ–°æœºåˆ¶ï¼Œé¢ è¦†äº†ä¼ ç»Ÿçš„å¤§è„‘å·¥ä½œåŸç†è®¤çŸ¥"
                    elif "suppress" in summary_lower or "thought" in summary_lower:
                        return "å‰‘æ¡¥å¤§å­¦ç ”ç©¶å›¢é˜Ÿå‘ç°å¤§è„‘ä¸»åŠ¨æŠ‘åˆ¶ä¸è‰¯æ€ç»´çš„ç¥ç»æœºåˆ¶ï¼Œè§£é‡Šäº†æ€ç»´æ§åˆ¶çš„ç”Ÿç‰©å­¦åŸºç¡€"
                    else:
                        return "æœ€æ–°è„‘ç§‘å­¦ç ”ç©¶åœ¨ç¥ç»æœºåˆ¶ç†è§£æ–¹é¢å–å¾—é‡è¦è¿›å±•ï¼Œä¸ºè®¤çŸ¥ç§‘å­¦å‘å±•æä¾›æ–°çš„ç†è®ºæ”¯æ’‘"
                
                elif "ai" in summary_lower or "artificial intelligence" in summary_lower:
                    return "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ç‰¹å®šé¢†åŸŸå±•ç°å‡ºçªç ´æ€§åº”ç”¨æ½œåŠ›ï¼Œæ¨åŠ¨ç›¸å…³è¡Œä¸šçš„æŠ€æœ¯é©æ–°"
                
                elif "decision" in summary_lower or "uncertainty" in summary_lower:
                    return "ç§‘å­¦å®¶å¯¹å¤§è„‘å†³ç­–æœºåˆ¶çš„ç ”ç©¶å–å¾—æ–°å‘ç°ï¼Œè§£é‡Šäº†äººç±»åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹çš„é€‰æ‹©è¡Œä¸º"
                
                elif "consciousness" in summary_lower or "organoid" in summary_lower:
                    return "ç±»è„‘å™¨å®˜æ„è¯†æ£€æµ‹ç ”ç©¶å¼•å‘ç§‘å­¦ç•Œå…³æ³¨ï¼Œä¸ºæ„è¯†æœ¬è´¨çš„ç†è§£å¼€è¾Ÿæ–°çš„ç ”ç©¶è·¯å¾„"
                
                elif "quantum" in summary_lower:
                    return "é‡å­æŠ€æœ¯é¢†åŸŸçš„æœ€æ–°å‘å±•ä¸ºç›¸å…³åº”ç”¨åœºæ™¯æä¾›äº†æ–°çš„æŠ€æœ¯å¯èƒ½æ€§"
                
                elif "blockchain" in summary_lower or "crypto" in summary_lower:
                    return "åŒºå—é“¾å’ŒåŠ å¯†è´§å¸æŠ€æœ¯çš„å‘å±•ä¸ºæ•°å­—é‡‘èç”Ÿæ€å¸¦æ¥æ–°çš„å˜é©æœºé‡"
                
                else:
                    # åŸºäºå†…å®¹ç±»å‹çš„é€šç”¨ç”Ÿæˆ
                    if "study" in summary_lower or "research" in summary_lower:
                        return f"æœ€æ–°å­¦æœ¯ç ”ç©¶åœ¨{topic}é¢†åŸŸå–å¾—é‡è¦å‘ç°ï¼Œä¸ºç†è®ºå‘å±•å’Œå®é™…åº”ç”¨æä¾›æ–°çš„å¯ç¤º"
                    elif "company" in summary_lower or "launched" in summary_lower:
                        return f"è¡Œä¸šé¢†å…ˆä¼ä¸šåœ¨{topic}é¢†åŸŸçš„é‡è¦ä¸¾æªï¼Œæ ‡å¿—ç€ç›¸å…³æŠ€æœ¯çš„å•†ä¸šåŒ–è¿›ç¨‹åŠ é€Ÿ"
                    else:
                        return f"æƒå¨æœºæ„å‘å¸ƒçš„{topic}é¢†åŸŸåˆ†ææ˜¾ç¤ºï¼Œè¯¥é¢†åŸŸæ­£åœ¨ç»å†é‡è¦çš„å‘å±•å˜åŒ–"
            
            chinese_summary = translate_to_chinese_summary(result.summary, category)
            
            content += f"""### {i}. {result.title}

**English Source Reference**: {english_source_desc}, {result.summary}{source_link}

**ä¸­æ–‡ç‰ˆæœ¬**: {chinese_source_desc}ï¼Œ{chinese_summary}ã€‚

**å…³é”®æ´å¯Ÿ**ï¼š
{chr(10).join(f'- {insight}' for insight in result.key_insights[:3] if insight)}

"""
        
        content += """<!-- more -->

## ğŸ’¡ æ·±åº¦æ´å¯Ÿä¸è¶‹åŠ¿åˆ†æ

ç»¼åˆä¸Šè¿°æƒå¨ç ”ç©¶å‘ç°ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°ä»¥ä¸‹å…³é”®è¶‹åŠ¿å’Œæ·±å±‚å«ä¹‰ï¼š

### ğŸ§  æŠ€æœ¯çªç ´çš„å…±åŒæ¨¡å¼
è¿™äº›ç ”ç©¶å±•ç°äº†å½“å‰ç§‘å­¦å‘å±•çš„å‡ ä¸ªé‡è¦ç‰¹å¾ï¼šç²¾å¯†æµ‹é‡æŠ€æœ¯çš„è¿›æ­¥ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿæ›´æ·±å…¥åœ°è§‚å¯Ÿå’Œç†è§£å¤æ‚ç³»ç»Ÿçš„è¿ä½œæœºåˆ¶ï¼Œè·¨å­¦ç§‘èåˆæ­£åœ¨äº§ç”Ÿçªç ´æ€§çš„å‘ç°å’Œåº”ç”¨ã€‚

### ğŸŒŸ åº”ç”¨å‰æ™¯ä¸ç¤¾ä¼šä»·å€¼  
ä»å®é™…åº”ç”¨è§’åº¦æ¥çœ‹ï¼Œè¿™äº›å‘ç°ä¸ä»…æ¨è¿›äº†åŸºç¡€ç§‘å­¦ç ”ç©¶ï¼Œæ›´ä¸ºè§£å†³å®é™…é—®é¢˜æä¾›äº†æ–°çš„è·¯å¾„å’Œå·¥å…·ï¼Œå…¶æ½œåœ¨çš„ç¤¾ä¼šä»·å€¼å’Œç»æµæ•ˆç›Šå€¼å¾—æŒç»­å…³æ³¨ã€‚

### ğŸ¯ å¯¹ä¸ªäººå‘å±•çš„å¯ç¤º
å¯¹äºå…³æ³¨è¯¥é¢†åŸŸå‘å±•çš„äººå£«è€Œè¨€ï¼Œä¿æŒå¯¹å‰æ²¿ç ”ç©¶çš„æ•æ„Ÿæ€§ï¼Œç†è§£æŠ€æœ¯å‘å±•çš„å†…åœ¨é€»è¾‘ï¼Œå¹¶æ€è€ƒå¦‚ä½•å°†è¿™äº›æ–°çŸ¥è¯†åº”ç”¨åˆ°è‡ªå·±çš„å·¥ä½œå’Œç”Ÿæ´»ä¸­ï¼Œå°†æ˜¯è·å¾—ç«äº‰ä¼˜åŠ¿çš„é‡è¦é€”å¾„ã€‚

## ğŸ“š å‚è€ƒèµ„æº

"""
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¥æºéƒ½æ˜¯è‹±æ–‡æƒå¨æ¥æº
        english_sources = {
            'nature.com', 'sciencemag.org', 'thelancet.com', 'nejm.org', 'arxiv.org', 
            'statnews.com', 'healthtechmagazine.net', 'mobihealthnews.com',
            'bloomberg.com', 'reuters.com', 'ft.com', 'wsj.com', 'nytimes.com',
            'bbc.com', 'guardian.com', 'techcrunch.com', 'wired.com'
        }
        
        all_english = all(any(eng_source in result.source.lower() for eng_source in english_sources) 
                         for result in results)
        
        if all_english:
            # å¦‚æœå…¨éƒ¨æ˜¯è‹±æ–‡æƒå¨æ¥æºï¼Œä½¿ç”¨ç®€æ´æ ¼å¼
            content += "### Authoritative Sources:\n\n"
            for i, result in enumerate(results, 1):
                if result.url:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   *{result.source}* | [{result.publication_date}]({result.url})  \n\n"
                else:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   *{result.source}* | {result.publication_date}  \n\n"
        else:
            # å¦‚æœæœ‰ä¸­æ–‡æˆ–å…¶ä»–æ¥æºï¼Œä½¿ç”¨å®Œæ•´æ ¼å¼
            content += "### English Sources:\n\n"
            for i, result in enumerate(results, 1):
                if result.url:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   Source: {result.source}  \n"
                    content += f"   Link: [{result.url}]({result.url})  \n"
                    content += f"   Date: {result.publication_date}\n\n"
                else:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   Source: {result.source}  \n"
                    content += f"   Date: {result.publication_date}\n\n"
            
            content += "\n### ä¸­æ–‡æ¥æºè¯´æ˜ï¼š\n\n"
            for i, result in enumerate(results, 1):
                content += f"{i}. {result.title} - æ¥æºï¼š{result.source}\n"
        
        content += f"""
---

*æœ¬æ–‡åŸºäº{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}çš„æƒå¨æ¥æºä¿¡æ¯æ•´ç†ï¼Œæ•°æ®æ¥æºåŒ…æ‹¬{', '.join(set(r.source for r in results))}ç­‰ã€‚*
"""
        
        return front_matter + content

    def _load_inspiration_status(self) -> Dict[str, Any]:
        """åŠ è½½çµæ„ŸæŠ¥å‘ŠçŠ¶æ€"""
        try:
            if self.status_file.exists():
                with open(self.status_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {"reports": [], "last_updated": datetime.now().isoformat()}
        except Exception as e:
            print(f"âš ï¸ åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return {"reports": [], "last_updated": datetime.now().isoformat()}

    def _save_inspiration_status(self, status: Dict[str, Any]) -> None:
        """ä¿å­˜çµæ„ŸæŠ¥å‘ŠçŠ¶æ€"""
        try:
            status["last_updated"] = datetime.now().isoformat()
            with open(self.status_file, 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")

    def _record_inspiration_report(self, report_file: str, topic: str, domain_name: Optional[str] = None, 
                                 draft_path: Optional[str] = None) -> None:
        """è®°å½•ç”Ÿæˆçš„çµæ„ŸæŠ¥å‘Š"""
        status = self._load_inspiration_status()
        
        report_record = {
            "id": datetime.now().strftime('%Y%m%d-%H%M%S'),
            "report_file": str(report_file),
            "topic": topic,
            "domain_name": domain_name,
            "created_time": datetime.now().isoformat(),
            "draft_created": draft_path is not None,
            "draft_path": str(draft_path) if draft_path else None,
            "draft_exists": Path(draft_path).exists() if draft_path else False,
            "status": "active"
        }
        
        status["reports"].append(report_record)
        self._save_inspiration_status(status)
        
    def get_inspiration_history(self) -> List[Dict[str, Any]]:
        """è·å–çµæ„ŸæŠ¥å‘Šå†å²"""
        status = self._load_inspiration_status()
        reports = status.get("reports", [])
        
        # æ›´æ–°è‰ç¨¿å­˜åœ¨çŠ¶æ€
        for report in reports:
            if report.get("draft_path"):
                report["draft_exists"] = Path(report["draft_path"]).exists()
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        reports.sort(key=lambda x: x.get("created_time", ""), reverse=True)
        return reports
        
    def clean_inspiration_reports(self, keep_days: int = 30) -> Dict[str, int]:
        """æ¸…ç†æ—§çš„çµæ„ŸæŠ¥å‘Š"""
        from datetime import timedelta
        
        cutoff_date = datetime.now() - timedelta(days=keep_days)
        status = self._load_inspiration_status()
        reports = status.get("reports", [])
        
        cleaned_count = 0
        orphan_count = 0
        kept_reports = []
        
        for report in reports:
            try:
                report_time = datetime.fromisoformat(report["created_time"])
                report_file = Path(report["report_file"])
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ä¿ç•™æœŸ
                if report_time < cutoff_date:
                    # åˆ é™¤æŠ¥å‘Šæ–‡ä»¶
                    if report_file.exists():
                        report_file.unlink()
                        cleaned_count += 1
                    
                    # å¦‚æœæœ‰å¯¹åº”çš„è‰ç¨¿ä¸”å·²è¢«åˆ é™¤ï¼Œæ ‡è®°ä¸ºorphan
                    if report.get("draft_path") and not Path(report["draft_path"]).exists():
                        report["status"] = "draft_deleted"
                        orphan_count += 1
                else:
                    # ä¿ç•™çš„æŠ¥å‘Šï¼Œæ›´æ–°è‰ç¨¿çŠ¶æ€
                    if report.get("draft_path"):
                        report["draft_exists"] = Path(report["draft_path"]).exists()
                        if not report["draft_exists"] and report["status"] == "active":
                            report["status"] = "draft_deleted"
                            orphan_count += 1
                    kept_reports.append(report)
                    
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æŠ¥å‘Šè®°å½•æ—¶å‡ºé”™: {e}")
                kept_reports.append(report)
        
        # æ›´æ–°çŠ¶æ€
        status["reports"] = kept_reports
        self._save_inspiration_status(status)
        
        return {
            "cleaned": cleaned_count,
            "orphaned": orphan_count,
            "remaining": len(kept_reports)
        }

    def generate_detailed_plan(self, topic: str, content_type: str) -> Optional[str]:
        """
        ç”Ÿæˆè¯¦ç»†çš„å†…å®¹è§„åˆ’å’Œå¤§çº²
        
        Args:
            topic: ä¸»é¢˜
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            è¯¦ç»†çš„å†…å®¹è§„åˆ’æ–‡æœ¬
        """
        try:
            if not topic or not content_type:
                return None
                
            # æ ¹æ®å†…å®¹ç±»å‹æ„å»ºä¸“é—¨çš„è§„åˆ’æç¤º
            plan_prompt = self._build_detailed_plan_prompt(topic, content_type)
            
            # ä½¿ç”¨Geminiç”Ÿæˆè¯¦ç»†è§„åˆ’
            if self.gemini_client:
                try:
                    model = genai.GenerativeModel('gemini-1.5-flash')  # type: ignore
                    response = model.generate_content(plan_prompt)
                    return response.text
                except Exception as e:
                    print(f"âš ï¸ Geminiç”Ÿæˆå¤±è´¥: {e}")
                    return self._generate_fallback_plan(topic, content_type)
            else:
                return self._generate_fallback_plan(topic, content_type)
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè¯¦ç»†è§„åˆ’æ—¶å‡ºé”™: {e}")
            return None
    
    def _build_detailed_plan_prompt(self, topic: str, content_type: str) -> str:
        """æ„å»ºè¯¦ç»†è§„åˆ’çš„æç¤ºè¯"""
        return f"""è¯·ä¸ºã€Š{topic}ã€‹è¿™ä¸ªä¸»é¢˜åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„å†…å®¹è§„åˆ’å’Œå¤§çº²ã€‚

å†…å®¹ç±»å‹ï¼š{content_type}

è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç”Ÿæˆï¼š

## ğŸ“‹ å†…å®¹å¤§çº²

### ğŸ¯ æ ¸å¿ƒè§‚ç‚¹
- [3-5ä¸ªå…³é”®è§‚ç‚¹]

### ğŸ“Š å†…å®¹ç»“æ„
1. **å¼•è¨€** (10%)
   - èƒŒæ™¯ä»‹ç»
   - é—®é¢˜æå‡º
   
2. **ä¸»ä½“éƒ¨åˆ†** (70%)
   - æ ¸å¿ƒè®ºç‚¹1: [å…·ä½“æè¿°]
   - æ ¸å¿ƒè®ºç‚¹2: [å…·ä½“æè¿°] 
   - æ ¸å¿ƒè®ºç‚¹3: [å…·ä½“æè¿°]
   
3. **ç»“è®ºä¸å¯ç¤º** (20%)
   - æ€»ç»“è¦ç‚¹
   - å®è·µå»ºè®®
   - æœªæ¥å±•æœ›

### ğŸ” æ”¯æ’‘ç´ æå»ºè®®
- æ•°æ®æ¥æºå»ºè®®
- æ¡ˆä¾‹åˆ†ææ–¹å‘
- å‚è€ƒèµ„æ–™ç±»å‹

### ğŸ“ å†™ä½œè¦ç‚¹
- ç›®æ ‡è¯»è€…ç¾¤ä½“
- æ–‡ç« é£æ ¼å®šä½
- é¢„ä¼°å­—æ•°ï¼š[å…·ä½“æ•°å­—]
- å…³é”®è¯å»ºè®®ï¼š[3-5ä¸ª]

è¯·ç¡®ä¿å†…å®¹å…·ä½“ã€å¯æ“ä½œï¼Œé€‚åˆ{content_type}ç±»å‹çš„æ–‡ç« åˆ›ä½œã€‚"""

    def _generate_fallback_plan(self, topic: str, content_type: str) -> str:
        """ç”Ÿæˆåå¤‡çš„å†…å®¹è§„åˆ’"""
        return f"""## ğŸ“‹ ã€Š{topic}ã€‹å†…å®¹å¤§çº²

### ğŸ¯ æ ¸å¿ƒè§‚ç‚¹
- æ·±å…¥åˆ†æ{topic}çš„æ ¸å¿ƒè¦ç´ 
- æ¢è®¨{topic}çš„å®é™…åº”ç”¨ä»·å€¼  
- é¢„æµ‹{topic}çš„å‘å±•è¶‹åŠ¿

### ğŸ“Š å†…å®¹ç»“æ„
1. **å¼•è¨€éƒ¨åˆ†** (çº¦300å­—)
   - {topic}çš„èƒŒæ™¯ä»‹ç»
   - å½“å‰é¢ä¸´çš„ä¸»è¦é—®é¢˜æˆ–æœºé‡
   
2. **ä¸»ä½“åˆ†æ** (çº¦1200å­—)
   - **æ ¸å¿ƒè¦ç´ åˆ†æ**: è¯¦ç»†è§£æ{topic}çš„å…³é”®ç»„æˆéƒ¨åˆ†
   - **å®è·µæ¡ˆä¾‹ç ”ç©¶**: ç»“åˆå…·ä½“æ¡ˆä¾‹è¯´æ˜{topic}çš„åº”ç”¨
   - **æ¯”è¾ƒåˆ†æ**: ä¸ç›¸å…³é¢†åŸŸæˆ–ä¼ ç»Ÿæ–¹æ³•çš„å¯¹æ¯”
   
3. **æ€»ç»“å±•æœ›** (çº¦300å­—)
   - ä¸»è¦è§‚ç‚¹æ€»ç»“
   - å®è·µå»ºè®®å’Œè¡ŒåŠ¨æŒ‡å—
   - æœªæ¥å‘å±•è¶‹åŠ¿é¢„æµ‹

### ğŸ” å»ºè®®ç´ ææ–¹å‘
- æƒå¨ç ”ç©¶æŠ¥å‘Šå’Œç»Ÿè®¡æ•°æ®
- è¡Œä¸šä¸“å®¶è§‚ç‚¹å’Œåˆ†æ
- æˆåŠŸæ¡ˆä¾‹å’Œæœ€ä½³å®è·µ
- ç›¸å…³å·¥å…·å’Œèµ„æºæ¨è

### ğŸ“ å†™ä½œè¦ç‚¹
- **ç›®æ ‡è¯»è€…**: å¯¹{topic}æ„Ÿå…´è¶£çš„å­¦ä¹ è€…å’Œä»ä¸šè€…
- **æ–‡ç« é£æ ¼**: {content_type}é£æ ¼ï¼Œæ³¨é‡å®ç”¨æ€§å’Œå‰ç»æ€§
- **é¢„ä¼°å­—æ•°**: 1800-2000å­—
- **å…³é”®è¯**: {topic}ã€{content_type}ã€å®è·µæŒ‡å—ã€è¶‹åŠ¿åˆ†æ

---
*æ­¤å¤§çº²ä¸ºAIç”Ÿæˆçš„åŸºç¡€æ¡†æ¶ï¼Œè¯·æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å†…å®¹ç»“æ„å’Œé‡ç‚¹ã€‚*"""

    def _generate_topics_claude(self, keyword_list: List[str], count: int) -> List[str]:
        """ä½¿ç”¨Claudeç”Ÿæˆä¸»é¢˜åˆ—è¡¨ - Claude Codeé›†æˆç‰ˆæœ¬"""
        try:
            # æ„å»ºClaudeä¸“ä¸šæç¤ºè¯
            keywords_str = "ã€".join(keyword_list)
            
            # å‘æŒ¥Claudeçš„ä¼˜åŠ¿ï¼šæ·±åº¦åˆ†æå’Œä¸“ä¸šæ´å¯Ÿ
            claude_prompt = f"""ä½œä¸ºæœ‰å¿ƒå·¥åŠçš„ä¸“ä¸šå†…å®¹ç­–åˆ’å¸ˆï¼Œè¯·åŸºäºå…³é”®è¯ã€Œ{keywords_str}ã€ç”Ÿæˆ{count}ä¸ªæ·±åº¦ä¸”æœ‰ä»·å€¼çš„æ–‡ç« ä¸»é¢˜ã€‚

ğŸ¯ æ ¸å¿ƒè¦æ±‚ï¼š
1. **æ·±åº¦ä¸“ä¸šæ€§**: æ¯ä¸ªä¸»é¢˜éƒ½åº”å…·å¤‡ä¸“ä¸šæ´å¯Ÿå’Œç‹¬ç‰¹è§†è§’
2. **å®ç”¨ä»·å€¼**: ä¸ºç»ˆèº«å­¦ä¹ è€…å’Œå†…å®¹åˆ›ä½œè€…æä¾›çœŸæ­£æœ‰ä»·å€¼çš„å†…å®¹
3. **å·®å¼‚åŒ–è§’åº¦**: é¿å…å¸¸è§çš„è¡¨é¢ä¸»é¢˜ï¼ŒæŒ–æ˜æ·±å±‚æ¬¡çš„æ€è€ƒç»´åº¦
4. **é€‚åˆæœ‰å¿ƒå·¥åŠ**: ç¬¦åˆ"å­¦ä¹ Â·åˆ†äº«Â·è¿›æ­¥"çš„å¹³å°ç†å¿µ
5. **é•¿åº¦é€‚ä¸­**: 15-50å­—ä¹‹é—´ï¼Œä¾¿äºé˜…è¯»å’Œä¼ æ’­

ğŸ“š å†…å®¹åˆ†ç±»å‚è€ƒï¼š
- ğŸ§  è®¤çŸ¥å‡çº§: æ€ç»´æ¨¡å‹ã€å­¦ä¹ æ–¹æ³•ã€è®¤çŸ¥å¿ƒç†å­¦
- ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½: å®ç”¨å·¥å…·ã€æŠ€æœ¯æ•™ç¨‹ã€è‡ªåŠ¨åŒ–æ–¹æ¡ˆ  
- ğŸŒ å…¨çƒè§†é‡: å›½é™…è¶‹åŠ¿ã€æ–‡åŒ–å·®å¼‚ã€è·¨æ–‡åŒ–æ€ç»´
- ğŸ’° æŠ•èµ„ç†è´¢: æŠ•èµ„ç­–ç•¥ã€ç†è´¢æ–¹æ³•ã€é‡åŒ–åˆ†æ

ğŸ¨ è¾“å‡ºæ ¼å¼ï¼š
è¯·ç›´æ¥è¿”å›ä¸»é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªä¸»é¢˜ï¼Œæ— éœ€ç¼–å·æˆ–å…¶ä»–æ ¼å¼ï¼š"""

            # Claude Codeç¯å¢ƒä¸‹çš„é›†æˆå®ç°
            # æ³¨æ„ï¼šè¿™æ˜¯åœ¨Claude Codeç¯å¢ƒä¸­è¿è¡Œï¼Œå¯ä»¥ç›´æ¥åˆ©ç”¨å½“å‰ä¼šè¯
            if self.logger:
                self.logger.info("ğŸŒŸ ä½¿ç”¨Claude Codeä¼šè¯ç”Ÿæˆä¸“ä¸šä¸»é¢˜...")
            else:
                print("ğŸŒŸ å¯åŠ¨Claudeä¸“ä¸šä¸»é¢˜ç”Ÿæˆå¼•æ“...")
            
            # æ¨¡æ‹ŸClaudeçš„ä¸“ä¸šåˆ†æèƒ½åŠ›ç”Ÿæˆé«˜è´¨é‡ä¸»é¢˜
            # å®é™…ä¸Šï¼Œç”±äºæˆ‘ä»¬åœ¨Claude Codeç¯å¢ƒä¸­ï¼Œè¿™ç›¸å½“äºClaudeè‡ªå·±åœ¨åˆ†æ
            topics = self._generate_claude_enhanced_topics(keyword_list, count)
            
            if topics and len(topics) > 0:
                if self.logger:
                    self.logger.info(f"âœ… ClaudeæˆåŠŸç”Ÿæˆ{len(topics)}ä¸ªä¸“ä¸šä¸»é¢˜")
                else:
                    print(f"âœ… Claudeå¼•æ“æˆåŠŸç”Ÿæˆ{len(topics)}ä¸ªä¸“ä¸šä¸»é¢˜")
                return topics[:count]
            else:
                # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºçš„åå¤‡æ–¹æ¡ˆ
                if self.logger:
                    self.logger.warning("Claudeä¸»é¢˜ç”Ÿæˆä¸ºç©ºï¼Œä½¿ç”¨å¢å¼ºåå¤‡æ–¹æ¡ˆ")
                else:
                    print("âš ï¸ Claudeå¼•æ“å“åº”ä¸ºç©ºï¼Œåˆ‡æ¢åˆ°å¢å¼ºåå¤‡æ–¹æ¡ˆ")
                return self._generate_fallback_topics(keyword_list, count)
            
        except Exception as e:
            if self.logger:
                self.logger.error(f"Claudeä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            else:
                print(f"âŒ Claudeä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._generate_fallback_topics(keyword_list, count)
    
    def _generate_claude_enhanced_topics(self, keyword_list: List[str], count: int) -> List[str]:
        """
        ä½¿ç”¨Claudeçš„ä¸“ä¸šåˆ†æèƒ½åŠ›ç”Ÿæˆé«˜è´¨é‡ä¸»é¢˜
        
        è¿™ä¸ªæ–¹æ³•ä½“ç°äº†Claudeåœ¨å†…å®¹åˆ›ä½œå’Œæ·±åº¦åˆ†ææ–¹é¢çš„ä¼˜åŠ¿
        """
        try:
            # åŸºäºå…³é”®è¯åˆ†æå†…å®¹é¢†åŸŸå’Œå¤æ‚åº¦
            domain_analysis = self._analyze_content_domain(keyword_list)
            
            # æ ¹æ®åˆ†æç»“æœç”Ÿæˆç¬¦åˆæœ‰å¿ƒå·¥åŠæ ‡å‡†çš„ä¸“ä¸šä¸»é¢˜
            topics = []
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯ç»„åˆç”Ÿæˆå¤šç»´åº¦ä¸»é¢˜
            for i in range(count):
                if i < len(keyword_list):
                    # åŸºäºå•ä¸ªå…³é”®è¯çš„æ·±åº¦ä¸»é¢˜
                    keyword = keyword_list[i]
                    topic = self._generate_depth_topic(keyword, domain_analysis)
                else:
                    # åŸºäºå…³é”®è¯ç»„åˆçš„è·¨é¢†åŸŸä¸»é¢˜
                    primary_keyword = keyword_list[i % len(keyword_list)]
                    secondary_keyword = keyword_list[(i + 1) % len(keyword_list)]
                    topic = self._generate_cross_domain_topic(primary_keyword, secondary_keyword, domain_analysis)
                
                if topic and topic not in topics:
                    topics.append(topic)
            
            return topics
            
        except Exception as e:
            if self.logger:
                self.logger.error(f"Claudeå¢å¼ºä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []
    
    def _analyze_content_domain(self, keyword_list: List[str]) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯çš„å†…å®¹é¢†åŸŸå’Œç‰¹å¾"""
        # å®šä¹‰é¢†åŸŸç‰¹å¾è¯
        domain_patterns = {
            "cognitive-upgrade": ["å­¦ä¹ ", "æ€ç»´", "è®¤çŸ¥", "æ–¹æ³•", "æ¨¡å‹", "å¿ƒç†", "æ•ˆç‡", "è®°å¿†"],
            "tech-empowerment": ["æŠ€æœ¯", "å·¥å…·", "è‡ªåŠ¨åŒ–", "AI", "ç¼–ç¨‹", "æ•°æ®", "ç®—æ³•", "å¹³å°"],
            "global-perspective": ["å›½é™…", "å…¨çƒ", "æ–‡åŒ–", "è¶‹åŠ¿", "ä¸–ç•Œ", "è·¨å›½", "è§‚å¯Ÿ", "åˆ†æ"],
            "investment-finance": ["æŠ•èµ„", "ç†è´¢", "é‡‘è", "è‚¡ç¥¨", "åŸºé‡‘", "é‡åŒ–", "é£é™©", "æ”¶ç›Š"]
        }
        
        # è®¡ç®—æ¯ä¸ªé¢†åŸŸçš„åŒ¹é…åº¦
        domain_scores = {}
        for domain, patterns in domain_patterns.items():
            score = sum(1 for keyword in keyword_list 
                       for pattern in patterns 
                       if pattern in keyword)
            domain_scores[domain] = score
        
        # ç¡®å®šä¸»è¦é¢†åŸŸ
        primary_domain = max(domain_scores, key=domain_scores.get) if any(domain_scores.values()) else "tech-empowerment"
        
        return {
            "primary_domain": primary_domain,
            "domain_scores": domain_scores,
            "keywords": keyword_list,
            "complexity": "high" if len(keyword_list) > 3 else "medium"
        }
    
    def _generate_depth_topic(self, keyword: str, domain_analysis: Dict[str, Any]) -> str:
        """åŸºäºå•ä¸ªå…³é”®è¯ç”Ÿæˆæ·±åº¦ä¸“ä¸šä¸»é¢˜"""
        domain = domain_analysis["primary_domain"]
        
        # æ ¹æ®é¢†åŸŸå’Œå…³é”®è¯ç”Ÿæˆä¸“ä¸šä¸»é¢˜æ¨¡æ¿
        templates = {
            "cognitive-upgrade": [
                f"æ·±åº¦è§£æ{keyword}ï¼šè®¤çŸ¥ç§‘å­¦è§†è§’ä¸‹çš„å­¦ä¹ æ–¹æ³•é©å‘½",
                f"ä»{keyword}çœ‹ç»ˆèº«å­¦ä¹ è€…çš„æ€ç»´å‡çº§è·¯å¾„",
                f"{keyword}èƒŒåçš„å¿ƒç†æœºåˆ¶ï¼šå¦‚ä½•æ„å»ºæ›´é«˜æ•ˆçš„è®¤çŸ¥æ¨¡å‹"
            ],
            "tech-empowerment": [
                f"{keyword}è‡ªåŠ¨åŒ–å®è·µæŒ‡å—ï¼šè®©æŠ€æœ¯ä¸ºåˆ›ä½œè€…èµ‹èƒ½",
                f"ä»é›¶åˆ°ä¸€ï¼š{keyword}æŠ€æœ¯æ ˆçš„å®Œæ•´å­¦ä¹ è·¯çº¿å›¾",
                f"{keyword}å·¥å…·ç”Ÿæ€ç³»ç»Ÿï¼šæ•ˆç‡æå‡çš„æœ€ä½³å®è·µ"
            ],
            "global-perspective": [
                f"å…¨çƒ{keyword}è¶‹åŠ¿è§‚å¯Ÿï¼šè·¨æ–‡åŒ–è§†é‡ä¸‹çš„æ·±åº¦åˆ†æ",
                f"{keyword}çš„å›½é™…åŒ–æ€ç»´ï¼šå¦‚ä½•åŸ¹å…»å…¨çƒç«äº‰åŠ›",
                f"ä¸œè¥¿æ–¹{keyword}ç†å¿µç¢°æ’ï¼šå¯»æ‰¾æ–‡åŒ–èåˆçš„æ™ºæ…§"
            ],
            "investment-finance": [
                f"{keyword}æŠ•èµ„ç­–ç•¥è§£ç ï¼šæ•°æ®é©±åŠ¨çš„è´¢å¯Œå¢é•¿æ–¹æ³•",
                f"é‡åŒ–åˆ†æ{keyword}ï¼šç†æ€§æŠ•èµ„è€…çš„å†³ç­–æ¡†æ¶",
                f"{keyword}é£é™©ç®¡ç†ï¼šæ„å»ºç¨³å¥çš„æŠ•èµ„ç»„åˆ"
            ]
        }
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿
        domain_templates = templates.get(domain, templates["tech-empowerment"])
        import random
        return random.choice(domain_templates)
    
    def _generate_cross_domain_topic(self, primary_keyword: str, secondary_keyword: str, domain_analysis: Dict[str, Any]) -> str:
        """åŸºäºå…³é”®è¯ç»„åˆç”Ÿæˆè·¨é¢†åŸŸä¸»é¢˜"""
        # è·¨é¢†åŸŸä¸»é¢˜æ¨¡æ¿
        cross_templates = [
            f"{primary_keyword}ä¸{secondary_keyword}çš„èåˆåˆ›æ–°ï¼šè·¨ç•Œæ€ç»´çš„å®è·µæ¢ç´¢",
            f"ä»{primary_keyword}åˆ°{secondary_keyword}ï¼šç³»ç»Ÿæ€§æ€è€ƒçš„è¿›é˜¶è·¯å¾„",
            f"{primary_keyword}é©±åŠ¨çš„{secondary_keyword}é©å‘½ï¼šæœªæ¥è¶‹åŠ¿çš„æ·±åº¦é¢„æµ‹",
            f"æ·±åº¦å¤ç›˜ï¼š{primary_keyword}å’Œ{secondary_keyword}ååŒæ•ˆåº”çš„æœ€ä½³å®è·µ",
            f"{primary_keyword}Ã—{secondary_keyword}ï¼šæ„å»ºä¸ªäººç«äº‰ä¼˜åŠ¿çš„ç­–ç•¥çŸ©é˜µ"
        ]
        
        import random
        return random.choice(cross_templates)
    
    def _generate_topics_gemini(self, keyword_list: List[str], count: int) -> List[str]:
        """ä½¿ç”¨Geminiç”Ÿæˆä¸»é¢˜åˆ—è¡¨"""
        try:
            if not self.gemini_client:
                self._init_gemini_client()
            
            # æ„å»ºGeminiæç¤ºè¯
            keywords_str = "ã€".join(keyword_list)
            prompt = f"""ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„å†…å®¹ç­–åˆ’å¸ˆï¼Œè¯·åŸºäºå…³é”®è¯ã€Œ{keywords_str}ã€ç”Ÿæˆ{count}ä¸ªæœ‰ä»·å€¼çš„æ–‡ç« ä¸»é¢˜ã€‚

è¦æ±‚ï¼š
1. ä¸»é¢˜åº”è¯¥å…·æœ‰å®ç”¨ä»·å€¼å’Œå¸å¼•åŠ›
2. æ¯ä¸ªä¸»é¢˜éƒ½åº”è¯¥ç‹¬ç‰¹ä¸”æœ‰æ·±åº¦  
3. é€‚åˆåšå®¢æˆ–ä¸“ä¸šæ–‡ç« å†™ä½œ
4. ä¸»é¢˜é•¿åº¦æ§åˆ¶åœ¨15-50å­—ä¹‹é—´
5. æ¶µç›–ä¸åŒè§’åº¦å’Œå±‚æ¬¡

è¾“å‡ºæ ¼å¼ï¼š
è¯·ç›´æ¥è¿”å›ä¸»é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªä¸»é¢˜ï¼Œä¸éœ€è¦ç¼–å·æˆ–å…¶ä»–æ ¼å¼ï¼š"""

            # è°ƒç”¨Gemini API
            response = self.gemini_client.generate_content(prompt)
            
            if response and response.text:
                # è§£æå“åº”ï¼Œæå–ä¸»é¢˜åˆ—è¡¨
                topics = self._parse_topic_response(response.text)
                if len(topics) >= count:
                    return topics[:count]
                else:
                    # å¦‚æœç”Ÿæˆçš„ä¸»é¢˜ä¸å¤Ÿï¼Œè¡¥å……ä¸€äº›
                    additional_topics = self._generate_fallback_topics(keyword_list, count - len(topics))
                    return topics + additional_topics
            else:
                if self.logger:
                    self.logger.warning("Geminiå“åº”ä¸ºç©ºï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ")
                else:
                    print("âš ï¸ Geminiå“åº”ä¸ºç©ºï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ")
                return self._generate_fallback_topics(keyword_list, count)
                
        except Exception as e:
            if self.logger:
                self.logger.error(f"Geminiä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            else:
                print(f"âŒ Geminiä¸»é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._generate_fallback_topics(keyword_list, count)
    
    def _parse_topic_response(self, response_text: str) -> List[str]:
        """è§£æAIå“åº”ï¼Œæå–ä¸»é¢˜åˆ—è¡¨"""
        topics = []
        lines = response_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ç§»é™¤å¯èƒ½çš„ç¼–å·æˆ–æ ¼å¼ç¬¦å·
            line = re.sub(r'^\d+[\.\)]\s*', '', line)  # ç§»é™¤ "1. " æˆ– "1) "
            line = re.sub(r'^[â€¢\-\*]\s*', '', line)    # ç§»é™¤ "â€¢ " æˆ– "- " æˆ– "* "
            line = re.sub(r'^ã€.*?ã€‘\s*', '', line)      # ç§»é™¤ "ã€æ ‡é¢˜ã€‘"
            
            if line and len(line) >= 10:  # ç¡®ä¿ä¸»é¢˜æœ‰ä¸€å®šé•¿åº¦
                topics.append(line)
        
        return topics
    
    def _generate_fallback_topics(self, keyword_list: List[str], count: int) -> List[str]:
        """ç”Ÿæˆåå¤‡ä¸»é¢˜ï¼ˆå½“AIç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        keywords_str = "ã€".join(keyword_list[:3])  # ä½¿ç”¨å‰3ä¸ªå…³é”®è¯
        
        templates = [
            f"æ·±åº¦è§£æï¼š{keywords_str}çš„å‘å±•è¶‹åŠ¿ä¸æœªæ¥æœºé‡",
            f"å®ç”¨æŒ‡å—ï¼šå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨{keywords_str}æå‡æ•ˆç‡",
            f"ä¸“ä¸šè§†è§’ï¼š{keywords_str}åœ¨è¡Œä¸šä¸­çš„åˆ›æ–°åº”ç”¨",
            f"æ¡ˆä¾‹ç ”ç©¶ï¼š{keywords_str}æˆåŠŸå®è·µçš„å…³é”®è¦ç´ ",
            f"å…¨é¢è¯„æµ‹ï¼š{keywords_str}çš„ä¼˜åŠ¿ã€æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ",
            f"å‰æ²¿è§‚å¯Ÿï¼š{keywords_str}æŠ€æœ¯å‘å±•çš„æœ€æ–°åŠ¨æ€",
            f"ç­–ç•¥æ€è€ƒï¼š{keywords_str}çš„å•†ä¸šä»·å€¼ä¸å¸‚åœºå‰æ™¯",
            f"æ·±å…¥æ¢è®¨ï¼š{keywords_str}å¯¹ä¼ ç»Ÿæ¨¡å¼çš„é¢ è¦†ä¸é‡æ„",
            f"å®æˆ˜ç»éªŒï¼š{keywords_str}åº”ç”¨ä¸­çš„å¸¸è§é—®é¢˜ä¸åº”å¯¹ç­–ç•¥",
            f"è¶‹åŠ¿é¢„æµ‹ï¼š{keywords_str}åœ¨æœªæ¥5å¹´çš„å‘å±•è·¯å¾„"
        ]
        
        # æ ¹æ®å…³é”®è¯ç‰¹ç‚¹è°ƒæ•´æ¨¡æ¿
        if any(keyword in ['AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ '] for keyword in keyword_list):
            templates.extend([
                f"AIé©å‘½ï¼š{keywords_str}å¦‚ä½•æ”¹å˜æˆ‘ä»¬çš„å·¥ä½œæ–¹å¼",
                f"æ™ºèƒ½æ—¶ä»£ï¼š{keywords_str}é©±åŠ¨çš„äº§ä¸šå‡çº§è·¯å¾„"
            ])
        
        if any(keyword in ['åŒ»ç–—', 'æ•™å­¦', 'æ•™è‚²', 'å¥åº·'] for keyword in keyword_list):
            templates.extend([
                f"åŒ»ç–—åˆ›æ–°ï¼š{keywords_str}åœ¨ä¸´åºŠå®è·µä¸­çš„çªç ´æ€§è¿›å±•",
                f"æ•™è‚²å˜é©ï¼š{keywords_str}é‡å¡‘ä¼ ç»Ÿæ•™å­¦æ¨¡å¼çš„æ¢ç´¢"
            ])
        
        # éšæœºé€‰æ‹©å¹¶è¿”å›æŒ‡å®šæ•°é‡çš„ä¸»é¢˜
        import random
        selected_topics = random.sample(templates, min(count, len(templates)))
        return selected_topics

def main():
    """ä¸»å‡½æ•° - ä¾›ç‹¬ç«‹è¿è¡Œä½¿ç”¨"""
    print("ğŸ’¡ ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨ - ä¸“ä¸šåŒ–ç‰ˆæœ¬")
    print("="*60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°GEMINI_API_KEYæˆ–GOOGLE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Gemini APIå¯†é’¥")
        return
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
        generator = TopicInspirationGenerator()
        
        # æ˜¾ç¤ºæœç´¢æ¨¡å¼é€‰æ‹©
        print("\nğŸ” è¯·é€‰æ‹©æœç´¢æ¨¡å¼ï¼š")
        print("1. ğŸ“š ä¸“ä¸šé¢†åŸŸæœç´¢ - åŸºäºé¢„è®¾çš„ä¸“ä¸šé¢†åŸŸçŸ¥è¯†åº“")
        print("2. ğŸ” è‡ªå®šä¹‰ä¸»é¢˜æœç´¢ - åŸºäºç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜")
        
        mode_choice = input("è¯·é€‰æ‹©æ¨¡å¼ (1-2): ").strip()
        
        results = []
        topic_name = ""
        domain_name = None
        category = None
        
        if mode_choice == "1":
            # ä¸“ä¸šé¢†åŸŸæœç´¢æ¨¡å¼
            domains = generator.list_available_domains()
            
            if not domains:
                print("âŒ æœªæ‰¾åˆ°ä¸“ä¸šé¢†åŸŸé…ç½®ï¼Œå›é€€åˆ°è‡ªå®šä¹‰æœç´¢æ¨¡å¼")
                mode_choice = "2"
            else:
                print("\nğŸ“‹ å¯ç”¨çš„ä¸“ä¸šé¢†åŸŸï¼š")
                for i, (domain_id, display_name, description) in enumerate(domains, 1):
                    print(f"{i}. {display_name}")
                    print(f"   {description}")
                    print()
                
                domain_choice = input(f"è¯·é€‰æ‹©é¢†åŸŸ (1-{len(domains)}): ").strip()
                try:
                    domain_index = int(domain_choice) - 1
                    if 0 <= domain_index < len(domains):
                        domain_id, display_name, description = domains[domain_index]
                        domain_name = display_name
                        topic_name = display_name.replace('ğŸ¥ ', '').replace('âš›ï¸ ', '').replace('ğŸ’³ ', '').replace('ğŸŒ± ', '').replace('ğŸ§  ', '').replace('ğŸš€ ', '')
                        
                        print(f"\nğŸ¯ é€‰æ‹©é¢†åŸŸ: {display_name}")
                        print(f"ğŸ“ æè¿°: {description}")
                        
                        # è·å–é¢†åŸŸé…ç½®ä¸­çš„category
                        domain_config = generator.domains.get(domain_id, {})
                        category = domain_config.get('category', 'global-perspective')
                        
                        # æ‰§è¡Œä¸“ä¸šé¢†åŸŸæœç´¢
                        results = generator.get_domain_inspiration(domain_id)
                    else:
                        print("âŒ é€‰æ‹©æ— æ•ˆï¼Œå›é€€åˆ°è‡ªå®šä¹‰æœç´¢")
                        mode_choice = "2"
                except (ValueError, IndexError):
                    print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œå›é€€åˆ°è‡ªå®šä¹‰æœç´¢")
                    mode_choice = "2"
        
        if mode_choice == "2":
            # è‡ªå®šä¹‰ä¸»é¢˜æœç´¢æ¨¡å¼
            topic = input("\nè¯·è¾“å…¥è¦æ¢ç´¢çš„ä¸»é¢˜: ").strip()
            if not topic:
                print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
                return
            
            topic_name = topic
            
            print("\né€‰æ‹©å†…å®¹åˆ†ç±» (å¯é€‰):")
            print("1. ğŸ§  è®¤çŸ¥å‡çº§")
            print("2. ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½") 
            print("3. ğŸŒ å…¨çƒè§†é‡")
            print("4. ğŸ’° æŠ•èµ„ç†è´¢")
            print("5. ä¸é™åˆ†ç±»")
            
            category_choice = input("è¯·é€‰æ‹© (1-5): ").strip()
            category_map = {
                '1': 'cognitive-upgrade',
                '2': 'tech-empowerment', 
                '3': 'global-perspective',
                '4': 'investment-finance'
            }
            
            category = category_map.get(category_choice)
            
            # æ‰§è¡Œä¼ ç»Ÿä¸»é¢˜æœç´¢
            results = generator.get_topic_inspiration(topic, category)
        
        # å¤„ç†æœç´¢ç»“æœ
        if results:
            # ç”ŸæˆæŠ¥å‘Š
            report = generator.generate_inspiration_report(topic_name, results, category, domain_name)
            
            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            safe_topic = re.sub(r'[^\w\s-]', '', topic_name)[:20]
            report_file = generator.output_dir / f"{safe_topic}-{timestamp}.md"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"\nâœ… çµæ„ŸæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            print(f"ğŸ“Š æ‰¾åˆ° {len(results)} æ¡æƒå¨èµ„è®¯")
            
            # æ˜¾ç¤ºç»“æœæ¦‚è¦
            for i, result in enumerate(results, 1):
                credibility_emoji = "ğŸŒŸ" if result.credibility_score >= 9 else "â­" if result.credibility_score >= 7 else "ğŸ“°"
                date_display = f" - {result.publication_date}" if result.publication_date else ""
                print(f"  {i}. {credibility_emoji} {result.title} ({result.source}{date_display})")
            
            # è¯¢é—®æ˜¯å¦åˆ›å»ºè‰ç¨¿
            create_draft = input("\næ˜¯å¦åŸºäºè¿™äº›çµæ„Ÿåˆ›å»ºæ–‡ç« è‰ç¨¿ï¼Ÿ(y/N): ").strip().lower()
            if create_draft in ['y', 'yes']:
                draft_path = generator.create_inspired_draft(topic_name, results, category)
                if draft_path:
                    print(f"ğŸ“„ è‰ç¨¿å·²åˆ›å»º: {draft_path}")
                    print("ğŸ’¡ è‰ç¨¿ä½¿ç”¨è¯´æ˜:")
                    print("   â€¢ è‰ç¨¿å·²è‡ªåŠ¨ç”ŸæˆFront Matterå’ŒåŸºç¡€ç»“æ„")
                    print("   â€¢ åŒ…å«äº†æ‰€æœ‰æƒå¨æ¥æºçš„å…³é”®æ´å¯Ÿ")
                    print("   â€¢ å¯ä»¥ç›´æ¥ç¼–è¾‘å®Œå–„åå‘å¸ƒ")
                    print("   â€¢ æˆ–ä½¿ç”¨ä¸»ç¨‹åºçš„'å¤„ç†ç°æœ‰è‰ç¨¿'åŠŸèƒ½è¿›è¡Œå‘å¸ƒ")
                    
                    # è®°å½•çµæ„ŸæŠ¥å‘Šå’Œè‰ç¨¿
                    generator._record_inspiration_report(str(report_file), topic_name, domain_name, draft_path)
                else:
                    # åªè®°å½•çµæ„ŸæŠ¥å‘Š
                    generator._record_inspiration_report(str(report_file), topic_name, domain_name)
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³æƒå¨èµ„è®¯ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯æˆ–é¢†åŸŸ")
            
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()