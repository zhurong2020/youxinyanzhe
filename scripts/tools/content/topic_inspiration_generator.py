#!/usr/bin/env python3
"""
ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨
åˆ©ç”¨Geminiçš„è”ç½‘æœç´¢èƒ½åŠ›è·å–åšæ–‡åˆ›ä½œçµæ„Ÿï¼Œç­›é€‰æƒå¨è‹±æ–‡æ¥æºçš„æœ€æ–°èµ„è®¯
"""

import os
import sys
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    import google.generativeai as genai
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…google-generativeaiåº“ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
    genai = None

@dataclass
class NewsResult:
    """æ–°é—»ç»“æœæ•°æ®ç»“æ„"""
    title: str
    source: str
    credibility_score: int
    publication_date: str
    summary: str
    key_insights: List[str]
    blog_angles: List[str]
    relevance_score: float
    url: Optional[str] = None

class TopicInspirationGenerator:
    """ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨ - åŸºäºGeminiè”ç½‘æœç´¢"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.gemini_client = self._init_gemini_client()
        self.output_dir = Path(".tmp/output/inspiration_reports")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æƒå¨æ¥æºåˆ—è¡¨ï¼ˆæŒ‰å¯ä¿¡åº¦æ’åºï¼‰
        self.authoritative_sources = {
            # é¡¶çº§æƒå¨æ¥æº (9-10åˆ†)
            'reuters.com': 10, 'bloomberg.com': 10, 'nature.com': 10,
            'science.org': 10, 'economist.com': 9, 'ft.com': 9,
            'harvard.edu': 10, 'mit.edu': 10, 'stanford.edu': 10,
            'oxford.ac.uk': 10, 'cambridge.org': 10,
            
            # é«˜å¯ä¿¡åº¦æ¥æº (7-8åˆ†)
            'nytimes.com': 8, 'wsj.com': 8, 'washingtonpost.com': 8,
            'bbc.com': 8, 'guardian.com': 7, 'techcrunch.com': 7,
            'wired.com': 7, 'atlantic.com': 8,
            
            # ä¸“ä¸š/è¡Œä¸šæƒå¨ (6-8åˆ†)
            'mckinsey.com': 8, 'bcg.com': 8, 'pwc.com': 7,
            'deloitte.com': 7, 'hbr.org': 8, 'sloan.mit.edu': 9,
            
            # ç§‘æŠ€ä¸“ä¸šåª’ä½“ (6-7åˆ†)
            'arstechnica.com': 7, 'ieee.org': 9, 'acm.org': 9,
            'venturebeat.com': 6, 'techreview.com': 8
        }
        
        # åˆ†ç±»ç›¸å…³çš„æœç´¢å¢å¼ºå…³é”®è¯
        self.category_keywords = {
            'tech-empowerment': ['technology', 'AI', 'automation', 'digital transformation', 'innovation', 'software', 'tools'],
            'investment-finance': ['finance', 'investment', 'market', 'economic', 'trading', 'portfolio', 'wealth', 'banking'],
            'global-perspective': ['international', 'global', 'geopolitics', 'culture', 'society', 'policy', 'trends'],
            'cognitive-upgrade': ['psychology', 'learning', 'productivity', 'mindset', 'cognitive', 'behavior', 'growth']
        }

    def _init_gemini_client(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        if genai is None:
            raise ValueError("æœªå®‰è£…google-generativeaiåº“ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
            
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°GOOGLE_API_KEYç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®")
        
        genai.configure(api_key=api_key)
        
        # ä½¿ç”¨æ”¯æŒæœç´¢çš„Geminiæ¨¡å‹
        model = genai.GenerativeModel(
            model_name='gemini-1.5-pro'
        )
        
        return model

    def get_topic_inspiration(self, topic: str, category: Optional[str] = None, days: int = 7) -> List[NewsResult]:
        """
        è·å–ä¸»é¢˜ç›¸å…³çš„æƒå¨è‹±æ–‡èµ„è®¯çµæ„Ÿ
        
        Args:
            topic: æœç´¢ä¸»é¢˜
            category: å†…å®¹åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
            days: æœç´¢å¤©æ•°èŒƒå›´
        
        Returns:
            æƒå¨æ–°é—»ç»“æœåˆ—è¡¨
        """
        try:
            print(f"ğŸ” æ­£åœ¨æœç´¢ä¸»é¢˜: {topic}")
            if category:
                print(f"ğŸ“‚ åˆ†ç±»é™åˆ¶: {category}")
            
            # æ„å»ºæœç´¢æç¤ºè¯
            search_prompt = self._build_search_prompt(topic, category, days)
            
            # æ‰§è¡ŒGeminiè”ç½‘æœç´¢
            print("ğŸŒ æ­£åœ¨è°ƒç”¨Geminiè”ç½‘æœç´¢...")
            response = self.gemini_client.generate_content(search_prompt)
            
            if not response or not response.text:
                print("âŒ Geminiæœç´¢æœªè¿”å›ç»“æœ")
                return []
            
            print("ğŸ“Š æ­£åœ¨è§£ææœç´¢ç»“æœ...")
            # è§£ææœç´¢ç»“æœ
            results = self._parse_search_results(response.text, topic)
            
            # ç­›é€‰å’Œè¯„åˆ†
            filtered_results = self._filter_and_score_results(results)
            
            # æŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦æ’åº
            sorted_results = sorted(
                filtered_results, 
                key=lambda x: (x.credibility_score * 0.6 + x.relevance_score * 0.4), 
                reverse=True
            )
            
            # è¿”å›å‰5ä¸ªç»“æœ
            return sorted_results[:5]
            
        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return []

    def _build_search_prompt(self, topic: str, category: Optional[str] = None, days: int = 7) -> str:
        """æ„å»ºæœç´¢æç¤ºè¯"""
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        date_range = f"{start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}"
        
        # åŸºç¡€æœç´¢æç¤º
        prompt = f"""
Search for recent, authoritative English-language news and insights about: "{topic}"

**SEARCH REQUIREMENTS:**
- Time Range: {date_range} (focus on the most recent {days} days)
- Language: English sources ONLY
- Geographic Focus: International/Global perspective preferred
- Source Quality: Prioritize authoritative and credible sources

**PREFERRED AUTHORITATIVE SOURCES:**
- Major News: Reuters, Bloomberg, New York Times, Wall Street Journal, Financial Times, BBC, The Guardian
- Academic: Harvard, MIT, Stanford, Oxford, Cambridge, Nature, Science
- Industry Leaders: McKinsey, Boston Consulting Group, Harvard Business Review
- Tech/Innovation: TechCrunch, Wired, MIT Technology Review, IEEE, ACM
- Financial: Bloomberg, Financial Times, Reuters Financial, MarketWatch

**OUTPUT FORMAT:**
For each of exactly 5 results, provide structured information:

## Result [Number]
**Title:** [Clear, descriptive headline]
**Source:** [Publication name]
**Date:** [YYYY-MM-DD format]
**URL:** [If available]
**Summary:** [2-3 sentences describing the main content]
**Key Insights:** 
- [Insight 1]
- [Insight 2] 
- [Insight 3]
**Blog Post Angles:**
- [Potential Chinese blog angle 1]
- [Potential Chinese blog angle 2]
- [Potential Chinese blog angle 3]

---
"""

        # æ·»åŠ åˆ†ç±»ç‰¹å®šçš„æŒ‡å¯¼
        if category and category in self.category_keywords:
            category_guidance = {
                'tech-empowerment': "Focus on technology innovations, AI developments, digital tools, automation, and their practical applications.",
                'investment-finance': "Focus on financial markets, investment strategies, economic analysis, fintech, and wealth management trends.",
                'global-perspective': "Focus on international affairs, geopolitical developments, cultural trends, and global economic patterns.",
                'cognitive-upgrade': "Focus on psychology research, learning methodologies, productivity techniques, and personal development insights."
            }
            
            prompt += f"\n**CATEGORY FOCUS:** {category_guidance[category]}\n"
            
            # æ·»åŠ åˆ†ç±»å…³é”®è¯
            keywords = self.category_keywords[category]
            prompt += f"**ENHANCED KEYWORDS:** Include these related terms in your search: {', '.join(keywords)}\n"
        
        prompt += """
**QUALITY CRITERIA:**
- Credible, fact-based reporting
- Recent developments (prioritize newer content)
- Global relevance and impact
- Unique insights or analysis
- Potential for inspiring thoughtful Chinese content

Please ensure all sources are legitimate and authoritative. Avoid opinion blogs, social media, or unverified sources.
"""
        
        return prompt

    def _parse_search_results(self, response_text: str, topic: str) -> List[NewsResult]:
        """è§£æGeminiæœç´¢ç»“æœ"""
        results = []
        
        try:
            # åˆ†å‰²ç»“æœæ®µè½
            result_sections = re.split(r'## Result \d+|---', response_text)
            
            for section in result_sections:
                if not section.strip():
                    continue
                    
                result = self._parse_single_result(section, topic)
                if result:
                    results.append(result)
            
            print(f"ğŸ“‹ è§£æåˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"âš ï¸ ç»“æœè§£æå‡ºé”™: {e}")
            # å¦‚æœç»“æ„åŒ–è§£æå¤±è´¥ï¼Œå°è¯•ç®€å•è§£æ
            return self._fallback_parse_results(response_text, topic)

    def _parse_single_result(self, section: str, topic: str) -> Optional[NewsResult]:
        """è§£æå•ä¸ªç»“æœæ®µè½"""
        try:
            lines = [line.strip() for line in section.split('\n') if line.strip()]
            
            # æå–å„ä¸ªå­—æ®µ
            title = ""
            source = ""
            date = ""
            url = ""
            summary = ""
            insights = []
            angles = []
            
            current_section = None
            
            for line in lines:
                if line.startswith('**Title:**'):
                    title = line.replace('**Title:**', '').strip()
                elif line.startswith('**Source:**'):
                    source = line.replace('**Source:**', '').strip()
                elif line.startswith('**Date:**'):
                    date = line.replace('**Date:**', '').strip()
                elif line.startswith('**URL:**'):
                    url = line.replace('**URL:**', '').strip()
                elif line.startswith('**Summary:**'):
                    summary = line.replace('**Summary:**', '').strip()
                elif line.startswith('**Key Insights:**'):
                    current_section = 'insights'
                elif line.startswith('**Blog Post Angles:**'):
                    current_section = 'angles'
                elif line.startswith('- '):
                    if current_section == 'insights':
                        insights.append(line[2:].strip())
                    elif current_section == 'angles':
                        angles.append(line[2:].strip())
                elif current_section == 'insights' and line and not line.startswith('**'):
                    insights.append(line.strip())
                elif current_section == 'angles' and line and not line.startswith('**'):
                    angles.append(line.strip())
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if not title or not source:
                return None
            
            # è®¡ç®—å¯ä¿¡åº¦åˆ†æ•°
            credibility = self._calculate_source_credibility(source)
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            relevance = self._calculate_relevance_score(title + " " + summary, topic)
            
            return NewsResult(
                title=title,
                source=source,
                credibility_score=credibility,
                publication_date=date or datetime.now().strftime('%Y-%m-%d'),
                summary=summary,
                key_insights=insights[:3],  # é™åˆ¶ä¸º3ä¸ªæ´å¯Ÿ
                blog_angles=angles[:3],     # é™åˆ¶ä¸º3ä¸ªè§’åº¦
                relevance_score=relevance,
                url=url if url.startswith('http') else None
            )
            
        except Exception as e:
            print(f"âš ï¸ è§£æå•ä¸ªç»“æœæ—¶å‡ºé”™: {e}")
            return None

    def _fallback_parse_results(self, response_text: str, topic: str) -> List[NewsResult]:
        """å¤‡ç”¨è§£ææ–¹æ³• - å½“ç»“æ„åŒ–è§£æå¤±è´¥æ—¶ä½¿ç”¨"""
        results = []
        
        try:
            # ç®€å•åœ°å°†å“åº”åˆ†å‰²ä¸ºæ®µè½ï¼Œå°è¯•æå–åŸºæœ¬ä¿¡æ¯
            paragraphs = [p.strip() for p in response_text.split('\n\n') if p.strip()]
            
            for i, paragraph in enumerate(paragraphs[:5]):  # æœ€å¤šå–5ä¸ªæ®µè½
                if len(paragraph) > 100:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                    # åˆ›å»ºåŸºç¡€ç»“æœ
                    title = f"æœç´¢ç»“æœ {i+1}: {topic}"
                    summary = paragraph[:200] + "..." if len(paragraph) > 200 else paragraph
                    
                    result = NewsResult(
                        title=title,
                        source="Mixed Sources",
                        credibility_score=5,  # ä¸­ç­‰å¯ä¿¡åº¦
                        publication_date=datetime.now().strftime('%Y-%m-%d'),
                        summary=summary,
                        key_insights=[f"ç›¸å…³ä¿¡æ¯ {j+1}" for j in range(2)],
                        blog_angles=[f"åˆ›ä½œè§’åº¦ {j+1}" for j in range(2)],
                        relevance_score=7.0
                    )
                    results.append(result)
            
            print(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•ï¼Œè·å¾— {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"âŒ å¤‡ç”¨è§£æä¹Ÿå¤±è´¥: {e}")
            return []

    def _calculate_source_credibility(self, source: str) -> int:
        """è®¡ç®—æ¥æºå¯ä¿¡åº¦åˆ†æ•° (1-10)"""
        source_lower = source.lower()
        
        # ç›´æ¥åŒ¹é…
        for domain, score in self.authoritative_sources.items():
            if domain in source_lower:
                return score
        
        # æ¨¡ç³ŠåŒ¹é…çŸ¥ååª’ä½“
        high_credibility_keywords = [
            'university', 'harvard', 'mit', 'stanford', 'oxford', 'cambridge',
            'reuters', 'bloomberg', 'times', 'journal', 'financial', 'economist',
            'nature', 'science', 'ieee', 'acm'
        ]
        
        for keyword in high_credibility_keywords:
            if keyword in source_lower:
                return 8
        
        # é»˜è®¤ä¸­ç­‰åˆ†æ•°
        return 6

    def _calculate_relevance_score(self, text: str, topic: str) -> float:
        """è®¡ç®—å†…å®¹ä¸ä¸»é¢˜çš„ç›¸å…³æ€§åˆ†æ•° (0-10)"""
        try:
            text_lower = text.lower()
            topic_lower = topic.lower()
            
            # åŸºç¡€ç›¸å…³æ€§ï¼šä¸»é¢˜å…³é”®è¯å‡ºç°æ¬¡æ•°
            topic_words = topic_lower.split()
            relevance_score = 0.0
            
            for word in topic_words:
                if len(word) > 2:  # å¿½ç•¥å¤ªçŸ­çš„è¯
                    count = text_lower.count(word)
                    relevance_score += min(count * 2, 6)  # æ¯ä¸ªè¯æœ€å¤šè´¡çŒ®6åˆ†
            
            # å½’ä¸€åŒ–åˆ°10åˆ†åˆ¶
            max_possible = len([w for w in topic_words if len(w) > 2]) * 6
            if max_possible > 0:
                relevance_score = min((relevance_score / max_possible) * 10, 10)
            else:
                relevance_score = 7.0  # é»˜è®¤ç›¸å…³æ€§
            
            return max(relevance_score, 5.0)  # æœ€ä½5åˆ†
            
        except Exception:
            return 7.0  # é»˜è®¤ç›¸å…³æ€§

    def _filter_and_score_results(self, results: List[NewsResult]) -> List[NewsResult]:
        """ç­›é€‰å’Œè¯„åˆ†ç»“æœ"""
        filtered_results = []
        
        for result in results:
            # åŸºæœ¬è´¨é‡è¿‡æ»¤
            if (len(result.title) < 10 or len(result.summary) < 50 or
                result.credibility_score < 5 or result.relevance_score < 5):
                continue
                
            filtered_results.append(result)
        
        return filtered_results

    def generate_inspiration_report(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """ç”Ÿæˆçµæ„ŸæŠ¥å‘Š"""
        
        if not results:
            return f"# ğŸ“° ä¸»é¢˜çµæ„ŸæŠ¥å‘Šï¼š{topic}\n\nâŒ æœªæ‰¾åˆ°ç›¸å…³çš„æƒå¨èµ„è®¯ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯ã€‚"
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_credibility = sum(r.credibility_score for r in results) / len(results)
        avg_relevance = sum(r.relevance_score for r in results) / len(results)
        
        # è·å–åˆ†ç±»æ˜¾ç¤ºå
        category_names = {
            'tech-empowerment': 'ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½',
            'investment-finance': 'ğŸ’° æŠ•èµ„ç†è´¢', 
            'global-perspective': 'ğŸŒ å…¨çƒè§†é‡',
            'cognitive-upgrade': 'ğŸ§  è®¤çŸ¥å‡çº§'
        }
        category_display = category_names.get(category, 'ğŸ” ç»¼åˆæœç´¢') if category else 'ğŸ” ç»¼åˆæœç´¢'
        
        report = f"""# ğŸ“° ä¸»é¢˜çµæ„ŸæŠ¥å‘Šï¼š{topic}

## ğŸ” æœç´¢æ¦‚è¦
- **æœç´¢æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **å†…å®¹åˆ†ç±»**: {category_display}
- **æƒå¨æ¥æºæ•°**: {len(results)}æ¡
- **å¹³å‡å¯ä¿¡åº¦**: {avg_credibility:.1f}/10
- **å¹³å‡ç›¸å…³æ€§**: {avg_relevance:.1f}/10

## ğŸ“‹ æ ¸å¿ƒå‘ç°

"""
        
        for i, result in enumerate(results, 1):
            report += f"""### {i}. {result.title}

**ğŸ“° æ¥æº**: {result.source} (å¯ä¿¡åº¦: {result.credibility_score}/10)  
**ğŸ“… æ—¥æœŸ**: {result.publication_date}  
**ğŸ¯ ç›¸å…³æ€§**: {result.relevance_score:.1f}/10  
{f'**ğŸ”— é“¾æ¥**: {result.url}' if result.url else ''}

**ğŸ“ æ ¸å¿ƒå†…å®¹**:  
{result.summary}

**ğŸ’¡ å…³é”®æ´å¯Ÿ**:
{chr(10).join(f'â€¢ {insight}' for insight in result.key_insights if insight)}

**ğŸ“š åšæ–‡åˆ›ä½œè§’åº¦**:
{chr(10).join(f'â€¢ {angle}' for angle in result.blog_angles if angle)}

---

"""
        
        # æ·»åŠ åˆ›ä½œå»ºè®®
        report += """## ğŸ¨ åˆ›ä½œå»ºè®®

### ğŸ“Š å†…å®¹ç­–ç•¥æ–¹å‘
1. **çƒ­ç‚¹è¿½è¸ª**: åŸºäºä»¥ä¸Šèµ„è®¯çš„æ—¶æ•ˆæ€§ï¼Œå¯ä»¥åˆ›ä½œ"æœ€æ–°åŠ¨æ€è§£è¯»"ç±»æ–‡ç« 
2. **æ·±åº¦åˆ†æ**: ç»“åˆå¤šä¸ªæ¥æºçš„è§‚ç‚¹ï¼Œå½¢æˆç‹¬ç‰¹çš„åˆ†æè§†è§’
3. **ä¸­å›½è§†è§’**: å°†å›½é™…èµ„è®¯ä¸ä¸­å›½å®é™…æƒ…å†µç»“åˆï¼Œæä¾›æœ¬åœ°åŒ–è§è§£
4. **å‰ç»é¢„æµ‹**: åŸºäºå½“å‰è¶‹åŠ¿ï¼Œé¢„æµ‹æœªæ¥å‘å±•æ–¹å‘

### âœï¸ å†™ä½œæŠ€å·§
- **å¼€å¤´å¸å¼•**: ä»¥æœ€æ–°ã€æœ€æƒå¨çš„æ•°æ®æˆ–äº‹ä»¶ä½œä¸ºå¼€å¤´
- **é€»è¾‘æ¸…æ™°**: é‡‡ç”¨"ç°çŠ¶â†’åˆ†æâ†’å½±å“â†’å¯ç¤º"çš„ç»“æ„
- **æ•°æ®æ”¯æ’‘**: å¼•ç”¨æƒå¨æ¥æºçš„å…·ä½“æ•°æ®å’Œä¸“å®¶è§‚ç‚¹
- **å®ç”¨ä»·å€¼**: ä¸ºè¯»è€…æä¾›å¯æ“ä½œçš„å»ºè®®å’Œæ€è€ƒæ¡†æ¶

---

ğŸ“„ *æœ¬æŠ¥å‘Šç”±æœ‰å¿ƒè¨€è€…ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨è‡ªåŠ¨ç”Ÿæˆ*  
ğŸ¤– *åŸºäºGeminiè”ç½‘æœç´¢ + æƒå¨æ¥æºç­›é€‰ç®—æ³•*
"""
        
        return report

    def create_inspired_draft(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """åŸºäºçµæ„Ÿç»“æœåˆ›å»ºæ–‡ç« è‰ç¨¿"""
        try:
            # åˆ›å»ºè‰ç¨¿æ–‡ä»¶å
            safe_topic = re.sub(r'[^\w\s-]', '', topic).strip()
            safe_topic = re.sub(r'[-\s]+', '-', safe_topic)
            timestamp = datetime.now().strftime('%Y-%m-%d')
            
            draft_filename = f"{timestamp}-{safe_topic[:50]}.md"
            draft_path = Path("_drafts") / draft_filename
            
            # ç¡®ä¿è‰ç¨¿ç›®å½•å­˜åœ¨
            draft_path.parent.mkdir(exist_ok=True)
            
            # ç”Ÿæˆè‰ç¨¿å†…å®¹
            draft_content = self._generate_draft_content(topic, results, category)
            
            # ä¿å­˜è‰ç¨¿
            with open(draft_path, 'w', encoding='utf-8') as f:
                f.write(draft_content)
            
            print(f"ğŸ“„ è‰ç¨¿å·²åˆ›å»º: {draft_path}")
            return str(draft_path)
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºè‰ç¨¿å¤±è´¥: {e}")
            return ""

    def _generate_draft_content(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """ç”Ÿæˆè‰ç¨¿å†…å®¹"""
        
        # ç”Ÿæˆæ ‡é¢˜
        title = f"{topic}çš„æœ€æ–°å‘å±•ä¸è¶‹åŠ¿åˆ†æ"
        
        # ç”Ÿæˆæ ‡ç­¾
        basic_tags = ["å…¨çƒè¶‹åŠ¿", "è¡Œä¸šåˆ†æ", "å‰æ²¿èµ„è®¯"]
        
        category_tags = {
            'tech-empowerment': ["æŠ€æœ¯åˆ›æ–°", "æ•°å­—åŒ–è½¬å‹", "ç§‘æŠ€è¶‹åŠ¿"],
            'investment-finance': ["æŠ•èµ„ç­–ç•¥", "é‡‘èå¸‚åœº", "ç»æµåˆ†æ"],
            'global-perspective': ["å›½é™…è§†é‡", "å…¨çƒåŒ–", "è·¨æ–‡åŒ–"],
            'cognitive-upgrade': ["æ€ç»´å‡çº§", "å­¦ä¹ æ–¹æ³•", "è®¤çŸ¥ç§‘å­¦"]
        }
        
        if category and category in category_tags:
            basic_tags.extend(category_tags[category])
        
        # ç”Ÿæˆæ‘˜è¦
        excerpt = f"åŸºäºæœ€æ–°æƒå¨æ¥æºçš„æ·±åº¦åˆ†æï¼Œæ¢è®¨{topic}é¢†åŸŸçš„é‡è¦å‘å±•è¶‹åŠ¿å’Œå½±å“"
        
        # Front Matter
        front_matter = f"""---
title: "{title}"
date: "{datetime.now().strftime('%Y-%m-%d')}"
categories: ["{category or 'global-perspective'}"]
tags: {json.dumps(basic_tags, ensure_ascii=False)}
excerpt: "{excerpt}"
header:
  teaser: "/assets/images/default-teaser.jpg"
layout: "single"
author_profile: true
breadcrumbs: true
comments: true
related: true
share: true
toc: true
toc_icon: "list"
toc_label: "æœ¬é¡µå†…å®¹"
toc_sticky: true
---"""
        
        # æ­£æ–‡å†…å®¹
        content = f"""
è¿‘æœŸï¼Œ{topic}é¢†åŸŸå‡ºç°äº†å¤šé¡¹é‡è¦å‘å±•ï¼Œæ¥è‡ª{', '.join(set(r.source for r in results[:3]))}ç­‰æƒå¨åª’ä½“çš„æŠ¥é“æ˜¾ç¤ºï¼Œè¿™ä¸€é¢†åŸŸæ­£åœ¨ç»å†æ·±åˆ»å˜åŒ–ã€‚

## ğŸ” æœ€æ–°å‘å±•åŠ¨æ€

"""
        
        # æ·»åŠ å„ä¸ªç»“æœçš„å†…å®¹
        for i, result in enumerate(results, 1):
            content += f"""### {i}. {result.title}

æ ¹æ®{result.source}çš„æŠ¥é“ï¼Œ{result.summary}

**å…³é”®è¦ç‚¹**ï¼š
{chr(10).join(f'- {insight}' for insight in result.key_insights[:2] if insight)}

"""
        
        content += """<!-- more -->

## ğŸ’¡ æ·±åº¦åˆ†æä¸æ€è€ƒ

åŸºäºä»¥ä¸Šæƒå¨æ¥æºçš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦æ¥ç†è§£è¿™äº›å‘å±•ï¼š

### ğŸŒ å…¨çƒå½±å“
è¿™äº›å‘å±•ä¸ä»…å½±å“ç‰¹å®šåœ°åŒºï¼Œæ›´å¯¹å…¨çƒæ ¼å±€äº§ç”Ÿæ·±è¿œå½±å“ã€‚

### ğŸš€ æœªæ¥è¶‹åŠ¿
ä»å½“å‰çš„å‘å±•è½¨è¿¹æ¥çœ‹ï¼Œæœªæ¥å¯èƒ½çš„æ¼”è¿›æ–¹å‘åŒ…æ‹¬...

### ğŸ¯ å®è·µå¯ç¤º
å¯¹äºæˆ‘ä»¬è€Œè¨€ï¼Œè¿™äº›å‘å±•æä¾›äº†ä»¥ä¸‹å¯ç¤ºï¼š

## ğŸ“š å‚è€ƒèµ„æº

"""
        
        # æ·»åŠ å‚è€ƒé“¾æ¥
        for result in results:
            if result.url:
                content += f"- [{result.title}]({result.url}) - {result.source}\n"
        
        content += f"""
---

*æœ¬æ–‡åŸºäº{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}çš„æƒå¨æ¥æºä¿¡æ¯æ•´ç†ï¼Œæ•°æ®æ¥æºåŒ…æ‹¬{', '.join(set(r.source for r in results))}ç­‰ã€‚*
"""
        
        return front_matter + content

def main():
    """ä¸»å‡½æ•° - ä¾›ç‹¬ç«‹è¿è¡Œä½¿ç”¨"""
    print("ğŸ’¡ ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨")
    print("="*50)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('GOOGLE_API_KEY'):
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°GOOGLE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Google APIå¯†é’¥")
        return
    
    # è·å–ç”¨æˆ·è¾“å…¥
    topic = input("è¯·è¾“å…¥è¦æ¢ç´¢çš„ä¸»é¢˜: ").strip()
    if not topic:
        print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
        return
    
    print("\né€‰æ‹©å†…å®¹åˆ†ç±» (å¯é€‰):")
    print("1. ğŸ§  è®¤çŸ¥å‡çº§")
    print("2. ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½") 
    print("3. ğŸŒ å…¨çƒè§†é‡")
    print("4. ğŸ’° æŠ•èµ„ç†è´¢")
    print("5. ä¸é™åˆ†ç±»")
    
    category_choice = input("è¯·é€‰æ‹© (1-5): ").strip()
    category_map = {
        '1': 'cognitive-upgrade',
        '2': 'tech-empowerment', 
        '3': 'global-perspective',
        '4': 'investment-finance'
    }
    
    category = category_map.get(category_choice)
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
        generator = TopicInspirationGenerator()
        
        # è·å–çµæ„Ÿ
        results = generator.get_topic_inspiration(topic, category)
        
        if results:
            # ç”ŸæˆæŠ¥å‘Š
            report = generator.generate_inspiration_report(topic, results, category)
            
            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            safe_topic = re.sub(r'[^\w\s-]', '', topic)[:20]
            report_file = generator.output_dir / f"{safe_topic}-{timestamp}.md"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"\nâœ… çµæ„ŸæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            print(f"ğŸ“Š æ‰¾åˆ° {len(results)} æ¡æƒå¨èµ„è®¯")
            
            # æ˜¾ç¤ºç»“æœæ¦‚è¦
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result.title} ({result.source})")
            
            # è¯¢é—®æ˜¯å¦åˆ›å»ºè‰ç¨¿
            create_draft = input("\næ˜¯å¦åŸºäºè¿™äº›çµæ„Ÿåˆ›å»ºæ–‡ç« è‰ç¨¿ï¼Ÿ(y/N): ").strip().lower()
            if create_draft in ['y', 'yes']:
                draft_path = generator.create_inspired_draft(topic, results, category)
                if draft_path:
                    print(f"ğŸ“„ è‰ç¨¿å·²åˆ›å»º: {draft_path}")
                    print("ğŸ’¡ æ‚¨å¯ä»¥ä½¿ç”¨ä¸»ç¨‹åºçš„'å¤„ç†ç°æœ‰è‰ç¨¿'åŠŸèƒ½æ¥å‘å¸ƒæ–‡ç« ")
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³æƒå¨èµ„è®¯ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")
            
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()