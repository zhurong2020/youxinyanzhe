#!/usr/bin/env python3
"""
ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨
åˆ©ç”¨Geminiçš„è”ç½‘æœç´¢èƒ½åŠ›è·å–åšæ–‡åˆ›ä½œçµæ„Ÿï¼Œç­›é€‰æƒå¨è‹±æ–‡æ¥æºçš„æœ€æ–°èµ„è®¯
"""

import os
import sys
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

try:
    import yaml
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…PyYAMLåº“ï¼Œè¯·è¿è¡Œ: pip install PyYAML")
    yaml = None

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…python-dotenvåº“ï¼Œè¯·è¿è¡Œ: pip install python-dotenv")

try:
    import google.generativeai as genai  # type: ignore
    # éªŒè¯åº“æ˜¯å¦æ­£ç¡®å®‰è£…å¹¶å¯ç”¨
    if hasattr(genai, 'configure') and hasattr(genai, 'GenerativeModel'):
        # ä¸»è¦åŠŸèƒ½å¯ç”¨
        pass
    else:
        raise AttributeError("google.generativeaiåº“åŠŸèƒ½ä¸å®Œæ•´")
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£…google-generativeaiåº“ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
    genai = None
except AttributeError:
    print("âš ï¸ è­¦å‘Šï¼šgoogle-generativeaiåº“ç‰ˆæœ¬å¯èƒ½ä¸å…¼å®¹")
    genai = None

@dataclass
class NewsResult:
    """æ–°é—»ç»“æœæ•°æ®ç»“æ„"""
    title: str
    source: str
    credibility_score: int
    publication_date: str
    summary: str
    key_insights: List[str]
    blog_angles: List[str]
    relevance_score: float
    url: Optional[str] = None

class TopicInspirationGenerator:
    """ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨ - åŸºäºGeminiè”ç½‘æœç´¢"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.gemini_client = self._init_gemini_client()
        self.output_dir = Path(".tmp/output/inspiration_reports")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # çµæ„ŸæŠ¥å‘ŠçŠ¶æ€è·Ÿè¸ªæ–‡ä»¶
        self.status_file = Path(".tmp/output/inspiration_status.json")
        self.status_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½ä¸“ä¸šé¢†åŸŸé…ç½®
        self.domains = self._load_domain_config()
        
        # æƒå¨æ¥æºåˆ—è¡¨ï¼ˆæŒ‰å¯ä¿¡åº¦æ’åºï¼‰
        self.authoritative_sources = {
            # é¡¶çº§æƒå¨æ¥æº (9-10åˆ†)
            'reuters.com': 10, 'bloomberg.com': 10, 'nature.com': 10,
            'science.org': 10, 'economist.com': 9, 'ft.com': 9,
            'harvard.edu': 10, 'mit.edu': 10, 'stanford.edu': 10,
            'oxford.ac.uk': 10, 'cambridge.org': 10,
            
            # é«˜å¯ä¿¡åº¦æ¥æº (7-8åˆ†)
            'nytimes.com': 8, 'wsj.com': 8, 'washingtonpost.com': 8,
            'bbc.com': 8, 'guardian.com': 7, 'techcrunch.com': 7,
            'wired.com': 7, 'atlantic.com': 8,
            
            # ä¸“ä¸š/è¡Œä¸šæƒå¨ (6-8åˆ†)
            'mckinsey.com': 8, 'bcg.com': 8, 'pwc.com': 7,
            'deloitte.com': 7, 'hbr.org': 8, 'sloan.mit.edu': 9,
            
            # ç§‘æŠ€ä¸“ä¸šåª’ä½“ (6-7åˆ†)
            'arstechnica.com': 7, 'ieee.org': 9, 'acm.org': 9,
            'venturebeat.com': 6, 'techreview.com': 8
        }
        
        # åˆ†ç±»ç›¸å…³çš„æœç´¢å¢å¼ºå…³é”®è¯
        self.category_keywords = {
            'tech-empowerment': ['technology', 'AI', 'automation', 'digital transformation', 'innovation', 'software', 'tools'],
            'investment-finance': ['finance', 'investment', 'market', 'economic', 'trading', 'portfolio', 'wealth', 'banking'],
            'global-perspective': ['international', 'global', 'geopolitics', 'culture', 'society', 'policy', 'trends'],
            'cognitive-upgrade': ['psychology', 'learning', 'productivity', 'mindset', 'cognitive', 'behavior', 'growth']
        }

    def _init_gemini_client(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        if genai is None:
            raise ValueError("æœªå®‰è£…google-generativeaiåº“ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
        
        # ç¡®ä¿åŠ è½½ç¯å¢ƒå˜é‡
        from dotenv import load_dotenv
        load_dotenv()
            
        # å°è¯•ä»ä¸¤ä¸ªå¯èƒ½çš„ç¯å¢ƒå˜é‡åè·å–APIå¯†é’¥
        api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°GEMINI_API_KEYæˆ–GOOGLE_API_KEYç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®")
        
        try:
            genai.configure(api_key=api_key)  # type: ignore
            
            # ä½¿ç”¨æœ€æ–°çš„Gemini 2.5æ¨¡å‹
            model = genai.GenerativeModel(  # type: ignore[attr-defined]
                model_name='gemini-2.5-pro'
            )
            
            # ä¸åœ¨åˆå§‹åŒ–æ—¶æµ‹è¯•è¿æ¥ï¼Œé¿å…é˜»å¡ç¨‹åºå¯åŠ¨
            print("âœ… Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
            return model
            
        except Exception as e:
            print(f"âš ï¸ Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–è­¦å‘Š: {e}")
            print("ğŸ’¡ è¿™ä¸ä¼šå½±å“åç»­æœç´¢åŠŸèƒ½ï¼Œå¦‚é‡åˆ°é—®é¢˜è¯·æ£€æŸ¥APIå¯†é’¥")
            # ä»ç„¶è¿”å›modelï¼Œè®©å…·ä½“æœç´¢æ—¶å¤„ç†é”™è¯¯
            model = genai.GenerativeModel(  # type: ignore[attr-defined]
                model_name='gemini-2.5-pro'
            )
            return model

    def _load_domain_config(self) -> Dict[str, Any]:
        """åŠ è½½ä¸“ä¸šé¢†åŸŸé…ç½®æ–‡ä»¶"""
        try:
            if yaml is None:
                print("âš ï¸ PyYAMLæœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return {}
                
            config_path = Path("config/inspiration_domains.yml")
            if not config_path.exists():
                print("âš ï¸ ä¸“ä¸šé¢†åŸŸé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return {}
                
            with open(config_path, 'r', encoding='utf-8') as f:
                domains = yaml.safe_load(f)
                
            print(f"âœ… æˆåŠŸåŠ è½½ {len(domains)} ä¸ªä¸“ä¸šé¢†åŸŸé…ç½®")
            return domains
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ä¸“ä¸šé¢†åŸŸé…ç½®å¤±è´¥: {e}")
            return {}

    def list_available_domains(self) -> List[tuple]:
        """è·å–å¯ç”¨çš„ä¸“ä¸šé¢†åŸŸåˆ—è¡¨"""
        domain_list = []
        for domain_id, config in self.domains.items():
            display_name = config.get('display_name', domain_id)
            description = config.get('description', '')
            domain_list.append((domain_id, display_name, description))
        return domain_list

    def get_domain_inspiration(self, domain_id: str, days: int = 7) -> List[NewsResult]:
        """
        åŸºäºä¸“ä¸šé¢†åŸŸé…ç½®è·å–çµæ„Ÿ
        
        Args:
            domain_id: é¢†åŸŸID
            days: æœç´¢å¤©æ•°èŒƒå›´
        
        Returns:
            æƒå¨æ–°é—»ç»“æœåˆ—è¡¨
        """
        if domain_id not in self.domains:
            print(f"âŒ æœªæ‰¾åˆ°é¢†åŸŸé…ç½®: {domain_id}")
            return []
            
        domain_config = self.domains[domain_id]
        print(f"ğŸ” æ­£åœ¨æœç´¢é¢†åŸŸ: {domain_config.get('display_name', domain_id)}")
        
        try:
            # æ„å»ºä¸“ä¸šé¢†åŸŸæœç´¢æç¤ºè¯
            search_prompt = self._build_domain_search_prompt(domain_config, days)
            
            # æ‰§è¡ŒGeminiè”ç½‘æœç´¢
            print("ğŸŒ æ­£åœ¨è°ƒç”¨Geminiè”ç½‘æœç´¢...")
            response = self.gemini_client.generate_content(search_prompt)
            
            if not response:
                print("âŒ Geminiæœç´¢æœªè¿”å›å“åº”")
                return []
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            response_text = None
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    finish_reason = candidate.finish_reason
                    if finish_reason == 1:  # STOP - æ­£å¸¸å®Œæˆ
                        print("âœ… æœç´¢æ­£å¸¸å®Œæˆ")
                    elif finish_reason == 2:  # MAX_TOKENS
                        print("âš ï¸ å“åº”è¢«æˆªæ–­ï¼Œä½†å¯èƒ½åŒ…å«æœ‰ç”¨ä¿¡æ¯")
                    elif finish_reason == 3:  # SAFETY
                        print("âŒ å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œå°è¯•ä½¿ç”¨æ›´é€šç”¨çš„æœç´¢è¯...")
                        # å°è¯•ä½¿ç”¨æ›´é€šç”¨çš„æœç´¢æç¤º
                        fallback_prompt = self._build_fallback_search_prompt(domain_config, days)
                        print("ğŸ”„ ä½¿ç”¨å¤‡ç”¨æœç´¢ç­–ç•¥...")
                        response = self.gemini_client.generate_content(fallback_prompt)
                        if not response:
                            print("âŒ å¤‡ç”¨æœç´¢ä¹Ÿå¤±è´¥")
                            return []
                    elif finish_reason == 4:  # RECITATION
                        print("âŒ å†…å®¹å› å¼•ç”¨é—®é¢˜è¢«è¿‡æ»¤ï¼Œè¯·å°è¯•å…¶ä»–æœç´¢è¯")
                        return []
            
            # å°è¯•è·å–å“åº”æ–‡æœ¬
            try:
                response_text = response.text
                if not response_text:
                    print("âŒ Geminiæœç´¢è¿”å›ç©ºå†…å®¹")
                    return []
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ç›´æ¥è·å–å“åº”æ–‡æœ¬: {e}")
                # å°è¯•ä»å€™é€‰ç­”æ¡ˆä¸­è·å–å†…å®¹
                if hasattr(response, 'candidates') and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and candidate.content:
                            if hasattr(candidate.content, 'parts') and candidate.content.parts:
                                for part in candidate.content.parts:
                                    if hasattr(part, 'text') and part.text:
                                        response_text = part.text
                                        print("âœ… ä»å€™é€‰å†…å®¹ä¸­æå–åˆ°æ–‡æœ¬")
                                        break
                                if response_text:
                                    break
                    
                    if not response_text:
                        print("âŒ æ— æ³•ä»ä»»ä½•å€™é€‰ç­”æ¡ˆä¸­æå–å†…å®¹")
                        return []
                else:
                    print("âŒ å“åº”ä¸­æ²¡æœ‰å€™é€‰ç­”æ¡ˆ")
                    return []
            
            print("ğŸ“Š æ­£åœ¨è§£ææœç´¢ç»“æœ...")
            # è§£ææœç´¢ç»“æœ
            topic_name = domain_config.get('display_name', domain_id)
            results = self._parse_search_results(response_text, topic_name)
            
            # ä½¿ç”¨é¢†åŸŸä¸“ç”¨çš„æƒå¨æ¥æºè¿›è¡Œç­›é€‰å’Œè¯„åˆ†
            filtered_results = self._filter_and_score_domain_results(results, domain_config)
            
            # æŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦æ’åº
            sorted_results = sorted(
                filtered_results, 
                key=lambda x: (x.credibility_score * 0.6 + x.relevance_score * 0.4), 
                reverse=True
            )
            
            # è¿”å›å‰5ä¸ªç»“æœ
            return sorted_results[:5]
            
        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return []

    def _build_domain_search_prompt(self, domain_config: Dict[str, Any], days: int = 7) -> str:
        """æ„å»ºä¸“ä¸šé¢†åŸŸæœç´¢æç¤ºè¯"""
        
        # æ—¥æœŸä¿¡æ¯ç”¨äºæœç´¢åå¥½
        
        # è·å–é¢†åŸŸé…ç½®
        keywords = domain_config.get('keywords', [])
        sources = domain_config.get('sources', [])
        template = domain_config.get('search_prompt_template', '')
        
        # ä½¿ç”¨é¢†åŸŸä¸“ç”¨çš„æœç´¢æ¨¡æ¿
        if template and keywords and sources:
            keywords_str = ', '.join(keywords)
            sources_str = ', '.join(sources)
            
            # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
            domain_prompt = template.format(
                keywords=keywords_str,
                sources=sources_str
            )
            
            # æ·»åŠ æ—¶é—´èŒƒå›´å’Œè¾“å‡ºæ ¼å¼è¦æ±‚
            prompt = f"""
{domain_prompt}

**TIME REQUIREMENTS:** 
- PRIORITIZE content from 2025 (current year)
- Include recent 2024 content as secondary priority  
- Focus on latest developments, news, and research
- Prefer content from the last 6 months when available

**OUTPUT FORMAT:**
For each of exactly 5 results, provide structured information:

## Result [Number]
**Title:** [Clear, descriptive headline]
**Source:** [Publication name]
**Date:** [YYYY-MM-DD format]
**URL:** [Original article URL - REQUIRED for credibility]
**Summary:** [2-3 sentences describing the main content]
**Key Insights:** 
- [Insight 1]
- [Insight 2] 
- [Insight 3]
**Blog Post Angles:**
- [Potential Chinese blog angle 1]
- [Potential Chinese blog angle 2]
- [Potential Chinese blog angle 3]

---

**QUALITY CRITERIA:**
- Credible, fact-based reporting from the specified authoritative sources
- Recent developments (prioritize newer content)
- Significant impact or breakthrough potential
- Unique insights or analysis
- Potential for inspiring thoughtful Chinese content

**CRITICAL: MUST include original article URLs for all results**
"""
        else:
            # å›é€€åˆ°é€šç”¨æœç´¢æ ¼å¼
            keywords_str = ', '.join(keywords) if keywords else "general topics"
            prompt = f"""
Search for recent, authoritative information about: {keywords_str}

**TIME RANGE:** {date_range} (focus on the most recent {days} days)
**PREFERRED SOURCES:** {', '.join(sources) if sources else 'Major international news and academic sources'}

[ç»§ç»­ä½¿ç”¨æ ‡å‡†è¾“å‡ºæ ¼å¼...]
"""
        
        return prompt

    def _build_fallback_search_prompt(self, domain_config: Dict[str, Any], days: int = 7) -> str:
        """æ„å»ºæ›´ç®€å•çš„å¤‡ç”¨æœç´¢æç¤ºè¯ï¼ˆé¿å…å®‰å…¨è¿‡æ»¤ï¼‰"""
        
        # æ—¥æœŸä¿¡æ¯ç”¨äºæœç´¢åå¥½
        
        # è·å–é¢†åŸŸçš„æ ¸å¿ƒå…³é”®è¯ï¼ˆä½¿ç”¨è¾ƒå°‘æ•æ„Ÿçš„è¯æ±‡ï¼‰
        keywords = domain_config.get('keywords', [])
        sources = domain_config.get('sources', [])
        
        # ç®€åŒ–å…³é”®è¯ï¼Œé¿å…å¯èƒ½è§¦å‘è¿‡æ»¤çš„è¯æ±‡
        safe_keywords = []
        for keyword in keywords[:4]:  # åªä½¿ç”¨å‰4ä¸ªå…³é”®è¯
            # ç§»é™¤å¯èƒ½æ•æ„Ÿçš„è¯æ±‡
            safe_keyword = keyword.replace('AI', 'artificial intelligence').replace('medical', 'healthcare')
            safe_keywords.append(safe_keyword)
        
        prompt = f"""
Find recent news and research developments about: {', '.join(safe_keywords)}

**TIME REQUIREMENTS**:
- PRIORITIZE content from 2025 (current year)
- Include recent 2024 content as secondary priority
- Focus on latest developments and trending topics
**Preferred Sources**: {', '.join(sources[:5])}

Please provide 5 recent articles or research papers with this format:

## Result 1
**Title:** [Article title]
**Source:** [Publication name] 
**Date:** [YYYY-MM-DD]
**Summary:** [Brief description]
**Key Points:**
- [Point 1]
- [Point 2]

## Result 2
[Same format...]

Focus on factual reporting, recent developments, and credible sources.
"""
        
        return prompt

    def get_topic_inspiration(self, topic: str, category: Optional[str] = None, days: int = 7) -> List[NewsResult]:
        """
        è·å–ä¸»é¢˜ç›¸å…³çš„æƒå¨è‹±æ–‡èµ„è®¯çµæ„Ÿ
        
        Args:
            topic: æœç´¢ä¸»é¢˜
            category: å†…å®¹åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
            days: æœç´¢å¤©æ•°èŒƒå›´
        
        Returns:
            æƒå¨æ–°é—»ç»“æœåˆ—è¡¨
        """
        try:
            print(f"ğŸ” æ­£åœ¨æœç´¢ä¸»é¢˜: {topic}")
            if category:
                print(f"ğŸ“‚ åˆ†ç±»é™åˆ¶: {category}")
            
            # æ„å»ºæœç´¢æç¤ºè¯
            search_prompt = self._build_search_prompt(topic, category, days)
            
            # æ‰§è¡ŒGeminiè”ç½‘æœç´¢
            print("ğŸŒ æ­£åœ¨è°ƒç”¨Geminiè”ç½‘æœç´¢...")
            response = self.gemini_client.generate_content(search_prompt)
            
            if not response:
                print("âŒ Geminiæœç´¢æœªè¿”å›å“åº”")
                return []
            
            # è·å–å“åº”æ–‡æœ¬ï¼ˆä½¿ç”¨ç›¸åŒçš„é”™è¯¯å¤„ç†é€»è¾‘ï¼‰
            try:
                response_text = response.text
                if not response_text:
                    print("âŒ Geminiæœç´¢è¿”å›ç©ºå†…å®¹")
                    return []
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ç›´æ¥è·å–å“åº”æ–‡æœ¬: {e}")
                # å°è¯•ä»å€™é€‰ç­”æ¡ˆä¸­è·å–å†…å®¹
                response_text = None
                if hasattr(response, 'candidates') and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and candidate.content:
                            if hasattr(candidate.content, 'parts') and candidate.content.parts:
                                for part in candidate.content.parts:
                                    if hasattr(part, 'text') and part.text:
                                        response_text = part.text
                                        print("âœ… ä»å€™é€‰å†…å®¹ä¸­æå–åˆ°æ–‡æœ¬")
                                        break
                                if response_text:
                                    break
                
                if not response_text:
                    print("âŒ æ— æ³•ä»å“åº”ä¸­æå–ä»»ä½•æ–‡æœ¬å†…å®¹")
                    return []
            
            print("ğŸ“Š æ­£åœ¨è§£ææœç´¢ç»“æœ...")
            # è§£ææœç´¢ç»“æœ
            results = self._parse_search_results(response_text, topic)
            
            # ç­›é€‰å’Œè¯„åˆ†
            filtered_results = self._filter_and_score_results(results)
            
            # æŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦æ’åº
            sorted_results = sorted(
                filtered_results, 
                key=lambda x: (x.credibility_score * 0.6 + x.relevance_score * 0.4), 
                reverse=True
            )
            
            # è¿”å›å‰5ä¸ªç»“æœ
            return sorted_results[:5]
            
        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return []

    def _build_search_prompt(self, topic: str, category: Optional[str] = None, days: int = 7) -> str:
        """æ„å»ºæœç´¢æç¤ºè¯"""
        
        # æ—¥æœŸä¿¡æ¯ç”¨äºæœç´¢åå¥½
        
        # åŸºç¡€æœç´¢æç¤º
        prompt = f"""
Search for recent, authoritative English-language news and insights about: "{topic}"

**SEARCH REQUIREMENTS:**
- Time Range: {date_range} (focus on the most recent {days} days)
- Current date: {datetime.now().strftime('%Y-%m-%d')}
- CRITICAL: ONLY content from {datetime.now().strftime('%Y')} (this year)
- EXCLUDE any content from 2024 or earlier years
- Language: English sources ONLY
- Geographic Focus: International/Global perspective preferred
- Source Quality: Prioritize authoritative and credible sources

**PREFERRED AUTHORITATIVE SOURCES:**
- Major News: Reuters, Bloomberg, New York Times, Wall Street Journal, Financial Times, BBC, The Guardian
- Academic: Harvard, MIT, Stanford, Oxford, Cambridge, Nature, Science
- Industry Leaders: McKinsey, Boston Consulting Group, Harvard Business Review
- Tech/Innovation: TechCrunch, Wired, MIT Technology Review, IEEE, ACM
- Financial: Bloomberg, Financial Times, Reuters Financial, MarketWatch

**OUTPUT FORMAT:**
For each of exactly 5 results, provide structured information:

## Result [Number]
**Title:** [Clear, descriptive headline]
**Source:** [Publication name]
**Date:** [YYYY-MM-DD format]
**URL:** [Original article URL - REQUIRED for credibility]
**Summary:** [2-3 sentences describing the main content]
**Key Insights:** 
- [Insight 1]
- [Insight 2] 
- [Insight 3]
**Blog Post Angles:**
- [Potential Chinese blog angle 1]
- [Potential Chinese blog angle 2]
- [Potential Chinese blog angle 3]

---
"""

        # æ·»åŠ åˆ†ç±»ç‰¹å®šçš„æŒ‡å¯¼
        if category and category in self.category_keywords:
            category_guidance = {
                'tech-empowerment': "Focus on technology innovations, AI developments, digital tools, automation, and their practical applications.",
                'investment-finance': "Focus on financial markets, investment strategies, economic analysis, fintech, and wealth management trends.",
                'global-perspective': "Focus on international affairs, geopolitical developments, cultural trends, and global economic patterns.",
                'cognitive-upgrade': "Focus on psychology research, learning methodologies, productivity techniques, and personal development insights."
            }
            
            prompt += f"\n**CATEGORY FOCUS:** {category_guidance[category]}\n"
            
            # æ·»åŠ åˆ†ç±»å…³é”®è¯
            keywords = self.category_keywords[category]
            prompt += f"**ENHANCED KEYWORDS:** Include these related terms in your search: {', '.join(keywords)}\n"
        
        prompt += """
**QUALITY CRITERIA:**
- Credible, fact-based reporting
- Recent developments (prioritize newer content)
- Global relevance and impact
- Unique insights or analysis
- Potential for inspiring thoughtful Chinese content

**CRITICAL: MUST include original article URLs for all results**
Please ensure all sources are legitimate and authoritative. Avoid opinion blogs, social media, or unverified sources.
"""
        
        return prompt

    def _parse_search_results(self, response_text: str, topic: str) -> List[NewsResult]:
        """è§£æGeminiæœç´¢ç»“æœ"""
        results = []
        
        try:
            # åˆ†å‰²ç»“æœæ®µè½
            result_sections = re.split(r'## Result \d+|---', response_text)
            
            for section in result_sections:
                if not section.strip():
                    continue
                    
                result = self._parse_single_result(section, topic)
                if result:
                    results.append(result)
            
            print(f"ğŸ“‹ è§£æåˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"âš ï¸ ç»“æœè§£æå‡ºé”™: {e}")
            # å¦‚æœç»“æ„åŒ–è§£æå¤±è´¥ï¼Œå°è¯•ç®€å•è§£æ
            return self._fallback_parse_results(response_text, topic)

    def _parse_single_result(self, section: str, topic: str) -> Optional[NewsResult]:
        """è§£æå•ä¸ªç»“æœæ®µè½"""
        try:
            lines = [line.strip() for line in section.split('\n') if line.strip()]
            
            # æå–å„ä¸ªå­—æ®µ
            title = ""
            source = ""
            date = ""
            url = ""
            summary = ""
            insights = []
            angles = []
            
            current_section = None
            
            for line in lines:
                if line.startswith('**Title:**'):
                    title = line.replace('**Title:**', '').strip()
                elif line.startswith('**Source:**'):
                    source = line.replace('**Source:**', '').strip()
                elif line.startswith('**Date:**'):
                    date = line.replace('**Date:**', '').strip()
                elif line.startswith('**URL:**'):
                    url = line.replace('**URL:**', '').strip()
                elif line.startswith('**Summary:**'):
                    summary = line.replace('**Summary:**', '').strip()
                elif line.startswith('**Key Insights:**'):
                    current_section = 'insights'
                elif line.startswith('**Blog Post Angles:**'):
                    current_section = 'angles'
                elif line.startswith('- '):
                    if current_section == 'insights':
                        insights.append(line[2:].strip())
                    elif current_section == 'angles':
                        angles.append(line[2:].strip())
                elif current_section == 'insights' and line and not line.startswith('**'):
                    insights.append(line.strip())
                elif current_section == 'angles' and line and not line.startswith('**'):
                    angles.append(line.strip())
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if not title or not source:
                return None
            
            # è®¡ç®—å¯ä¿¡åº¦åˆ†æ•°
            credibility = self._calculate_source_credibility(source)
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            relevance = self._calculate_relevance_score(title + " " + summary, topic)
            
            return NewsResult(
                title=title,
                source=source,
                credibility_score=credibility,
                publication_date=date or datetime.now().strftime('%Y-%m-%d'),
                summary=summary,
                key_insights=insights[:3],  # é™åˆ¶ä¸º3ä¸ªæ´å¯Ÿ
                blog_angles=angles[:3],     # é™åˆ¶ä¸º3ä¸ªè§’åº¦
                relevance_score=relevance,
                url=url if url.startswith('http') else None
            )
            
        except Exception as e:
            print(f"âš ï¸ è§£æå•ä¸ªç»“æœæ—¶å‡ºé”™: {e}")
            return None

    def _fallback_parse_results(self, response_text: str, topic: str) -> List[NewsResult]:
        """å¤‡ç”¨è§£ææ–¹æ³• - å½“ç»“æ„åŒ–è§£æå¤±è´¥æ—¶ä½¿ç”¨"""
        results = []
        
        try:
            # ç®€å•åœ°å°†å“åº”åˆ†å‰²ä¸ºæ®µè½ï¼Œå°è¯•æå–åŸºæœ¬ä¿¡æ¯
            paragraphs = [p.strip() for p in response_text.split('\n\n') if p.strip()]
            
            for i, paragraph in enumerate(paragraphs[:5]):  # æœ€å¤šå–5ä¸ªæ®µè½
                if len(paragraph) > 100:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                    # åˆ›å»ºåŸºç¡€ç»“æœ
                    title = f"æœç´¢ç»“æœ {i+1}: {topic}"
                    summary = paragraph[:200] + "..." if len(paragraph) > 200 else paragraph
                    
                    result = NewsResult(
                        title=title,
                        source="Mixed Sources",
                        credibility_score=5,  # ä¸­ç­‰å¯ä¿¡åº¦
                        publication_date=datetime.now().strftime('%Y-%m-%d'),
                        summary=summary,
                        key_insights=[f"ç›¸å…³ä¿¡æ¯ {j+1}" for j in range(2)],
                        blog_angles=[f"åˆ›ä½œè§’åº¦ {j+1}" for j in range(2)],
                        relevance_score=7.0
                    )
                    results.append(result)
            
            print(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•ï¼Œè·å¾— {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"âŒ å¤‡ç”¨è§£æä¹Ÿå¤±è´¥: {e}")
            return []

    def _calculate_source_credibility(self, source: str) -> int:
        """è®¡ç®—æ¥æºå¯ä¿¡åº¦åˆ†æ•° (1-10)"""
        source_lower = source.lower()
        
        # ç›´æ¥åŒ¹é…
        for domain, score in self.authoritative_sources.items():
            if domain in source_lower:
                return score
        
        # æ¨¡ç³ŠåŒ¹é…çŸ¥ååª’ä½“
        high_credibility_keywords = [
            'university', 'harvard', 'mit', 'stanford', 'oxford', 'cambridge',
            'reuters', 'bloomberg', 'times', 'journal', 'financial', 'economist',
            'nature', 'science', 'ieee', 'acm'
        ]
        
        for keyword in high_credibility_keywords:
            if keyword in source_lower:
                return 8
        
        # é»˜è®¤ä¸­ç­‰åˆ†æ•°
        return 6

    def _calculate_relevance_score(self, text: str, topic: str) -> float:
        """è®¡ç®—å†…å®¹ä¸ä¸»é¢˜çš„ç›¸å…³æ€§åˆ†æ•° (0-10)"""
        try:
            text_lower = text.lower()
            topic_lower = topic.lower()
            
            # åŸºç¡€ç›¸å…³æ€§ï¼šä¸»é¢˜å…³é”®è¯å‡ºç°æ¬¡æ•°
            topic_words = topic_lower.split()
            relevance_score = 0.0
            
            for word in topic_words:
                if len(word) > 2:  # å¿½ç•¥å¤ªçŸ­çš„è¯
                    count = text_lower.count(word)
                    relevance_score += min(count * 2, 6)  # æ¯ä¸ªè¯æœ€å¤šè´¡çŒ®6åˆ†
            
            # å½’ä¸€åŒ–åˆ°10åˆ†åˆ¶
            max_possible = len([w for w in topic_words if len(w) > 2]) * 6
            if max_possible > 0:
                relevance_score = min((relevance_score / max_possible) * 10, 10)
            else:
                relevance_score = 7.0  # é»˜è®¤ç›¸å…³æ€§
            
            return max(relevance_score, 5.0)  # æœ€ä½5åˆ†
            
        except Exception:
            return 7.0  # é»˜è®¤ç›¸å…³æ€§

    def _filter_and_score_results(self, results: List[NewsResult]) -> List[NewsResult]:
        """ç­›é€‰å’Œè¯„åˆ†ç»“æœ"""
        filtered_results = []
        
        for result in results:
            # åŸºæœ¬è´¨é‡è¿‡æ»¤
            if (len(result.title) < 10 or len(result.summary) < 50 or
                result.credibility_score < 5 or result.relevance_score < 5):
                continue
                
            filtered_results.append(result)
        
        return filtered_results

    def _filter_and_score_domain_results(self, results: List[NewsResult], domain_config: Dict[str, Any]) -> List[NewsResult]:
        """ç­›é€‰å’Œè¯„åˆ†é¢†åŸŸä¸“ç”¨ç»“æœ"""
        filtered_results = []
        domain_sources = domain_config.get('sources', [])
        domain_keywords = domain_config.get('keywords', [])
        
        print(f"ğŸ” å¼€å§‹ç­›é€‰ {len(results)} ä¸ªæœç´¢ç»“æœ...")
        
        for i, result in enumerate(results):
            print(f"  ç»“æœ {i+1}: {result.title[:50]}...")
            print(f"    æ¥æº: {result.source}")
            print(f"    åŸå§‹å¯ä¿¡åº¦: {result.credibility_score}")
            print(f"    åŸå§‹ç›¸å…³æ€§: {result.relevance_score:.1f}")
            
            # åŸºæœ¬è´¨é‡è¿‡æ»¤
            if (len(result.title) < 10 or len(result.summary) < 50):
                print(f"    âŒ è¢«è¿‡æ»¤ï¼šæ ‡é¢˜æˆ–æ‘˜è¦å¤ªçŸ­ (æ ‡é¢˜:{len(result.title)}, æ‘˜è¦:{len(result.summary)})")
                continue
            
            # ä½¿ç”¨é¢†åŸŸä¸“ç”¨æ¥æºè®¡ç®—å¯ä¿¡åº¦
            domain_credibility = self._calculate_domain_source_credibility(result.source, domain_sources)
            result.credibility_score = max(result.credibility_score, domain_credibility)
            
            # ä½¿ç”¨é¢†åŸŸå…³é”®è¯è®¡ç®—ç›¸å…³æ€§
            domain_relevance = self._calculate_domain_relevance_score(
                result.title + " " + result.summary, 
                domain_keywords
            )
            result.relevance_score = max(result.relevance_score, domain_relevance)
            
            print(f"    é¢†åŸŸå¯ä¿¡åº¦: {domain_credibility}")
            print(f"    é¢†åŸŸç›¸å…³æ€§: {domain_relevance:.1f}")
            print(f"    æœ€ç»ˆå¯ä¿¡åº¦: {result.credibility_score}")
            print(f"    æœ€ç»ˆç›¸å…³æ€§: {result.relevance_score:.1f}")
            
            # æ”¾å®½è´¨é‡æ ‡å‡† - ä»6åˆ†é™åˆ°5åˆ†
            if result.credibility_score >= 5 and result.relevance_score >= 5:
                print(f"    âœ… é€šè¿‡ç­›é€‰")
                filtered_results.append(result)
            else:
                print(f"    âŒ è¢«è¿‡æ»¤ï¼šè´¨é‡ä¸è¾¾æ ‡ (å¯ä¿¡åº¦:{result.credibility_score}, ç›¸å…³æ€§:{result.relevance_score:.1f})")
        
        print(f"ğŸ“Š ç­›é€‰ç»“æœï¼š{len(filtered_results)}/{len(results)} ä¸ªç»“æœé€šè¿‡")
        return filtered_results

    def _calculate_domain_source_credibility(self, source: str, domain_sources: List[str]) -> int:
        """è®¡ç®—é¢†åŸŸä¸“ç”¨æ¥æºå¯ä¿¡åº¦åˆ†æ•°"""
        source_lower = source.lower()
        
        # ä¼˜å…ˆåŒ¹é…é¢†åŸŸä¸“ç”¨æ¥æº
        for domain_source in domain_sources:
            if domain_source.lower() in source_lower:
                # é¢†åŸŸä¸“ç”¨æ¥æºç»™äºˆæ›´é«˜åˆ†æ•°
                if domain_source in ['nature.com', 'sciencemag.org', 'nejm.org', 'arxiv.org']:
                    return 10
                elif domain_source in ['bloomberg.com', 'reuters.com', 'ft.com']:
                    return 9
                else:
                    return 8
        
        # å›é€€åˆ°é€šç”¨æƒå¨æ¥æºè¯„åˆ†
        return self._calculate_source_credibility(source)

    def _calculate_domain_relevance_score(self, text: str, domain_keywords: List[str]) -> float:
        """è®¡ç®—ä¸é¢†åŸŸå…³é”®è¯çš„ç›¸å…³æ€§åˆ†æ•°"""
        try:
            text_lower = text.lower()
            relevance_score = 0.0
            matched_keywords = 0
            
            print(f"      åˆ†ææ–‡æœ¬: {text_lower[:100]}...")
            print(f"      é¢†åŸŸå…³é”®è¯: {domain_keywords}")
            
            # è®¡ç®—é¢†åŸŸå…³é”®è¯åŒ¹é…åº¦
            for keyword in domain_keywords:
                keyword_lower = keyword.lower()
                keyword_matched = False
                
                if keyword_lower in text_lower:
                    # å®Œæ•´çŸ­è¯­åŒ¹é…ç»™äºˆæ›´é«˜åˆ†æ•°
                    if ' ' in keyword:
                        relevance_score += 4  # æé«˜å®Œæ•´çŸ­è¯­åˆ†æ•°
                        print(f"      âœ… å®Œæ•´çŸ­è¯­åŒ¹é…: '{keyword}' (+4åˆ†)")
                    else:
                        relevance_score += 3  # æé«˜å•è¯åˆ†æ•°
                        print(f"      âœ… å•è¯åŒ¹é…: '{keyword}' (+3åˆ†)")
                    keyword_matched = True
                else:
                    # éƒ¨åˆ†è¯åŒ¹é…
                    keyword_words = keyword_lower.split()
                    partial_matches = 0
                    for word in keyword_words:
                        if len(word) > 2 and word in text_lower:  # é™ä½è¯é•¿åº¦è¦æ±‚
                            partial_matches += 1
                            relevance_score += 1
                            print(f"      âš¡ éƒ¨åˆ†åŒ¹é…: '{word}' (+1åˆ†)")
                    
                    if partial_matches > 0:
                        keyword_matched = True
                
                if keyword_matched:
                    matched_keywords += 1
            
            # æ›´å®½æ¾çš„å½’ä¸€åŒ– - åŸºäºåŒ¹é…çš„å…³é”®è¯æ•°é‡è€Œéæœ€å¤§å¯èƒ½åˆ†æ•°
            if matched_keywords > 0:
                # åŸºç¡€åˆ†æ•° + åŒ¹é…å¥–åŠ±
                base_score = 6.0  # æé«˜åŸºç¡€åˆ†æ•°
                match_bonus = min(relevance_score * 0.5, 4.0)  # åŒ¹é…å¥–åŠ±
                relevance_score = base_score + match_bonus
            else:
                relevance_score = 5.0  # æ²¡æœ‰åŒ¹é…æ—¶çš„åŸºç¡€åˆ†æ•°
            
            print(f"      åŒ¹é…å…³é”®è¯æ•°: {matched_keywords}/{len(domain_keywords)}")
            print(f"      è®¡ç®—ç›¸å…³æ€§: {relevance_score:.1f}")
            
            return min(relevance_score, 10.0)  # æœ€é«˜10åˆ†
            
        except Exception as e:
            print(f"      âŒ ç›¸å…³æ€§è®¡ç®—å‡ºé”™: {e}")
            return 6.0  # æé«˜é»˜è®¤ç›¸å…³æ€§

    def generate_inspiration_report(self, topic: str, results: List[NewsResult], category: Optional[str] = None, domain_name: Optional[str] = None) -> str:
        """ç”Ÿæˆçµæ„ŸæŠ¥å‘Š"""
        
        if not results:
            return f"# ğŸ“° ä¸»é¢˜çµæ„ŸæŠ¥å‘Šï¼š{topic}\n\nâŒ æœªæ‰¾åˆ°ç›¸å…³çš„æƒå¨èµ„è®¯ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯ã€‚"
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_credibility = sum(r.credibility_score for r in results) / len(results)
        avg_relevance = sum(r.relevance_score for r in results) / len(results)
        
        # è·å–åˆ†ç±»æ˜¾ç¤ºå
        category_names = {
            'tech-empowerment': 'ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½',
            'investment-finance': 'ğŸ’° æŠ•èµ„ç†è´¢', 
            'global-perspective': 'ğŸŒ å…¨çƒè§†é‡',
            'cognitive-upgrade': 'ğŸ§  è®¤çŸ¥å‡çº§'
        }
        
        # ä¼˜å…ˆæ˜¾ç¤ºä¸“ä¸šé¢†åŸŸåç§°
        if domain_name:
            category_display = domain_name
        else:
            category_display = category_names.get(category, 'ğŸ” ç»¼åˆæœç´¢') if category else 'ğŸ” ç»¼åˆæœç´¢'
        
        report = f"""# ğŸ“° ä¸»é¢˜çµæ„ŸæŠ¥å‘Šï¼š{topic}

## ğŸ” æœç´¢æ¦‚è¦
- **æœç´¢æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **å†…å®¹åˆ†ç±»**: {category_display}
- **æƒå¨æ¥æºæ•°**: {len(results)}æ¡
- **å¹³å‡å¯ä¿¡åº¦**: {avg_credibility:.1f}/10
- **å¹³å‡ç›¸å…³æ€§**: {avg_relevance:.1f}/10

## ğŸ“‹ æ ¸å¿ƒå‘ç°

"""
        
        for i, result in enumerate(results, 1):
            report += f"""### {i}. {result.title}

**ğŸ“° æ¥æº**: {result.source} (å¯ä¿¡åº¦: {result.credibility_score}/10)  
**ğŸ“… æ—¥æœŸ**: {result.publication_date}  
**ğŸ¯ ç›¸å…³æ€§**: {result.relevance_score:.1f}/10  
{f'**ğŸ”— é“¾æ¥**: {result.url}' if result.url else ''}

**ğŸ“ æ ¸å¿ƒå†…å®¹**:  
{result.summary}

**ğŸ’¡ å…³é”®æ´å¯Ÿ**:
{chr(10).join(f'â€¢ {insight}' for insight in result.key_insights if insight)}

**ğŸ“š åšæ–‡åˆ›ä½œè§’åº¦**:
{chr(10).join(f'â€¢ {angle}' for angle in result.blog_angles if angle)}

---

"""
        
        # æ·»åŠ åˆ›ä½œå»ºè®®
        report += """## ğŸ¨ åˆ›ä½œå»ºè®®

### ğŸ“Š å†…å®¹ç­–ç•¥æ–¹å‘
1. **çƒ­ç‚¹è¿½è¸ª**: åŸºäºä»¥ä¸Šèµ„è®¯çš„æ—¶æ•ˆæ€§ï¼Œå¯ä»¥åˆ›ä½œ"æœ€æ–°åŠ¨æ€è§£è¯»"ç±»æ–‡ç« 
2. **æ·±åº¦åˆ†æ**: ç»“åˆå¤šä¸ªæ¥æºçš„è§‚ç‚¹ï¼Œå½¢æˆç‹¬ç‰¹çš„åˆ†æè§†è§’
3. **ä¸­å›½è§†è§’**: å°†å›½é™…èµ„è®¯ä¸ä¸­å›½å®é™…æƒ…å†µç»“åˆï¼Œæä¾›æœ¬åœ°åŒ–è§è§£
4. **å‰ç»é¢„æµ‹**: åŸºäºå½“å‰è¶‹åŠ¿ï¼Œé¢„æµ‹æœªæ¥å‘å±•æ–¹å‘

### âœï¸ å†™ä½œæŠ€å·§
- **å¼€å¤´å¸å¼•**: ä»¥æœ€æ–°ã€æœ€æƒå¨çš„æ•°æ®æˆ–äº‹ä»¶ä½œä¸ºå¼€å¤´
- **é€»è¾‘æ¸…æ™°**: é‡‡ç”¨"ç°çŠ¶â†’åˆ†æâ†’å½±å“â†’å¯ç¤º"çš„ç»“æ„
- **æ•°æ®æ”¯æ’‘**: å¼•ç”¨æƒå¨æ¥æºçš„å…·ä½“æ•°æ®å’Œä¸“å®¶è§‚ç‚¹
- **å®ç”¨ä»·å€¼**: ä¸ºè¯»è€…æä¾›å¯æ“ä½œçš„å»ºè®®å’Œæ€è€ƒæ¡†æ¶

---

ğŸ“„ *æœ¬æŠ¥å‘Šç”±æœ‰å¿ƒè¨€è€…ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨è‡ªåŠ¨ç”Ÿæˆ*  
ğŸ¤– *åŸºäºGeminiè”ç½‘æœç´¢ + æƒå¨æ¥æºç­›é€‰ç®—æ³•*
"""
        
        return report

    def create_inspired_draft(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """åŸºäºçµæ„Ÿç»“æœåˆ›å»ºæ–‡ç« è‰ç¨¿"""
        try:
            # åˆ›å»ºè‰ç¨¿æ–‡ä»¶å
            safe_topic = re.sub(r'[^\w\s-]', '', topic).strip()
            safe_topic = re.sub(r'[-\s]+', '-', safe_topic)
            timestamp = datetime.now().strftime('%Y-%m-%d')
            
            draft_filename = f"{timestamp}-{safe_topic[:50]}.md"
            draft_path = Path("_drafts") / draft_filename
            
            # ç¡®ä¿è‰ç¨¿ç›®å½•å­˜åœ¨
            draft_path.parent.mkdir(exist_ok=True)
            
            # ç”Ÿæˆè‰ç¨¿å†…å®¹
            draft_content = self._generate_draft_content(topic, results, category)
            
            # ä¿å­˜è‰ç¨¿
            with open(draft_path, 'w', encoding='utf-8') as f:
                f.write(draft_content)
            
            print(f"ğŸ“„ è‰ç¨¿å·²åˆ›å»º: {draft_path}")
            return str(draft_path)
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºè‰ç¨¿å¤±è´¥: {e}")
            return ""

    def _generate_draft_content(self, topic: str, results: List[NewsResult], category: Optional[str] = None) -> str:
        """ç”Ÿæˆè‰ç¨¿å†…å®¹"""
        
        # ç”Ÿæˆæ ‡é¢˜
        title = f"{topic}çš„æœ€æ–°å‘å±•ä¸è¶‹åŠ¿åˆ†æ"
        
        # ç”Ÿæˆæ ‡ç­¾
        basic_tags = ["å…¨çƒè¶‹åŠ¿", "è¡Œä¸šåˆ†æ", "å‰æ²¿èµ„è®¯"]
        
        category_tags = {
            'tech-empowerment': ["æŠ€æœ¯åˆ›æ–°", "æ•°å­—åŒ–è½¬å‹", "ç§‘æŠ€è¶‹åŠ¿"],
            'investment-finance': ["æŠ•èµ„ç­–ç•¥", "é‡‘èå¸‚åœº", "ç»æµåˆ†æ"],
            'global-perspective': ["å›½é™…è§†é‡", "å…¨çƒåŒ–", "è·¨æ–‡åŒ–"],
            'cognitive-upgrade': ["æ€ç»´å‡çº§", "å­¦ä¹ æ–¹æ³•", "è®¤çŸ¥ç§‘å­¦"]
        }
        
        if category and category in category_tags:
            basic_tags.extend(category_tags[category])
        
        # ç”Ÿæˆæ‘˜è¦
        excerpt = f"åŸºäºæœ€æ–°æƒå¨æ¥æºçš„æ·±åº¦åˆ†æï¼Œæ¢è®¨{topic}é¢†åŸŸçš„é‡è¦å‘å±•è¶‹åŠ¿å’Œå½±å“"
        
        # Front Matter
        front_matter = f"""---
title: "{title}"
date: "{datetime.now().strftime('%Y-%m-%d')}"
categories: ["{category or 'global-perspective'}"]
tags: {json.dumps(basic_tags, ensure_ascii=False)}
excerpt: "{excerpt}"
header:
  teaser: "/assets/images/default-teaser.jpg"
layout: "single"
author_profile: true
breadcrumbs: true
comments: true
related: true
share: true
toc: true
toc_icon: "list"
toc_label: "æœ¬é¡µå†…å®¹"
toc_sticky: true
---"""
        
        # æ­£æ–‡å†…å®¹
        content = f"""
è¿‘æœŸï¼Œ{topic}é¢†åŸŸå‡ºç°äº†å¤šé¡¹é‡è¦å‘å±•ï¼Œæ¥è‡ª{', '.join(set(r.source for r in results[:3]))}ç­‰æƒå¨åª’ä½“çš„æŠ¥é“æ˜¾ç¤ºï¼Œè¿™ä¸€é¢†åŸŸæ­£åœ¨ç»å†æ·±åˆ»å˜åŒ–ã€‚

## ğŸ” æœ€æ–°å‘å±•åŠ¨æ€

"""
        
        # æ·»åŠ å„ä¸ªç»“æœçš„å†…å®¹
        for i, result in enumerate(results, 1):
            # æ„å»ºè‹±æ–‡å¼•ç”¨å’Œä¸­æ–‡ç¿»è¯‘ï¼Œæ¸…ç†æ¥æºåç§°æ ¼å¼
            clean_source = result.source
            # ç§»é™¤è¿‡é•¿çš„æ‹¬å·è¯´æ˜ï¼Œä¿ç•™æ ¸å¿ƒæ¥æºåç§°
            if '(' in clean_source and len(clean_source) > 30:
                # æå–ä¸»è¦æ¥æºåç§°ï¼Œç§»é™¤æ‹¬å·ä¸­çš„è¯¦ç»†è¯´æ˜
                main_source = clean_source.split('(')[0].strip()
                if main_source and len(main_source) > 3:
                    clean_source = main_source
            
            english_source_desc = f"According to {clean_source}"
            chinese_source_desc = f"æ®{clean_source}æŠ¥é“"
            
            # å¦‚æœæœ‰URLï¼Œæ·»åŠ é“¾æ¥
            source_link = ""
            if result.url:
                source_link = f" ([åŸæ–‡é“¾æ¥]({result.url}))"
            
            # ä¸ºä¸­æ–‡ç‰ˆæœ¬åˆ›å»ºåŸºäºè‹±æ–‡æ‘˜è¦çš„ä¸­æ–‡æè¿°
            def translate_to_chinese_summary(english_summary: str) -> str:
                """åŸºäºè‹±æ–‡æ‘˜è¦ç”Ÿæˆæœ‰æ„ä¹‰çš„ä¸­æ–‡æ€»ç»“"""
                summary_lower = english_summary.lower()
                
                # æ›´ç²¾ç¡®çš„å…³é”®è¯è¯†åˆ«å’Œä¸­æ–‡ç”Ÿæˆ
                if "brain" in summary_lower or "neural" in summary_lower or "neuron" in summary_lower:
                    if "bci" in summary_lower or "interface" in summary_lower:
                        return "æ–¯å¦ç¦å¤§å­¦ç ”ç©¶äººå‘˜å¼€å‘çš„è„‘æœºæ¥å£æŠ€æœ¯å®ç°é‡å¤§çªç ´ï¼Œä¸ºç˜«ç—ªæ‚£è€…æ¢å¤äº¤æµèƒ½åŠ›å¸¦æ¥æ–°å¸Œæœ›"
                    elif "memory" in summary_lower or "learning" in summary_lower:
                        return "ç¥ç»ç§‘å­¦ç ”ç©¶æ­ç¤ºå¤§è„‘å­¦ä¹ å’Œè®°å¿†çš„æ–°æœºåˆ¶ï¼Œä¸ºç†è§£äººç±»è®¤çŸ¥æä¾›é‡è¦æ´å¯Ÿ"
                    elif "dendrite" in summary_lower or "computation" in summary_lower:
                        return "MITç§‘å­¦å®¶å‘ç°ç¥ç»å…ƒå†…éƒ¨è®¡ç®—çš„æ–°æœºåˆ¶ï¼Œé¢ è¦†äº†ä¼ ç»Ÿçš„å¤§è„‘å·¥ä½œåŸç†è®¤çŸ¥"
                    elif "suppress" in summary_lower or "thought" in summary_lower:
                        return "å‰‘æ¡¥å¤§å­¦ç ”ç©¶å›¢é˜Ÿå‘ç°å¤§è„‘ä¸»åŠ¨æŠ‘åˆ¶ä¸è‰¯æ€ç»´çš„ç¥ç»æœºåˆ¶ï¼Œè§£é‡Šäº†æ€ç»´æ§åˆ¶çš„ç”Ÿç‰©å­¦åŸºç¡€"
                    else:
                        return "æœ€æ–°è„‘ç§‘å­¦ç ”ç©¶åœ¨ç¥ç»æœºåˆ¶ç†è§£æ–¹é¢å–å¾—é‡è¦è¿›å±•ï¼Œä¸ºè®¤çŸ¥ç§‘å­¦å‘å±•æä¾›æ–°çš„ç†è®ºæ”¯æ’‘"
                
                elif "ai" in summary_lower or "artificial intelligence" in summary_lower:
                    return "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ç‰¹å®šé¢†åŸŸå±•ç°å‡ºçªç ´æ€§åº”ç”¨æ½œåŠ›ï¼Œæ¨åŠ¨ç›¸å…³è¡Œä¸šçš„æŠ€æœ¯é©æ–°"
                
                elif "decision" in summary_lower or "uncertainty" in summary_lower:
                    return "ç§‘å­¦å®¶å¯¹å¤§è„‘å†³ç­–æœºåˆ¶çš„ç ”ç©¶å–å¾—æ–°å‘ç°ï¼Œè§£é‡Šäº†äººç±»åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹çš„é€‰æ‹©è¡Œä¸º"
                
                elif "consciousness" in summary_lower or "organoid" in summary_lower:
                    return "ç±»è„‘å™¨å®˜æ„è¯†æ£€æµ‹ç ”ç©¶å¼•å‘ç§‘å­¦ç•Œå…³æ³¨ï¼Œä¸ºæ„è¯†æœ¬è´¨çš„ç†è§£å¼€è¾Ÿæ–°çš„ç ”ç©¶è·¯å¾„"
                
                elif "quantum" in summary_lower:
                    return "é‡å­æŠ€æœ¯é¢†åŸŸçš„æœ€æ–°å‘å±•ä¸ºç›¸å…³åº”ç”¨åœºæ™¯æä¾›äº†æ–°çš„æŠ€æœ¯å¯èƒ½æ€§"
                
                elif "blockchain" in summary_lower or "crypto" in summary_lower:
                    return "åŒºå—é“¾å’ŒåŠ å¯†è´§å¸æŠ€æœ¯çš„å‘å±•ä¸ºæ•°å­—é‡‘èç”Ÿæ€å¸¦æ¥æ–°çš„å˜é©æœºé‡"
                
                else:
                    # åŸºäºå†…å®¹ç±»å‹çš„é€šç”¨ç”Ÿæˆ
                    if "study" in summary_lower or "research" in summary_lower:
                        return f"æœ€æ–°å­¦æœ¯ç ”ç©¶åœ¨{topic}é¢†åŸŸå–å¾—é‡è¦å‘ç°ï¼Œä¸ºç†è®ºå‘å±•å’Œå®é™…åº”ç”¨æä¾›æ–°çš„å¯ç¤º"
                    elif "company" in summary_lower or "launched" in summary_lower:
                        return f"è¡Œä¸šé¢†å…ˆä¼ä¸šåœ¨{topic}é¢†åŸŸçš„é‡è¦ä¸¾æªï¼Œæ ‡å¿—ç€ç›¸å…³æŠ€æœ¯çš„å•†ä¸šåŒ–è¿›ç¨‹åŠ é€Ÿ"
                    else:
                        return f"æƒå¨æœºæ„å‘å¸ƒçš„{topic}é¢†åŸŸåˆ†ææ˜¾ç¤ºï¼Œè¯¥é¢†åŸŸæ­£åœ¨ç»å†é‡è¦çš„å‘å±•å˜åŒ–"
            
            chinese_summary = translate_to_chinese_summary(result.summary)
            
            content += f"""### {i}. {result.title}

**English Source Reference**: {english_source_desc}, {result.summary}{source_link}

**ä¸­æ–‡ç‰ˆæœ¬**: {chinese_source_desc}ï¼Œ{chinese_summary}ã€‚

**å…³é”®æ´å¯Ÿ**ï¼š
{chr(10).join(f'- {insight}' for insight in result.key_insights[:3] if insight)}

"""
        
        content += """<!-- more -->

## ğŸ’¡ æ·±åº¦æ´å¯Ÿä¸è¶‹åŠ¿åˆ†æ

ç»¼åˆä¸Šè¿°æƒå¨ç ”ç©¶å‘ç°ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°ä»¥ä¸‹å…³é”®è¶‹åŠ¿å’Œæ·±å±‚å«ä¹‰ï¼š

### ğŸ§  æŠ€æœ¯çªç ´çš„å…±åŒæ¨¡å¼
è¿™äº›ç ”ç©¶å±•ç°äº†å½“å‰ç§‘å­¦å‘å±•çš„å‡ ä¸ªé‡è¦ç‰¹å¾ï¼šç²¾å¯†æµ‹é‡æŠ€æœ¯çš„è¿›æ­¥ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿæ›´æ·±å…¥åœ°è§‚å¯Ÿå’Œç†è§£å¤æ‚ç³»ç»Ÿçš„è¿ä½œæœºåˆ¶ï¼Œè·¨å­¦ç§‘èåˆæ­£åœ¨äº§ç”Ÿçªç ´æ€§çš„å‘ç°å’Œåº”ç”¨ã€‚

### ğŸŒŸ åº”ç”¨å‰æ™¯ä¸ç¤¾ä¼šä»·å€¼  
ä»å®é™…åº”ç”¨è§’åº¦æ¥çœ‹ï¼Œè¿™äº›å‘ç°ä¸ä»…æ¨è¿›äº†åŸºç¡€ç§‘å­¦ç ”ç©¶ï¼Œæ›´ä¸ºè§£å†³å®é™…é—®é¢˜æä¾›äº†æ–°çš„è·¯å¾„å’Œå·¥å…·ï¼Œå…¶æ½œåœ¨çš„ç¤¾ä¼šä»·å€¼å’Œç»æµæ•ˆç›Šå€¼å¾—æŒç»­å…³æ³¨ã€‚

### ğŸ¯ å¯¹ä¸ªäººå‘å±•çš„å¯ç¤º
å¯¹äºå…³æ³¨è¯¥é¢†åŸŸå‘å±•çš„äººå£«è€Œè¨€ï¼Œä¿æŒå¯¹å‰æ²¿ç ”ç©¶çš„æ•æ„Ÿæ€§ï¼Œç†è§£æŠ€æœ¯å‘å±•çš„å†…åœ¨é€»è¾‘ï¼Œå¹¶æ€è€ƒå¦‚ä½•å°†è¿™äº›æ–°çŸ¥è¯†åº”ç”¨åˆ°è‡ªå·±çš„å·¥ä½œå’Œç”Ÿæ´»ä¸­ï¼Œå°†æ˜¯è·å¾—ç«äº‰ä¼˜åŠ¿çš„é‡è¦é€”å¾„ã€‚

## ğŸ“š å‚è€ƒèµ„æº

"""
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¥æºéƒ½æ˜¯è‹±æ–‡æƒå¨æ¥æº
        english_sources = {
            'nature.com', 'sciencemag.org', 'thelancet.com', 'nejm.org', 'arxiv.org', 
            'statnews.com', 'healthtechmagazine.net', 'mobihealthnews.com',
            'bloomberg.com', 'reuters.com', 'ft.com', 'wsj.com', 'nytimes.com',
            'bbc.com', 'guardian.com', 'techcrunch.com', 'wired.com'
        }
        
        all_english = all(any(eng_source in result.source.lower() for eng_source in english_sources) 
                         for result in results)
        
        if all_english:
            # å¦‚æœå…¨éƒ¨æ˜¯è‹±æ–‡æƒå¨æ¥æºï¼Œä½¿ç”¨ç®€æ´æ ¼å¼
            content += "### Authoritative Sources:\n\n"
            for i, result in enumerate(results, 1):
                if result.url:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   *{result.source}* | [{result.publication_date}]({result.url})  \n\n"
                else:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   *{result.source}* | {result.publication_date}  \n\n"
        else:
            # å¦‚æœæœ‰ä¸­æ–‡æˆ–å…¶ä»–æ¥æºï¼Œä½¿ç”¨å®Œæ•´æ ¼å¼
            content += "### English Sources:\n\n"
            for i, result in enumerate(results, 1):
                if result.url:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   Source: {result.source}  \n"
                    content += f"   Link: [{result.url}]({result.url})  \n"
                    content += f"   Date: {result.publication_date}\n\n"
                else:
                    content += f"{i}. **{result.title}**  \n"
                    content += f"   Source: {result.source}  \n"
                    content += f"   Date: {result.publication_date}\n\n"
            
            content += "\n### ä¸­æ–‡æ¥æºè¯´æ˜ï¼š\n\n"
            for i, result in enumerate(results, 1):
                content += f"{i}. {result.title} - æ¥æºï¼š{result.source}\n"
        
        content += f"""
---

*æœ¬æ–‡åŸºäº{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}çš„æƒå¨æ¥æºä¿¡æ¯æ•´ç†ï¼Œæ•°æ®æ¥æºåŒ…æ‹¬{', '.join(set(r.source for r in results))}ç­‰ã€‚*
"""
        
        return front_matter + content

    def _load_inspiration_status(self) -> Dict[str, Any]:
        """åŠ è½½çµæ„ŸæŠ¥å‘ŠçŠ¶æ€"""
        try:
            if self.status_file.exists():
                with open(self.status_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {"reports": [], "last_updated": datetime.now().isoformat()}
        except Exception as e:
            print(f"âš ï¸ åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return {"reports": [], "last_updated": datetime.now().isoformat()}

    def _save_inspiration_status(self, status: Dict[str, Any]) -> None:
        """ä¿å­˜çµæ„ŸæŠ¥å‘ŠçŠ¶æ€"""
        try:
            status["last_updated"] = datetime.now().isoformat()
            with open(self.status_file, 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")

    def _record_inspiration_report(self, report_file: str, topic: str, domain_name: Optional[str] = None, 
                                 draft_path: Optional[str] = None) -> None:
        """è®°å½•ç”Ÿæˆçš„çµæ„ŸæŠ¥å‘Š"""
        status = self._load_inspiration_status()
        
        report_record = {
            "id": datetime.now().strftime('%Y%m%d-%H%M%S'),
            "report_file": str(report_file),
            "topic": topic,
            "domain_name": domain_name,
            "created_time": datetime.now().isoformat(),
            "draft_created": draft_path is not None,
            "draft_path": str(draft_path) if draft_path else None,
            "draft_exists": Path(draft_path).exists() if draft_path else False,
            "status": "active"
        }
        
        status["reports"].append(report_record)
        self._save_inspiration_status(status)
        
    def get_inspiration_history(self) -> List[Dict[str, Any]]:
        """è·å–çµæ„ŸæŠ¥å‘Šå†å²"""
        status = self._load_inspiration_status()
        reports = status.get("reports", [])
        
        # æ›´æ–°è‰ç¨¿å­˜åœ¨çŠ¶æ€
        for report in reports:
            if report.get("draft_path"):
                report["draft_exists"] = Path(report["draft_path"]).exists()
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        reports.sort(key=lambda x: x.get("created_time", ""), reverse=True)
        return reports
        
    def clean_inspiration_reports(self, keep_days: int = 30) -> Dict[str, int]:
        """æ¸…ç†æ—§çš„çµæ„ŸæŠ¥å‘Š"""
        from datetime import timedelta
        
        cutoff_date = datetime.now() - timedelta(days=keep_days)
        status = self._load_inspiration_status()
        reports = status.get("reports", [])
        
        cleaned_count = 0
        orphan_count = 0
        kept_reports = []
        
        for report in reports:
            try:
                report_time = datetime.fromisoformat(report["created_time"])
                report_file = Path(report["report_file"])
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ä¿ç•™æœŸ
                if report_time < cutoff_date:
                    # åˆ é™¤æŠ¥å‘Šæ–‡ä»¶
                    if report_file.exists():
                        report_file.unlink()
                        cleaned_count += 1
                    
                    # å¦‚æœæœ‰å¯¹åº”çš„è‰ç¨¿ä¸”å·²è¢«åˆ é™¤ï¼Œæ ‡è®°ä¸ºorphan
                    if report.get("draft_path") and not Path(report["draft_path"]).exists():
                        report["status"] = "draft_deleted"
                        orphan_count += 1
                else:
                    # ä¿ç•™çš„æŠ¥å‘Šï¼Œæ›´æ–°è‰ç¨¿çŠ¶æ€
                    if report.get("draft_path"):
                        report["draft_exists"] = Path(report["draft_path"]).exists()
                        if not report["draft_exists"] and report["status"] == "active":
                            report["status"] = "draft_deleted"
                            orphan_count += 1
                    kept_reports.append(report)
                    
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æŠ¥å‘Šè®°å½•æ—¶å‡ºé”™: {e}")
                kept_reports.append(report)
        
        # æ›´æ–°çŠ¶æ€
        status["reports"] = kept_reports
        self._save_inspiration_status(status)
        
        return {
            "cleaned": cleaned_count,
            "orphaned": orphan_count,
            "remaining": len(kept_reports)
        }

def main():
    """ä¸»å‡½æ•° - ä¾›ç‹¬ç«‹è¿è¡Œä½¿ç”¨"""
    print("ğŸ’¡ ä¸»é¢˜çµæ„Ÿç”Ÿæˆå™¨ - ä¸“ä¸šåŒ–ç‰ˆæœ¬")
    print("="*60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°GEMINI_API_KEYæˆ–GOOGLE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Gemini APIå¯†é’¥")
        return
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
        generator = TopicInspirationGenerator()
        
        # æ˜¾ç¤ºæœç´¢æ¨¡å¼é€‰æ‹©
        print("\nğŸ” è¯·é€‰æ‹©æœç´¢æ¨¡å¼ï¼š")
        print("1. ğŸ“š ä¸“ä¸šé¢†åŸŸæœç´¢ - åŸºäºé¢„è®¾çš„ä¸“ä¸šé¢†åŸŸçŸ¥è¯†åº“")
        print("2. ğŸ” è‡ªå®šä¹‰ä¸»é¢˜æœç´¢ - åŸºäºç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜")
        
        mode_choice = input("è¯·é€‰æ‹©æ¨¡å¼ (1-2): ").strip()
        
        results = []
        topic_name = ""
        domain_name = None
        category = None
        
        if mode_choice == "1":
            # ä¸“ä¸šé¢†åŸŸæœç´¢æ¨¡å¼
            domains = generator.list_available_domains()
            
            if not domains:
                print("âŒ æœªæ‰¾åˆ°ä¸“ä¸šé¢†åŸŸé…ç½®ï¼Œå›é€€åˆ°è‡ªå®šä¹‰æœç´¢æ¨¡å¼")
                mode_choice = "2"
            else:
                print("\nğŸ“‹ å¯ç”¨çš„ä¸“ä¸šé¢†åŸŸï¼š")
                for i, (domain_id, display_name, description) in enumerate(domains, 1):
                    print(f"{i}. {display_name}")
                    print(f"   {description}")
                    print()
                
                domain_choice = input(f"è¯·é€‰æ‹©é¢†åŸŸ (1-{len(domains)}): ").strip()
                try:
                    domain_index = int(domain_choice) - 1
                    if 0 <= domain_index < len(domains):
                        domain_id, display_name, description = domains[domain_index]
                        domain_name = display_name
                        topic_name = display_name.replace('ğŸ¥ ', '').replace('âš›ï¸ ', '').replace('ğŸ’³ ', '').replace('ğŸŒ± ', '').replace('ğŸ§  ', '').replace('ğŸš€ ', '')
                        
                        print(f"\nğŸ¯ é€‰æ‹©é¢†åŸŸ: {display_name}")
                        print(f"ğŸ“ æè¿°: {description}")
                        
                        # è·å–é¢†åŸŸé…ç½®ä¸­çš„category
                        domain_config = generator.domains.get(domain_id, {})
                        category = domain_config.get('category', 'global-perspective')
                        
                        # æ‰§è¡Œä¸“ä¸šé¢†åŸŸæœç´¢
                        results = generator.get_domain_inspiration(domain_id)
                    else:
                        print("âŒ é€‰æ‹©æ— æ•ˆï¼Œå›é€€åˆ°è‡ªå®šä¹‰æœç´¢")
                        mode_choice = "2"
                except (ValueError, IndexError):
                    print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œå›é€€åˆ°è‡ªå®šä¹‰æœç´¢")
                    mode_choice = "2"
        
        if mode_choice == "2":
            # è‡ªå®šä¹‰ä¸»é¢˜æœç´¢æ¨¡å¼
            topic = input("\nè¯·è¾“å…¥è¦æ¢ç´¢çš„ä¸»é¢˜: ").strip()
            if not topic:
                print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
                return
            
            topic_name = topic
            
            print("\né€‰æ‹©å†…å®¹åˆ†ç±» (å¯é€‰):")
            print("1. ğŸ§  è®¤çŸ¥å‡çº§")
            print("2. ğŸ› ï¸ æŠ€æœ¯èµ‹èƒ½") 
            print("3. ğŸŒ å…¨çƒè§†é‡")
            print("4. ğŸ’° æŠ•èµ„ç†è´¢")
            print("5. ä¸é™åˆ†ç±»")
            
            category_choice = input("è¯·é€‰æ‹© (1-5): ").strip()
            category_map = {
                '1': 'cognitive-upgrade',
                '2': 'tech-empowerment', 
                '3': 'global-perspective',
                '4': 'investment-finance'
            }
            
            category = category_map.get(category_choice)
            
            # æ‰§è¡Œä¼ ç»Ÿä¸»é¢˜æœç´¢
            results = generator.get_topic_inspiration(topic, category)
        
        # å¤„ç†æœç´¢ç»“æœ
        if results:
            # ç”ŸæˆæŠ¥å‘Š
            report = generator.generate_inspiration_report(topic_name, results, category, domain_name)
            
            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            safe_topic = re.sub(r'[^\w\s-]', '', topic_name)[:20]
            report_file = generator.output_dir / f"{safe_topic}-{timestamp}.md"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"\nâœ… çµæ„ŸæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            print(f"ğŸ“Š æ‰¾åˆ° {len(results)} æ¡æƒå¨èµ„è®¯")
            
            # æ˜¾ç¤ºç»“æœæ¦‚è¦
            for i, result in enumerate(results, 1):
                credibility_emoji = "ğŸŒŸ" if result.credibility_score >= 9 else "â­" if result.credibility_score >= 7 else "ğŸ“°"
                date_display = f" - {result.publication_date}" if result.publication_date else ""
                print(f"  {i}. {credibility_emoji} {result.title} ({result.source}{date_display})")
            
            # è¯¢é—®æ˜¯å¦åˆ›å»ºè‰ç¨¿
            create_draft = input("\næ˜¯å¦åŸºäºè¿™äº›çµæ„Ÿåˆ›å»ºæ–‡ç« è‰ç¨¿ï¼Ÿ(y/N): ").strip().lower()
            if create_draft in ['y', 'yes']:
                draft_path = generator.create_inspired_draft(topic_name, results, category)
                if draft_path:
                    print(f"ğŸ“„ è‰ç¨¿å·²åˆ›å»º: {draft_path}")
                    print("ğŸ’¡ è‰ç¨¿ä½¿ç”¨è¯´æ˜:")
                    print("   â€¢ è‰ç¨¿å·²è‡ªåŠ¨ç”ŸæˆFront Matterå’ŒåŸºç¡€ç»“æ„")
                    print("   â€¢ åŒ…å«äº†æ‰€æœ‰æƒå¨æ¥æºçš„å…³é”®æ´å¯Ÿ")
                    print("   â€¢ å¯ä»¥ç›´æ¥ç¼–è¾‘å®Œå–„åå‘å¸ƒ")
                    print("   â€¢ æˆ–ä½¿ç”¨ä¸»ç¨‹åºçš„'å¤„ç†ç°æœ‰è‰ç¨¿'åŠŸèƒ½è¿›è¡Œå‘å¸ƒ")
                    
                    # è®°å½•çµæ„ŸæŠ¥å‘Šå’Œè‰ç¨¿
                    generator._record_inspiration_report(str(report_file), topic_name, domain_name, draft_path)
                else:
                    # åªè®°å½•çµæ„ŸæŠ¥å‘Š
                    generator._record_inspiration_report(str(report_file), topic_name, domain_name)
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³æƒå¨èµ„è®¯ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯æˆ–é¢†åŸŸ")
            
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()