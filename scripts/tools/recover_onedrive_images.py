#!/usr/bin/env python3
"""
OneDriveå›¾ç‰‡æ¢å¤å·¥å…·
ä»OneDriveç´¢å¼•æ¢å¤å›¾ç‰‡åˆ°åŸå§‹æœ¬åœ°ç›®å½•ï¼Œä¿æŒåŸæœ‰æ–‡ä»¶å
"""

import json
import requests
import os
from pathlib import Path
from typing import Dict, List, Optional
import argparse
from urllib.parse import urlparse, parse_qs
import re

class OneDriveImageRecovery:
    def __init__(self, index_file: str = "_data/onedrive_image_index.json"):
        self.index_file = Path(index_file)
        self.index_data = self.load_index()
    
    def load_index(self) -> Dict:
        """åŠ è½½OneDriveç´¢å¼•æ–‡ä»¶"""
        try:
            with open(self.index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ ç´¢å¼•æ–‡ä»¶æœªæ‰¾åˆ°: {self.index_file}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ ç´¢å¼•æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            return {}
    
    def extract_original_info(self, record: Dict) -> Optional[Dict]:
        """ä»ç´¢å¼•è®°å½•ä¸­æå–åŸå§‹æ–‡ä»¶ä¿¡æ¯"""
        try:
            # ä»Windowsè·¯å¾„æ¨æ–­åŸå§‹æ–‡ä»¶ä¿¡æ¯
            local_path = record.get('local_path', '')
            filename = record.get('filename', '')
            
            # å¦‚æœlocal_pathåŒ…å«Windowsè·¯å¾„ï¼Œè§£æå‡ºåŸå§‹ç›®å½•
            if '\\' in local_path:
                # Windowsè·¯å¾„æ ¼å¼
                original_dir = Path(local_path).parent
                original_filename = Path(local_path).name
            else:
                # é¡¹ç›®å†…è·¯å¾„ï¼Œä½¿ç”¨æ–‡ä»¶åå’Œæ¨æ–­çš„ç›®å½•
                # å¯¹äºæ¡Œé¢å›¾ç‰‡ï¼Œæ¢å¤åˆ°é¡¹ç›®ä¸´æ—¶ç›®å½•
                original_dir = Path("temp/recovered_images") 
                original_filename = filename
            
            return {
                'original_dir': str(original_dir),
                'original_filename': original_filename,
                'download_url': record.get('onedrive_url', ''),
                'article_title': record.get('article_title', ''),
                'upload_date': record.get('upload_date', '')
            }
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è§£æè®°å½•: {e}")
            return None
    
    def convert_to_direct_download_url(self, share_url: str) -> str:
        """å°†OneDriveåˆ†äº«é“¾æ¥è½¬æ¢ä¸ºç›´æ¥ä¸‹è½½é“¾æ¥"""
        try:
            # å¯¹äºSharePointé“¾æ¥æ ¼å¼
            if 'sharepoint.com' in share_url and ':i:' in share_url:
                # æå–åŸºç¡€URLå’Œæ–‡ä»¶ID
                base_match = re.search(r'(https://[^/]+)', share_url)
                if base_match:
                    base_url = base_match.group(1)
                    # è½¬æ¢ä¸ºç›´æ¥ä¸‹è½½æ ¼å¼
                    if '/personal/' in share_url:
                        personal_part = share_url.split('/personal/')[1].split('/')[0]
                        # æ„å»ºä¸‹è½½é“¾æ¥ - è¿™é‡Œå¯èƒ½éœ€è¦æ ¹æ®å®é™…é“¾æ¥æ ¼å¼è°ƒæ•´
                        return f"{base_url}/personal/{personal_part}/_layouts/15/download.aspx"
            
            # å¦‚æœå·²ç»æ˜¯ä¸‹è½½é“¾æ¥ï¼Œç›´æ¥è¿”å›
            if 'download.aspx' in share_url:
                return share_url
                
            # å¯¹äºå…¶ä»–æ ¼å¼ï¼Œå°è¯•æ·»åŠ ä¸‹è½½å‚æ•°
            return share_url + "&download=1" if '?' in share_url else share_url + "?download=1"
            
        except Exception as e:
            print(f"âš ï¸ URLè½¬æ¢å¤±è´¥: {e}")
            return share_url
    
    def download_image(self, url: str, target_path: Path) -> bool:
        """ä¸‹è½½å›¾ç‰‡åˆ°æŒ‡å®šè·¯å¾„"""
        try:
            target_path.parent.mkdir(parents=True, exist_ok=True)
            
            # è½¬æ¢ä¸ºç›´æ¥ä¸‹è½½é“¾æ¥
            download_url = self.convert_to_direct_download_url(url)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            print(f"ğŸ“¥ ä¸‹è½½: {target_path.name}")
            response = requests.get(download_url, headers=headers, stream=True, timeout=30)
            
            if response.status_code == 200:
                with open(target_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {target_path}")
                return True
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥ ({response.status_code}): {target_path.name}")
                return False
                
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            return False
    
    def recover_images_for_article(self, article_title: str) -> Dict:
        """æ¢å¤æŒ‡å®šæ–‡ç« çš„æ‰€æœ‰å›¾ç‰‡"""
        recovered = []
        failed = []
        
        print(f"\nğŸ”„ å¼€å§‹æ¢å¤æ–‡ç« å›¾ç‰‡: {article_title}")
        
        for key, record in self.index_data.items():
            if record.get('article_title') == article_title:
                info = self.extract_original_info(record)
                if not info:
                    failed.append(f"æ— æ³•è§£æè®°å½•: {key}")
                    continue
                
                # æ„å»ºç›®æ ‡è·¯å¾„
                if info['original_dir'].startswith('c:') or info['original_dir'].startswith('C:'):
                    # Windowsè·¯å¾„ï¼Œè½¬æ¢ä¸ºWSLæ ¼å¼å¹¶æ¢å¤åˆ°é¡¹ç›®ä¸´æ—¶ç›®å½•
                    target_dir = Path("temp/recovered_images/desktop")
                else:
                    # é¡¹ç›®å†…è·¯å¾„ï¼Œæ¢å¤åˆ°åŸä½ç½®
                    target_dir = Path(info['original_dir'])
                
                target_path = target_dir / info['original_filename']
                
                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯¢é—®æ˜¯å¦è¦†ç›–
                if target_path.exists():
                    response = input(f"æ–‡ä»¶å·²å­˜åœ¨: {target_path}\næ˜¯å¦è¦†ç›–? (y/N): ").strip().lower()
                    if response != 'y':
                        print(f"â­ï¸ è·³è¿‡: {target_path.name}")
                        continue
                
                # ä¸‹è½½å›¾ç‰‡
                if self.download_image(info['download_url'], target_path):
                    recovered.append(str(target_path))
                else:
                    failed.append(f"{info['original_filename']}: ä¸‹è½½å¤±è´¥")
        
        return {
            'recovered': recovered,
            'failed': failed,
            'total': len(recovered) + len(failed)
        }
    
    def recover_all_images(self) -> Dict:
        """æ¢å¤æ‰€æœ‰å›¾ç‰‡"""
        print("ğŸ”„ å¼€å§‹æ¢å¤æ‰€æœ‰å›¾ç‰‡...")
        
        all_recovered = []
        all_failed = []
        
        # æŒ‰æ–‡ç« åˆ†ç»„å¤„ç†
        articles = set(record.get('article_title', '') for record in self.index_data.values())
        
        for article in articles:
            if article:
                result = self.recover_images_for_article(article)
                all_recovered.extend(result['recovered'])
                all_failed.extend(result['failed'])
        
        return {
            'recovered': all_recovered,
            'failed': all_failed,
            'total': len(all_recovered) + len(all_failed)
        }
    
    def list_recoverable_images(self) -> None:
        """åˆ—å‡ºå¯æ¢å¤çš„å›¾ç‰‡"""
        print("\nğŸ“‹ å¯æ¢å¤çš„å›¾ç‰‡åˆ—è¡¨:")
        print("=" * 60)
        
        articles = {}
        for key, record in self.index_data.items():
            article = record.get('article_title', 'æœªçŸ¥æ–‡ç« ')
            if article not in articles:
                articles[article] = []
            
            info = self.extract_original_info(record)
            if info:
                articles[article].append({
                    'filename': info['original_filename'],
                    'original_dir': info['original_dir'],
                    'upload_date': info['upload_date']
                })
        
        for article, images in articles.items():
            print(f"\nğŸ“„ {article}")
            print(f"   å›¾ç‰‡æ•°é‡: {len(images)}")
            for img in images:
                print(f"   ğŸ“¸ {img['filename']}")
                print(f"      åŸå§‹ç›®å½•: {img['original_dir']}")
                print(f"      ä¸Šä¼ æ—¶é—´: {img['upload_date']}")

def main():
    parser = argparse.ArgumentParser(description="OneDriveå›¾ç‰‡æ¢å¤å·¥å…·")
    parser.add_argument('--article', '-a', help="æ¢å¤æŒ‡å®šæ–‡ç« çš„å›¾ç‰‡")
    parser.add_argument('--all', action='store_true', help="æ¢å¤æ‰€æœ‰å›¾ç‰‡")
    parser.add_argument('--list', '-l', action='store_true', help="åˆ—å‡ºå¯æ¢å¤çš„å›¾ç‰‡")
    parser.add_argument('--index', '-i', default="_data/onedrive_image_index.json", 
                       help="ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    recovery = OneDriveImageRecovery(args.index)
    
    if not recovery.index_data:
        print("âŒ æ— å¯ç”¨çš„ç´¢å¼•æ•°æ®")
        return
    
    if args.list:
        recovery.list_recoverable_images()
    elif args.article:
        result = recovery.recover_images_for_article(args.article)
        print(f"\nğŸ“Š æ¢å¤ç»“æœ:")
        print(f"âœ… æˆåŠŸ: {len(result['recovered'])} ä¸ªæ–‡ä»¶")
        print(f"âŒ å¤±è´¥: {len(result['failed'])} ä¸ªæ–‡ä»¶")
        if result['failed']:
            print("å¤±è´¥è¯¦æƒ…:")
            for failure in result['failed']:
                print(f"  - {failure}")
    elif args.all:
        result = recovery.recover_all_images()
        print(f"\nğŸ“Š æ¢å¤ç»“æœ:")
        print(f"âœ… æˆåŠŸ: {len(result['recovered'])} ä¸ªæ–‡ä»¶")
        print(f"âŒ å¤±è´¥: {len(result['failed'])} ä¸ªæ–‡ä»¶")
        if result['failed']:
            print("å¤±è´¥è¯¦æƒ…:")
            for failure in result['failed']:
                print(f"  - {failure}")
    else:
        parser.print_help()

if __name__ == "__main__":
    main()