"""
ÂÜÖÂÆπÊâìÂåÖÂàõÂª∫Âô®
Áî®‰∫éËá™Âä®ÁîüÊàêPDFÂíåËµÑÊñôÂåÖZIPÊñá‰ª∂ÔºåÊîØÊåÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂÜÖÂÆπÂèòÁé∞Á≥ªÁªü
"""

import os
import re
import zipfile
import tempfile
import requests
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
import json
import frontmatter
from urllib.parse import urlparse
import markdown2
from weasyprint import HTML, CSS
from weasyprint.text.fonts import FontConfiguration

# ÈÖçÁΩÆweasyprintÂíåÁõ∏ÂÖ≥Â∫ìÁöÑÊó•ÂøóÁ∫ßÂà´
logging.getLogger('weasyprint').setLevel(logging.ERROR)
logging.getLogger('fontTools').setLevel(logging.ERROR)
logging.getLogger('fontTools.subset').setLevel(logging.ERROR)
logging.getLogger('fontTools.ttLib').setLevel(logging.ERROR)


class PackageCreator:
    """ÂÜÖÂÆπÂåÖÂàõÂª∫Âô®"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # È°πÁõÆË∑ØÂæÑ
        self.project_root = Path(__file__).parent.parent.parent
        self.output_dir = self.project_root / ".tmp/output/packages"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ËµÑÊñôÊ∏ÖÂçïÊ®°Êùø
        self.resource_list_template = """# üì¶ ËµÑÊñôÂåÖÊ∏ÖÂçï

## üìÑ ÊñáÁ´†‰ø°ÊÅØ
- **Ê†áÈ¢ò**: {title}
- **ÂèëÂ∏ÉÊó•Êúü**: {date}
- **ÁîüÊàêÊó∂Èó¥**: {generated_at}

## üìÅ ÂåÖÂê´Êñá‰ª∂

### 1. ÂÆåÊï¥ÊñáÁ´†PDF
- `{article_filename}.pdf` - È´òË¥®ÈáèPDFÁâàÊú¨ÔºåÈÄÇÂêà‰øùÂ≠òÂíåÊâìÂç∞

### 2. È´òÊ∏ÖÂõæÁâáËµÑÊ∫ê
{image_list}

### 3. ÂèÇËÄÉËµÑÊñô
- `ËµÑÊñôÊ∏ÖÂçï.md` - Êú¨Êñá‰ª∂ÔºåÂåÖÂê´ÊâÄÊúâËµÑÊ∫êÈìæÊé•
- `ÈìæÊé•Ê±áÊÄª.txt` - ÊñáÁ´†‰∏≠ÊèêÂà∞ÁöÑÊâÄÊúâÂ§ñÈÉ®ÈìæÊé•

## üîó Âú®Á∫øËµÑÊ∫êÈìæÊé•

### üé¨ ËßÜÈ¢ë/Èü≥È¢ëËµÑÊ∫ê
{youtube_links}

### ÂÆòÊñπ‰ø°ÊÅØÊù•Ê∫ê
{official_links}

### Êâ©Â±ïÈòÖËØª
{additional_links}

## üí° ‰ΩøÁî®ËØ¥Êòé

1. **PDFÈòÖËØª**: Êé®Ëçê‰ΩøÁî®Adobe ReaderÊàñÂÖ∂‰ªñPDFÈòÖËØªÂô®
2. **ÂõæÁâáÊü•Áúã**: ÊâÄÊúâÂõæÁâáÂùá‰∏∫È´òÊ∏ÖÁâàÊú¨ÔºåÂèØÁõ¥Êé•‰ΩøÁî®
3. **ÈìæÊé•ËÆøÈóÆ**: ÈÉ®ÂàÜÈìæÊé•ÂèØËÉΩÈúÄË¶ÅÁßëÂ≠¶‰∏äÁΩëÂ∑•ÂÖ∑
4. **Êõ¥Êñ∞Ëé∑Âèñ**: ÂÖ≥Ê≥®ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑"ÊúâÂøÉË®ÄËÄÖ"Ëé∑ÂèñÊúÄÊñ∞ÂÜÖÂÆπ

## üìû ËÅîÁ≥ªÊñπÂºè

- **ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑**: ÊúâÂøÉË®ÄËÄÖ
- **ÂçöÂÆ¢**: https://zhurong2020.github.io
- **ÈÇÆÁÆ±**: ÈÄöËøáÂÖ¨‰ºóÂè∑ËÅîÁ≥ª

---

ÊÑüË∞¢ÊÇ®ÁöÑÊîØÊåÅÔºÅÂ¶ÇÊûúËßâÂæóÊúâ‰ª∑ÂÄºÔºåÊ¨¢ËøéÂàÜ‰∫´ÁªôÊõ¥Â§öÊúãÂèã„ÄÇ

*Ê≠§ËµÑÊñôÂåÖÁî±Ëá™Âä®ÂåñÁ≥ªÁªüÁîüÊàêÔºåÂ¶ÇÊúâÈóÆÈ¢òËØ∑ÈÄöËøáÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂèçÈ¶à„ÄÇ*
"""
    
    def create_package(self, article_path: str, include_images: bool = True, 
                      include_links: bool = True) -> Tuple[bool, Dict]:
        """
        ÂàõÂª∫ÂÆåÊï¥ÁöÑÂÜÖÂÆπÂåÖ
        
        Args:
            article_path: ÊñáÁ´†Êñá‰ª∂Ë∑ØÂæÑ
            include_images: ÊòØÂê¶ÂåÖÂê´ÂõæÁâá
            include_links: ÊòØÂê¶ÂåÖÂê´ÈìæÊé•Ê±áÊÄª
            
        Returns:
            (success, result_info)
        """
        try:
            article_file = Path(article_path)
            if not article_file.exists():
                return False, {"error": f"ÊñáÁ´†Êñá‰ª∂‰∏çÂ≠òÂú®: {article_path}"}
            
            # Ëß£ÊûêÊñáÁ´†
            with open(article_file, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            article_title = str(post.metadata.get('title', article_file.stem))
            article_date = str(post.metadata.get('date', ''))
            
            self.logger.info(f"ÂºÄÂßãÂàõÂª∫ÂÜÖÂÆπÂåÖ: {article_title}")
            
            # ÂàõÂª∫‰∏¥Êó∂Â∑•‰ΩúÁõÆÂΩï
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                
                # 1. ÁîüÊàêPDF
                pdf_success, pdf_path = self._create_pdf(post, temp_path, article_title)
                if not pdf_success:
                    return False, {"error": "PDFÁîüÊàêÂ§±Ë¥•"}
                
                # 2. Êî∂ÈõÜÂõæÁâá
                images_info = []
                if include_images:
                    images_info = self._collect_images(post.content, temp_path)
                
                # 3. ÊèêÂèñÈìæÊé•
                links_info = []
                if include_links:
                    links_info = self._extract_links(post.content)
                    self._create_links_file(links_info, temp_path)
                
                # 4. ÁîüÊàêËµÑÊñôÊ∏ÖÂçï
                self._create_resource_list(
                    article_title, article_date, images_info, links_info, temp_path, post.content
                )
                
                # 5. ÂàõÂª∫ZIPÊñá‰ª∂
                package_success, package_path = self._create_zip_package(
                    temp_path, article_title, article_date
                )
                
                if package_success and package_path:
                    result = {
                        "package_path": str(package_path),
                        "title": article_title,
                        "date": article_date,
                        "files": {
                            "pdf": f"{self._safe_filename(article_title)}.pdf",
                            "images_count": len(images_info),
                            "links_count": len(links_info)
                        },
                        "size_mb": round(package_path.stat().st_size / (1024 * 1024), 2)
                    }
                    
                    self.logger.info(f"‚úÖ ÂÜÖÂÆπÂåÖÂàõÂª∫ÊàêÂäü: {package_path}")
                    return True, result
                else:
                    return False, {"error": "ZIPÊâìÂåÖÂ§±Ë¥•"}
                    
        except Exception as e:
            error_msg = f"ÂàõÂª∫ÂÜÖÂÆπÂåÖÊó∂ÂèëÁîüÈîôËØØ: {e}"
            self.logger.error(error_msg)
            return False, {"error": error_msg}
    
    def _create_pdf(self, post: frontmatter.Post, temp_path: Path, 
                   title: str) -> Tuple[bool, Optional[Path]]:
        """ÁîüÊàêPDFÊñá‰ª∂"""
        try:
            # ÂáÜÂ§áHTMLÂÜÖÂÆπ
            html_content = self._prepare_html_for_pdf(post, title)
            
            # CSSÊ†∑Âºè
            css_content = """
            @page {
                size: A4;
                margin: 2cm;
            }
            
            body {
                font-family: "Noto Sans CJK SC", "Source Han Sans CN", "PingFang SC", "Microsoft YaHei", "SimHei", "DejaVu Sans", "Liberation Sans", "Arial", sans-serif;
                line-height: 1.6;
                color: #333;
                font-size: 14px;
            }
            
            h1 {
                color: #2c3e50;
                border-bottom: 3px solid #3498db;
                padding-bottom: 10px;
                margin-bottom: 30px;
                font-size: 24px;
            }
            
            h2 {
                color: #34495e;
                margin-top: 30px;
                margin-bottom: 15px;
                font-size: 20px;
            }
            
            h3 {
                color: #7f8c8d;
                margin-top: 25px;
                margin-bottom: 12px;
                font-size: 16px;
            }
            
            p {
                margin-bottom: 12px;
                text-align: justify;
            }
            
            ul, ol {
                margin-bottom: 15px;
                padding-left: 25px;
            }
            
            li {
                margin-bottom: 5px;
            }
            
            blockquote {
                border-left: 4px solid #3498db;
                margin: 20px 0;
                padding: 10px 20px;
                background-color: #f8f9fa;
                font-style: italic;
            }
            
            code {
                background-color: #f1f2f6;
                padding: 2px 4px;
                border-radius: 3px;
                font-family: "Noto Sans Mono CJK SC", "Source Han Sans CN", "Consolas", "DejaVu Sans Mono", "Liberation Mono", monospace;
            }
            
            pre {
                background-color: #f8f9fa;
                border: 1px solid #e9ecef;
                border-radius: 4px;
                padding: 15px;
                margin: 15px 0;
                overflow-x: auto;
            }
            
            img {
                max-width: 100%;
                height: auto;
                margin: 15px 0;
                border-radius: 5px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            }
            
            .article-meta {
                color: #7f8c8d;
                font-size: 12px;
                margin-bottom: 30px;
                padding: 15px;
                background-color: #f8f9fa;
                border-radius: 5px;
            }
            
            .footer {
                margin-top: 40px;
                padding-top: 20px;
                border-top: 1px solid #e9ecef;
                font-size: 12px;
                color: #7f8c8d;
                text-align: center;
            }
            """
            
            # ÁîüÊàêPDF
            pdf_filename = f"{self._safe_filename(title)}.pdf"
            pdf_path = temp_path / pdf_filename
            
            # ÈÖçÁΩÆ‰∏≠ÊñáÂ≠ó‰ΩìÊîØÊåÅ
            font_config = FontConfiguration()
            
            # Ê∑ªÂä†‰∏≠ÊñáÂ≠ó‰ΩìCSS - ‰ΩøÁî®Á≥ªÁªüÂ∑≤ÊúâÂ≠ó‰Ωì
            chinese_font_css = """
            @font-face {
                font-family: 'ChineseFont';
                src: local('DejaVu Sans'), local('Liberation Sans'), local('Arial Unicode MS');
                unicode-range: U+4E00-9FFF, U+3400-4DBF, U+20000-2A6DF, U+2A700-2B73F, U+2B740-2B81F, U+2B820-2CEAF;
            }
            
            body, p, h1, h2, h3, h4, h5, h6, li, td, th, div, span {
                font-family: 'ChineseFont', 'DejaVu Sans', 'Liberation Sans', 'Arial', sans-serif !important;
            }
            
            /* ‰∏∫‰∏≠ÊñáÂ≠óÁ¨¶Âº∫Âà∂‰ΩøÁî®ÁâπÂÆöÂ≠ó‰Ωì */
            .chinese-text {
                font-family: 'DejaVu Sans', 'Liberation Sans', 'Arial Unicode MS', sans-serif;
                font-size: 14px;
                line-height: 1.8;
            }
            """
            
            html_doc = HTML(string=html_content)
            css_doc = CSS(string=css_content + chinese_font_css, font_config=font_config)
            
            html_doc.write_pdf(str(pdf_path), stylesheets=[css_doc], font_config=font_config)
            
            self.logger.info(f"PDFÁîüÊàêÊàêÂäü: {pdf_filename}")
            return True, pdf_path
            
        except Exception as e:
            self.logger.error(f"PDFÁîüÊàêÂ§±Ë¥•: {e}")
            return False, None
    
    def _prepare_html_for_pdf(self, post: frontmatter.Post, title: str) -> str:
        """ÂáÜÂ§áÁî®‰∫éPDFÁöÑHTMLÂÜÖÂÆπ"""
        # ÊñáÁ´†ÂÖÉ‰ø°ÊÅØ
        date = post.metadata.get('date', '')
        categories = post.metadata.get('categories', [])
        tags = post.metadata.get('tags', [])
        
        # Á°Æ‰øùcategoriesÂíåtagsÊòØÂ≠óÁ¨¶‰∏≤ÂàóË°®
        if categories and not isinstance(categories, list):
            categories = [str(categories)]
        if tags and not isinstance(tags, list):
            tags = [str(tags)]
        
        # ËΩ¨Êç¢ÊâÄÊúâÂÖÉÁ¥†‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÁ°Æ‰øùÁ±ªÂûãÂÆâÂÖ®
        if categories and isinstance(categories, (list, tuple)):
            categories = [str(cat) for cat in categories]
        else:
            categories = []
        
        if tags and isinstance(tags, (list, tuple)):
            tags = [str(tag) for tag in tags]
        else:
            tags = []
        
        # ËΩ¨Êç¢Markdown‰∏∫HTML
        html_body = markdown2.markdown(
            post.content,
            extras=["fenced-code-blocks", "tables", "strike", "task_list"]
        )
        
        # Â§ÑÁêÜÂõæÁâáÈìæÊé• - ÁßªÈô§OneDriveÈìæÊé•ÔºåÂõ†‰∏∫PDF‰∏≠Êó†Ê≥ïÊòæÁ§∫
        html_body = re.sub(r'<img[^>]+src="[^"]*1drv\.ms[^"]*"[^>]*>', 
                          '<p style="color: #666; font-style: italic;">[ÂõæÁâáÂ∑≤ÁúÅÁï•ÔºåËØ∑Êü•ÁúãÂéüÊñáÊàñ‰∏ãËΩΩÂõæÁâáËµÑÊ∫ê]</p>', 
                          html_body)
        
        # ÊûÑÂª∫ÂÆåÊï¥HTML
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
</head>
<body class="chinese-text">
    <h1 class="chinese-text">{title}</h1>
    
    <div class="article-meta chinese-text">
        <p><strong>ÂèëÂ∏ÉÊó•Êúü</strong>: {date}</p>
        {f'<p><strong>ÂàÜÁ±ª</strong>: {", ".join(categories)}</p>' if categories else ''}
        {f'<p><strong>Ê†áÁ≠æ</strong>: {", ".join(tags)}</p>' if tags else ''}
        <p><strong>PDFÁîüÊàêÊó∂Èó¥</strong>: {datetime.now().strftime("%YÂπ¥%mÊúà%dÊó• %H:%M")}</p>
    </div>
    
    <div class="chinese-text">
    {html_body}
    </div>
    
    <div class="footer chinese-text">
        <p>Êú¨PDFÁî±"ÊúâÂøÉË®ÄËÄÖ"Ëá™Âä®ÁîüÊàêÁ≥ªÁªüÂàõÂª∫</p>
        <p>Ëé∑ÂèñÊõ¥Â§öÂÜÖÂÆπËØ∑ÂÖ≥Ê≥®ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÔºöÊúâÂøÉË®ÄËÄÖ</p>
        <p>ÂçöÂÆ¢Âú∞ÂùÄÔºöhttps://zhurong2020.github.io</p>
    </div>
</body>
</html>
        """
        
        return html_content
    
    def _collect_images(self, content: str, temp_path: Path) -> List[Dict]:
        """Êî∂ÈõÜÂπ∂‰∏ãËΩΩÊñáÁ´†‰∏≠ÁöÑÂõæÁâá"""
        images_info = []
        
        # Êü•ÊâæÊâÄÊúâÂõæÁâáÈìæÊé•
        image_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
        matches = re.findall(image_pattern, content)
        
        images_dir = temp_path / "images"
        images_dir.mkdir(exist_ok=True)
        
        for i, (alt_text, image_url) in enumerate(matches, 1):
            try:
                if image_url.startswith(('http://', 'https://')):
                    # ‰∏ãËΩΩÁΩëÁªúÂõæÁâá
                    response = requests.get(image_url, timeout=20)
                    if response.status_code == 200:
                        # Â∞ùËØï‰ªéURLÊàñheadersËé∑ÂèñÊñá‰ª∂Êâ©Â±ïÂêç
                        ext = self._get_image_extension(image_url, response.headers)
                        filename = f"image_{i:02d}{ext}"
                        
                        image_path = images_dir / filename
                        with open(image_path, 'wb') as f:
                            f.write(response.content)
                        
                        images_info.append({
                            "filename": filename,
                            "alt_text": alt_text,
                            "original_url": image_url,
                            "local_path": str(image_path),
                            "size_kb": round(len(response.content) / 1024, 2)
                        })
                        
                        self.logger.info(f"ÂõæÁâá‰∏ãËΩΩÊàêÂäü: {filename}")
                    else:
                        self.logger.warning(f"ÂõæÁâá‰∏ãËΩΩÂ§±Ë¥•: {image_url}")
                        
            except Exception as e:
                self.logger.warning(f"Â§ÑÁêÜÂõæÁâáÊó∂Âá∫Èîô: {image_url} - {e}")
        
        return images_info
    
    def _get_image_extension(self, url: str, headers) -> str:
        """‰ªéURLÊàñheadersËé∑ÂèñÂõæÁâáÊâ©Â±ïÂêç"""
        # ÂÖà‰ªéURLË∑ØÂæÑÂ∞ùËØï
        parsed_url = urlparse(url)
        path = parsed_url.path.lower()
        
        for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']:
            if ext in path:
                return ext
        
        # ‰ªéContent-TypeÂ§¥Ëé∑Âèñ
        content_type = headers.get('content-type', '').lower()
        if 'jpeg' in content_type or 'jpg' in content_type:
            return '.jpg'
        elif 'png' in content_type:
            return '.png'
        elif 'gif' in content_type:
            return '.gif'
        elif 'webp' in content_type:
            return '.webp'
        
        # ÈªòËÆ§‰ΩøÁî®jpg
        return '.jpg'
    
    def _extract_links(self, content: str) -> List[Dict]:
        """ÊèêÂèñÊñáÁ´†‰∏≠ÁöÑÊâÄÊúâÈìæÊé•"""
        links_info = []
        
        # MarkdownÈìæÊé•Ê†ºÂºè [text](url)
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        matches = re.findall(link_pattern, content)
        
        # ÂéªÈáçÂπ∂ÂàÜÁ±ª
        seen_urls = set()
        for text, url in matches:
            if url not in seen_urls and url.startswith(('http://', 'https://')):
                seen_urls.add(url)
                
                # ÁÆÄÂçïÂàÜÁ±ª
                category = "ÂÖ∂‰ªñ"
                domain = urlparse(url).netloc.lower()
                
                if any(official in domain for official in ['tesla.com', 'spacex.com', 'neuralink.com', 'x.com']):
                    category = "ÂÆòÊñπÁΩëÁ´ô"
                elif any(news in domain for news in ['bloomberg.com', 'reuters.com', 'cnbc.com', 'wsj.com']):
                    category = "Êñ∞ÈóªÂ™í‰Ωì"
                elif any(tech in domain for tech in ['github.com', 'arxiv.org', 'nature.com', 'science.org']):
                    category = "ÊäÄÊúØËµÑÊñô"
                elif any(social in domain for social in ['twitter.com', 'linkedin.com', 'youtube.com']):
                    category = "Á§æ‰∫§Â™í‰Ωì"
                
                links_info.append({
                    "text": text,
                    "url": url,
                    "category": category,
                    "domain": domain
                })
        
        return links_info
    
    def _create_links_file(self, links_info: List[Dict], temp_path: Path) -> None:
        """ÂàõÂª∫ÈìæÊé•Ê±áÊÄªÊñá‰ª∂"""
        if not links_info:
            return
        
        content = "# üîó ÈìæÊé•Ê±áÊÄª\n\n"
        
        # ÊåâÂàÜÁ±ªÁªÑÁªáÈìæÊé•
        categories: Dict[str, List[Dict]] = {}
        for link in links_info:
            category = link["category"]
            if category not in categories:
                categories[category] = []
            categories[category].append(link)
        
        for category, links in categories.items():
            content += f"## {category}\n\n"
            for link in links:
                content += f"- [{link['text']}]({link['url']})\n"
            content += "\n"
        
        content += "---\n\n"
        content += f"*ÂÖ±ËÆ° {len(links_info)} ‰∏™ÈìæÊé•ÔºåÁîüÊàêÊó∂Èó¥: {datetime.now().strftime('%YÂπ¥%mÊúà%dÊó• %H:%M')}*\n"
        
        links_file = temp_path / "ÈìæÊé•Ê±áÊÄª.txt"
        with open(links_file, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _create_resource_list(self, title: str, date: str, images_info: List[Dict], 
                            links_info: List[Dict], temp_path: Path, article_content: str = "") -> None:
        """ÂàõÂª∫ËµÑÊñôÊ∏ÖÂçïÊñá‰ª∂"""
        # ÁîüÊàêÂõæÁâáÂàóË°®
        image_list = ""
        if images_info:
            for img in images_info:
                image_list += f"- `{img['filename']}` - {img['alt_text']} ({img['size_kb']} KB)\n"
        else:
            image_list = "- Êó†ÂõæÁâáËµÑÊ∫ê\n"
        
        # ÁîüÊàêÂÆòÊñπÈìæÊé•ÂàóË°®
        official_links = ""
        additional_links = ""
        
        for link in links_info:
            link_line = f"- [{link['text']}]({link['url']})\n"
            if link['category'] == "ÂÆòÊñπÁΩëÁ´ô":
                official_links += link_line
            else:
                additional_links += link_line
        
        if not official_links:
            official_links = "- Êó†ÂÆòÊñπÈìæÊé•\n"
        if not additional_links:
            additional_links = "- Êó†Êâ©Â±ïËµÑÊñô\n"
        
        # ÊèêÂèñYouTubeÈìæÊé•
        youtube_links = self._extract_youtube_links(article_content)
        if not youtube_links:
            youtube_links = "- Êó†ËßÜÈ¢ë/Èü≥È¢ëËµÑÊ∫ê\n"
        
        # ÁîüÊàêËµÑÊñôÊ∏ÖÂçï
        content = self.resource_list_template.format(
            title=title,
            date=date,
            generated_at=datetime.now().strftime("%YÂπ¥%mÊúà%dÊó• %H:%M"),
            article_filename=self._safe_filename(title),
            image_list=image_list,
            youtube_links=youtube_links,
            official_links=official_links,
            additional_links=additional_links
        )
        
        readme_file = temp_path / "ËµÑÊñôÊ∏ÖÂçï.md"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _extract_youtube_links(self, content: str) -> str:
        """ÊèêÂèñÊñáÁ´†‰∏≠ÁöÑYouTubeÈìæÊé•"""
        youtube_links = ""
        
        # 1. ‰ªéYouTube iframeÂµåÂÖ•‰ª£Á†Å‰∏≠ÊèêÂèñ
        iframe_pattern = re.compile(r'<iframe[^>]*src="https://www\.youtube\.com/embed/([^"]*)"[^>]*>', re.IGNORECASE)
        iframe_matches = iframe_pattern.findall(content)
        
        for video_id in iframe_matches:
            youtube_url = f"https://www.youtube.com/watch?v={video_id}"
            youtube_links += f"- üéß [‰∏≠ÊñáÊí≠ÂÆ¢ÂØºËØª]({youtube_url}) - AIÁîüÊàêÁöÑ‰∏≠ÊñáËÆ≤Ëß£ÁâàÊú¨\n"
        
        # 2. ‰ªéÂ∏∏ËßÑÈìæÊé•‰∏≠ÊèêÂèñ
        link_pattern = re.compile(r'\[([^\]]*)\]\((https://(?:www\.)?youtube\.com/watch\?v=[^)]*)\)', re.IGNORECASE)
        link_matches = link_pattern.findall(content)
        
        for link_text, youtube_url in link_matches:
            if "youtube.com/watch" in youtube_url.lower():
                youtube_links += f"- üé¨ [{link_text}]({youtube_url}) - ÂéüÂßãËßÜÈ¢ëËµÑÊ∫ê\n"
        
        # 3. Êü•ÊâæÊú¨Âú∞Èü≥È¢ëÊñá‰ª∂ÂØπÂ∫îÁöÑYouTubeÊò†Â∞Ñ
        try:
            # ÂØºÂÖ•Êò†Â∞ÑÁÆ°ÁêÜÂô®
            import sys
            project_root = Path(__file__).parent.parent.parent
            sys.path.insert(0, str(project_root))
            from .youtube_link_mapper import YouTubeLinkMapper
            
            mapper = YouTubeLinkMapper()
            
            # ÊèêÂèñÈü≥È¢ëÊñá‰ª∂Ë∑ØÂæÑ
            audio_pattern = re.compile(r'{{ site\.baseurl }}/assets/audio/([^"]*\.mp3)', re.IGNORECASE)
            audio_matches = audio_pattern.findall(content)
            
            for audio_file in audio_matches:
                audio_path = f"assets/audio/{audio_file}"
                mapping_info = mapper.get_mapping_info(audio_path)
                if mapping_info:
                    youtube_url = mapping_info["youtube_url"]
                    title = mapping_info.get("title", "Èü≥È¢ëÂÜÖÂÆπ")
                    youtube_links += f"- üéß [{title}]({youtube_url}) - ‰ªéÊú¨Âú∞Èü≥È¢ë‰∏ä‰º†\n"
                    
        except Exception as e:
            self.logger.debug(f"Êü•ÊâæYouTubeÊò†Â∞ÑÊó∂Âá∫Èîô: {e}")
        
        return youtube_links
    
    def _create_zip_package(self, temp_path: Path, title: str, date: str) -> Tuple[bool, Optional[Path]]:
        """ÂàõÂª∫ZIPÊñá‰ª∂"""
        try:
            # ÁîüÊàêZIPÊñá‰ª∂Âêç
            safe_title = self._safe_filename(title)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"{safe_title}_{timestamp}_package.zip"
            zip_path = self.output_dir / zip_filename
            
            # ÂàõÂª∫ZIPÊñá‰ª∂
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # Ê∑ªÂä†ÊâÄÊúâÊñá‰ª∂
                for file_path in temp_path.rglob('*'):
                    if file_path.is_file():
                        # ËÆ°ÁÆóÁõ∏ÂØπË∑ØÂæÑ
                        arcname = file_path.relative_to(temp_path)
                        zipf.write(file_path, arcname)
            
            self.logger.info(f"ZIPÂåÖÂàõÂª∫ÊàêÂäü: {zip_filename}")
            return True, zip_path
            
        except Exception as e:
            self.logger.error(f"ÂàõÂª∫ZIPÂåÖÂ§±Ë¥•: {e}")
            return False, None
    
    def _safe_filename(self, filename: str) -> str:
        """ÁîüÊàêÂÆâÂÖ®ÁöÑÊñá‰ª∂Âêç"""
        # ÁßªÈô§ÊàñÊõøÊç¢‰∏çÂÆâÂÖ®ÁöÑÂ≠óÁ¨¶
        safe = re.sub(r'[^\w\s-]', '', filename)
        safe = re.sub(r'[-\s]+', '-', safe).strip('-')
        return safe[:50]  # ÈôêÂà∂ÈïøÂ∫¶
    
    def get_package_info(self, package_path: str) -> Optional[Dict]:
        """Ëé∑ÂèñÂÜÖÂÆπÂåÖ‰ø°ÊÅØ"""
        try:
            zip_path = Path(package_path)
            if not zip_path.exists():
                return None
            
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                file_list = zipf.namelist()
                
                info = {
                    "path": str(zip_path),
                    "filename": zip_path.name,
                    "size_mb": round(zip_path.stat().st_size / (1024 * 1024), 2),
                    "created_at": datetime.fromtimestamp(zip_path.stat().st_ctime),
                    "files": {
                        "total": len(file_list),
                        "pdf": len([f for f in file_list if f.endswith('.pdf')]),
                        "images": len([f for f in file_list if f.startswith('images/')]),
                        "docs": len([f for f in file_list if f.endswith(('.md', '.txt'))])
                    }
                }
                
                return info
                
        except Exception as e:
            self.logger.error(f"Ëé∑ÂèñÂåÖ‰ø°ÊÅØÂ§±Ë¥•: {e}")
            return None


def create_package_creator() -> PackageCreator:
    """ÂàõÂª∫ÂÜÖÂÆπÂåÖÂàõÂª∫Âô®ÂÆû‰æã"""
    return PackageCreator()


if __name__ == "__main__":
    # ÊµãËØïËÑöÊú¨
    import sys
    
    if len(sys.argv) != 2:
        print("Áî®Ê≥ï: python package_creator.py <article_path>")
        sys.exit(1)
    
    article_path = sys.argv[1]
    
    try:
        creator = create_package_creator()
        success, result = creator.create_package(article_path)
        
        if success:
            print(f"‚úÖ ÂÜÖÂÆπÂåÖÂàõÂª∫ÊàêÂäü!")
            print(f"Êñá‰ª∂Ë∑ØÂæÑ: {result['package_path']}")
            print(f"Êñá‰ª∂Â§ßÂ∞è: {result['size_mb']} MB")
            print(f"ÂåÖÂê´Êñá‰ª∂: PDF + {result['files']['images_count']}Âº†ÂõæÁâá + {result['files']['links_count']}‰∏™ÈìæÊé•")
        else:
            print(f"‚ùå ÂàõÂª∫Â§±Ë¥•: {result.get('error', 'Êú™Áü•ÈîôËØØ')}")
            
    except Exception as e:
        print(f"‚ùå ÈîôËØØ: {e}")