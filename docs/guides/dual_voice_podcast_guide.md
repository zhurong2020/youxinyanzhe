# 双人对话播客功能使用指南

## 概述

我已经为你的YouTube播客生成器升级了双人对话功能，现在可以生成更生动的播客音频，模拟两个人的真实对话。

## ✅ 已完成的功能

### 1. ElevenLabs API角色查询
- **新增功能**: `get_available_models()` 方法获取所有可用TTS模型
- **增强功能**: `list_all_voices()` 方法获取详细的声音信息，包括支持的模型
- **工具菜单**: 在`elevenlabs_voice_tester.py`中添加了"获取可用TTS模型"选项

### 2. 双人对话音频生成
- **智能检测**: 自动识别对话格式文本，启用双人模式
- **多种格式**: 支持 `[角色]: 内容`、`【角色】: 内容`、`A: 内容` 等格式
- **声音区分**: 不同角色使用不同的声音和参数配置
- **无缝回退**: 非对话格式自动切换到单人播音模式

### 3. 智能对话解析
- **角色映射**: 自动将各种角色名映射到A/B说话者
  - 说话者A: 主播助手、主持人、播音员等
  - 说话者B: 学习导师、嘉宾、专家、分析师等
- **文本清理**: 对话模式保留标记，单人模式移除标记
- **音频合并**: 使用pydub自动合并音频片段，添加适当停顿

## 🚀 使用方法

### 方法1: 通过测试工具

```bash
# 1. 测试ElevenLabs API和声音
python scripts/tools/elevenlabs_voice_tester.py

# 选择选项:
# 1. 列出所有可用声音 - 查看你账户中的声音
# 2. 获取可用TTS模型 - 查看支持的模型
# 4. 创建双人对话播客测试 - 直接测试双声音效果
# 7. 完整测试流程 - 一键完成所有测试

# 2. 测试双人对话功能
python scripts/tools/test_dual_voice_podcast.py
```

### 方法2: 通过主程序

```bash
# 运行主程序
python run.py

# 选择选项 10: YouTube播客生成器
# 输入YouTube视频URL，系统会自动:
# 1. 检测生成的脚本是否为对话格式
# 2. 如果是对话格式且使用ElevenLabs，启用双人模式
# 3. 生成双声音播客音频
```

## 📝 对话脚本格式

系统支持以下对话格式，会自动启用双人模式：

### 格式1: 方括号标记
```
[主播助手]: 大家好，欢迎收听今天的播客。
[学习导师]: 是的，今天我们要讨论一个很有趣的话题。
```

### 格式2: 书名号标记  
```
【主持人】: 这个技术发展如何？
【专家】: 从技术角度来看，确实很有前景。
```

### 格式3: 简单标记
```
A: 你对这个问题怎么看？
B: 我认为需要从多个角度分析。
```

## ⚙️ 配置说明

### 声音配置文件: `config/elevenlabs_voices.yml`

```yaml
elevenlabs_voices:
  voice_combinations:
    chinese_podcast:
      speaker_a:
        voice_id: "21m00Tcm4TlvDq8ikWAM"  # Rachel - 女声主持
        name: "Rachel"
        role: "主持人"
        settings:
          stability: 0.4
          similarity_boost: 0.8
          style: 0.6
      speaker_b:
        voice_id: "TxGEqnHWrfWFTfGW9XjX"  # Josh - 男声嘉宾
        name: "Josh"
        role: "嘉宾" 
        settings:
          stability: 0.35
          similarity_boost: 0.85
          style: 0.5
```

### 自定义声音组合

1. 运行 `python scripts/tools/elevenlabs_voice_tester.py`
2. 选择选项1列出所有可用声音
3. 选择选项3测试你喜欢的声音
4. 修改 `config/elevenlabs_voices.yml` 中的 `voice_id`
5. 调整 `settings` 参数优化声音效果

## 📊 技术特性

### 智能模式切换
- **检测逻辑**: 扫描脚本中的对话标记
- **条件判断**: 对话格式 + ElevenLabs引擎 = 双人模式
- **回退机制**: 任何失败都会回退到可靠的单人模式

### 音频处理
- **分段生成**: 每个对话片段单独生成音频
- **智能停顿**: 对话间自动添加0.6秒停顿
- **API限流**: 片段间0.5秒间隔避免限流
- **格式统一**: 输出标准WAV格式

### 错误处理
- **配置缺失**: 自动使用默认声音配置
- **库依赖**: pydub缺失时回退到单人模式
- **API失败**: ElevenLabs失败时切换到其他TTS引擎

## 🔧 常见问题

### Q: 如何确认双人模式已启用？
A: 查看日志输出：
```
🎭 检测到对话格式，启用双人对话模式
🎤 生成对话片段 1/6: 大家好，欢迎收听今天的播客...
✅ 双人对话音频生成成功: assets/audio/podcast.wav
```

### Q: 为什么没有启用双人模式？
A: 检查以下条件：
1. 文本包含对话标记（`[角色]:`、`A:`等）
2. 使用ElevenLabs TTS引擎
3. ELEVENLABS_API_KEY已正确配置
4. pydub库已安装

### Q: 如何选择最佳的声音组合？
A: 建议：
- **性别区分**: 一男一女区分度最高
- **音调差异**: 选择音调明显不同的声音  
- **角色匹配**: 根据内容选择合适风格的声音
- **多次测试**: 使用测试工具试听不同组合

### Q: 可以自定义说话者角色吗？
A: 可以，修改 `_parse_dialogue()` 方法中的角色映射：
```python
# 在 youtube_podcast_generator.py 中
if speaker_raw in ['A', '甲', '主持人', '自定义角色名']:
    speaker = 'A'
```

## 📈 性能优化

### API调用控制
- 每个片段生成间隔0.5秒
- 使用经过验证的声音ID避免失败
- 智能重试机制和错误恢复

### 音频质量
- 使用 `eleven_multilingual_v2` 模型获得最佳中文效果
- 针对双人对话优化的声音参数
- 适当的停顿时间增强听感

### 内存管理
- 流式音频生成避免大文件内存占用
- 及时清理临时音频数据
- 分段处理长文本内容

## 🎯 下一步建议

1. **测试你的API**: 先运行 `elevenlabs_voice_tester.py` 确认API工作正常
2. **选择声音**: 试听不同声音组合，选择最适合的配置
3. **生成播客**: 使用YouTube播客生成器测试完整流程
4. **优化配置**: 根据效果调整声音参数和角色映射

现在你可以生成更加生动、自然的双人对话播客了！🎉